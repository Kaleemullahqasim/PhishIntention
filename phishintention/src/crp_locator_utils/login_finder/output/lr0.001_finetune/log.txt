[03/28 11:04:34] detectron2 INFO: Rank of current process: 0. World size: 1
[03/28 11:04:35] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.7 (default, Mar 23 2020, 22:36:06) [GCC 7.3.0]
numpy                   1.18.1
detectron2              0.1.3 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/detectron2
Compiler                GCC 5.4
CUDA compiler           CUDA 9.2
detectron2 arch flags   sm_70
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.5.0 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   TITAN V
CUDA_HOME               /usr/local/cuda-11.2
Pillow                  7.0.0
torchvision             0.6.0a0+82fd1c8 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70
fvcore                  0.1.1.post20200623
cv2                     4.2.0
----------------------  -------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 9.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[03/28 11:04:35] detectron2 INFO: Command line arguments: Namespace(config_file='configs/faster_rcnn_login_lr0.001_finetune.yaml', dist_url='tcp://127.0.0.1:49923', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[03/28 11:04:35] detectron2 INFO: Contents of args.config_file=configs/faster_rcnn_login_lr0.001_finetune.yaml:
_BASE_: "./bases/Base-RCNN-FPN.yaml"
MODEL:
  # COCO ResNet50 weights
  WEIGHTS: "./output/lr0.001_aug/model_final.pth"
  MASK_ON: False # Not doing segmentation
  RESNETS:
    DEPTH: 50 # ResNet50
  ROI_HEADS:
    NUM_CLASSES: 1 # Change to suit own task
    # Can reduce this for lower memory/faster training; Default 512
    BATCH_SIZE_PER_IMAGE: 512
  BACKBONE:
    FREEZE_AT: 2 # Default 2
DATASETS:
  TRAIN: ("login_train",)
  TEST: ("login_test",)
DATALOADER:
  NUM_WORKERS: 0
SOLVER:
  IMS_PER_BATCH: 8 # Batch size; Default 16
  BASE_LR: 0.001
  # (2/3, 8/9)
  STEPS: (12000, 16000) # The iteration number to decrease learning rate by GAMMA.
  MAX_ITER: 18000 # Number of training iterations
  CHECKPOINT_PERIOD: 4000 # Saves checkpoint every number of steps
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800) # Image input sizes
TEST:
  # The period (in terms of steps) to evaluate the model during training.
  # Set to 0 to disable.
  EVAL_PERIOD: 2000
OUTPUT_DIR: "./output/lr0.001_finetune" # Specify output directory



[03/28 11:04:35] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 0
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('login_test',)
  TRAIN: ('login_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/lr0.001_aug/model_final.pth
OUTPUT_DIR: ./output/lr0.001_finetune
SEED: -1
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: False
  STEPS: (12000, 16000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 2000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[03/28 11:04:35] detectron2 INFO: Full config saved to ./output/lr0.001_finetune/config.yaml
[03/28 11:04:35] d2.utils.env INFO: Using a generated random seed 35439879
[03/28 11:04:38] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[03/28 11:04:38] d2.data.datasets.coco INFO: Loaded 4843 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/train_coco2.json
[03/28 11:04:38] d2.data.build INFO: Removed 7 images with no usable annotations. 4836 images left.
[03/28 11:04:38] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   login    | 14179        |
|            |              |[0m
[03/28 11:04:38] d2.data.common INFO: Serializing 4836 elements to byte tensors and concatenating them all ...
[03/28 11:04:38] d2.data.common INFO: Serialized dataset takes 1.67 MiB
[03/28 11:04:38] d2.data.build INFO: Using training sampler TrainingSampler
[03/28 11:04:39] fvcore.common.checkpoint INFO: Loading checkpoint from ./output/lr0.001_aug/model_final.pth
[03/28 11:04:40] d2.engine.train_loop INFO: Starting training from iteration 0
[03/28 11:05:16] d2.utils.events INFO:  eta: 8:15:01  iter: 19  total_loss: 1.122  loss_cls: 0.187  loss_box_reg: 0.022  loss_rpn_cls: 0.836  loss_rpn_loc: 0.098  time: 1.7139  data_time: 1.1662  lr: 0.000020  max_mem: 9421M
[03/28 11:06:00] d2.utils.events INFO:  eta: 8:14:28  iter: 39  total_loss: 0.479  loss_cls: 0.195  loss_box_reg: 0.031  loss_rpn_cls: 0.143  loss_rpn_loc: 0.077  time: 1.9553  data_time: 1.6185  lr: 0.000040  max_mem: 9421M
[03/28 11:06:33] d2.utils.events INFO:  eta: 7:45:17  iter: 59  total_loss: 0.355  loss_cls: 0.165  loss_box_reg: 0.051  loss_rpn_cls: 0.045  loss_rpn_loc: 0.080  time: 1.8467  data_time: 1.0892  lr: 0.000060  max_mem: 9421M
[03/28 11:07:06] d2.utils.events INFO:  eta: 7:57:06  iter: 79  total_loss: 0.250  loss_cls: 0.118  loss_box_reg: 0.049  loss_rpn_cls: 0.042  loss_rpn_loc: 0.047  time: 1.7996  data_time: 1.0838  lr: 0.000080  max_mem: 9421M
[03/28 11:07:41] d2.utils.events INFO:  eta: 8:09:02  iter: 99  total_loss: 0.250  loss_cls: 0.100  loss_box_reg: 0.047  loss_rpn_cls: 0.035  loss_rpn_loc: 0.061  time: 1.7874  data_time: 1.1817  lr: 0.000100  max_mem: 9421M
[03/28 11:08:17] d2.utils.events INFO:  eta: 8:09:49  iter: 119  total_loss: 0.221  loss_cls: 0.081  loss_box_reg: 0.046  loss_rpn_cls: 0.038  loss_rpn_loc: 0.056  time: 1.7961  data_time: 1.2730  lr: 0.000120  max_mem: 9421M
[03/28 11:08:54] d2.utils.events INFO:  eta: 8:07:56  iter: 139  total_loss: 0.224  loss_cls: 0.088  loss_box_reg: 0.054  loss_rpn_cls: 0.036  loss_rpn_loc: 0.040  time: 1.8034  data_time: 1.2752  lr: 0.000140  max_mem: 9421M
[03/28 11:09:37] d2.utils.events INFO:  eta: 8:01:42  iter: 159  total_loss: 0.214  loss_cls: 0.088  loss_box_reg: 0.053  loss_rpn_cls: 0.031  loss_rpn_loc: 0.040  time: 1.8187  data_time: 1.3576  lr: 0.000160  max_mem: 9421M
[03/28 11:10:11] d2.utils.events INFO:  eta: 7:57:44  iter: 179  total_loss: 0.191  loss_cls: 0.074  loss_box_reg: 0.054  loss_rpn_cls: 0.032  loss_rpn_loc: 0.029  time: 1.8037  data_time: 1.0987  lr: 0.000180  max_mem: 9421M
[03/28 11:10:45] d2.utils.events INFO:  eta: 7:56:14  iter: 199  total_loss: 0.194  loss_cls: 0.074  loss_box_reg: 0.053  loss_rpn_cls: 0.026  loss_rpn_loc: 0.037  time: 1.7916  data_time: 1.1266  lr: 0.000200  max_mem: 9421M
[03/28 11:11:26] d2.utils.events INFO:  eta: 7:55:42  iter: 219  total_loss: 0.205  loss_cls: 0.072  loss_box_reg: 0.051  loss_rpn_cls: 0.023  loss_rpn_loc: 0.035  time: 1.8188  data_time: 1.5436  lr: 0.000220  max_mem: 9421M
[03/28 11:12:02] d2.utils.events INFO:  eta: 7:56:49  iter: 239  total_loss: 0.215  loss_cls: 0.076  loss_box_reg: 0.054  loss_rpn_cls: 0.024  loss_rpn_loc: 0.042  time: 1.8162  data_time: 1.2202  lr: 0.000240  max_mem: 9421M
[03/28 11:12:43] d2.utils.events INFO:  eta: 7:55:19  iter: 259  total_loss: 0.194  loss_cls: 0.072  loss_box_reg: 0.057  loss_rpn_cls: 0.026  loss_rpn_loc: 0.039  time: 1.8328  data_time: 1.4480  lr: 0.000260  max_mem: 9421M
[03/28 11:13:18] d2.utils.events INFO:  eta: 7:54:06  iter: 279  total_loss: 0.194  loss_cls: 0.069  loss_box_reg: 0.053  loss_rpn_cls: 0.034  loss_rpn_loc: 0.041  time: 1.8284  data_time: 1.1839  lr: 0.000280  max_mem: 9421M
[03/28 11:13:50] d2.utils.events INFO:  eta: 7:53:34  iter: 299  total_loss: 0.202  loss_cls: 0.075  loss_box_reg: 0.052  loss_rpn_cls: 0.033  loss_rpn_loc: 0.045  time: 1.8104  data_time: 0.9956  lr: 0.000300  max_mem: 9421M
[03/28 11:14:28] d2.utils.events INFO:  eta: 7:53:43  iter: 319  total_loss: 0.224  loss_cls: 0.082  loss_box_reg: 0.059  loss_rpn_cls: 0.029  loss_rpn_loc: 0.042  time: 1.8179  data_time: 1.3690  lr: 0.000320  max_mem: 9421M
[03/28 11:15:11] d2.utils.events INFO:  eta: 7:53:11  iter: 339  total_loss: 0.166  loss_cls: 0.059  loss_box_reg: 0.049  loss_rpn_cls: 0.020  loss_rpn_loc: 0.026  time: 1.8362  data_time: 1.5634  lr: 0.000340  max_mem: 9421M
[03/28 11:15:49] d2.utils.events INFO:  eta: 7:52:38  iter: 359  total_loss: 0.210  loss_cls: 0.074  loss_box_reg: 0.055  loss_rpn_cls: 0.029  loss_rpn_loc: 0.047  time: 1.8404  data_time: 1.3225  lr: 0.000360  max_mem: 9421M
[03/28 11:16:22] d2.utils.events INFO:  eta: 7:51:25  iter: 379  total_loss: 0.155  loss_cls: 0.059  loss_box_reg: 0.050  loss_rpn_cls: 0.017  loss_rpn_loc: 0.032  time: 1.8315  data_time: 1.0941  lr: 0.000380  max_mem: 9421M
[03/28 11:16:54] d2.utils.events INFO:  eta: 7:50:53  iter: 399  total_loss: 0.178  loss_cls: 0.064  loss_box_reg: 0.049  loss_rpn_cls: 0.022  loss_rpn_loc: 0.029  time: 1.8193  data_time: 1.0083  lr: 0.000400  max_mem: 9421M
[03/28 11:17:27] d2.utils.events INFO:  eta: 7:51:02  iter: 419  total_loss: 0.176  loss_cls: 0.065  loss_box_reg: 0.055  loss_rpn_cls: 0.024  loss_rpn_loc: 0.037  time: 1.8106  data_time: 1.0650  lr: 0.000420  max_mem: 9421M
[03/28 11:18:11] d2.utils.events INFO:  eta: 7:51:44  iter: 439  total_loss: 0.183  loss_cls: 0.066  loss_box_reg: 0.056  loss_rpn_cls: 0.024  loss_rpn_loc: 0.034  time: 1.8293  data_time: 1.6427  lr: 0.000440  max_mem: 9421M
[03/28 11:18:53] d2.utils.events INFO:  eta: 7:53:23  iter: 459  total_loss: 0.173  loss_cls: 0.062  loss_box_reg: 0.052  loss_rpn_cls: 0.026  loss_rpn_loc: 0.031  time: 1.8410  data_time: 1.5232  lr: 0.000460  max_mem: 9421M
[03/28 11:19:37] d2.utils.events INFO:  eta: 7:55:10  iter: 479  total_loss: 0.172  loss_cls: 0.054  loss_box_reg: 0.048  loss_rpn_cls: 0.022  loss_rpn_loc: 0.037  time: 1.8556  data_time: 1.6175  lr: 0.000480  max_mem: 9421M
[03/28 11:20:19] d2.utils.events INFO:  eta: 7:56:09  iter: 499  total_loss: 0.230  loss_cls: 0.072  loss_box_reg: 0.059  loss_rpn_cls: 0.027  loss_rpn_loc: 0.058  time: 1.8660  data_time: 1.5472  lr: 0.000500  max_mem: 9421M
[03/28 11:20:54] d2.utils.events INFO:  eta: 7:56:38  iter: 519  total_loss: 0.176  loss_cls: 0.065  loss_box_reg: 0.048  loss_rpn_cls: 0.023  loss_rpn_loc: 0.030  time: 1.8607  data_time: 1.1503  lr: 0.000519  max_mem: 9421M
[03/28 11:21:42] d2.utils.events INFO:  eta: 7:56:05  iter: 539  total_loss: 0.166  loss_cls: 0.063  loss_box_reg: 0.051  loss_rpn_cls: 0.017  loss_rpn_loc: 0.033  time: 1.8813  data_time: 1.8385  lr: 0.000539  max_mem: 9421M
[03/28 11:22:26] d2.utils.events INFO:  eta: 7:55:44  iter: 559  total_loss: 0.172  loss_cls: 0.067  loss_box_reg: 0.049  loss_rpn_cls: 0.022  loss_rpn_loc: 0.025  time: 1.8913  data_time: 1.5698  lr: 0.000559  max_mem: 9421M
[03/28 11:23:05] d2.utils.events INFO:  eta: 7:55:00  iter: 579  total_loss: 0.158  loss_cls: 0.060  loss_box_reg: 0.054  loss_rpn_cls: 0.021  loss_rpn_loc: 0.028  time: 1.8941  data_time: 1.4017  lr: 0.000579  max_mem: 9421M
[03/28 11:23:41] d2.utils.events INFO:  eta: 7:55:14  iter: 599  total_loss: 0.176  loss_cls: 0.069  loss_box_reg: 0.052  loss_rpn_cls: 0.018  loss_rpn_loc: 0.028  time: 1.8903  data_time: 1.2091  lr: 0.000599  max_mem: 9421M
[03/28 11:24:20] d2.utils.events INFO:  eta: 7:55:42  iter: 619  total_loss: 0.173  loss_cls: 0.062  loss_box_reg: 0.046  loss_rpn_cls: 0.022  loss_rpn_loc: 0.027  time: 1.8928  data_time: 1.4047  lr: 0.000619  max_mem: 9421M
[03/28 11:24:58] d2.utils.events INFO:  eta: 7:55:09  iter: 639  total_loss: 0.168  loss_cls: 0.061  loss_box_reg: 0.051  loss_rpn_cls: 0.020  loss_rpn_loc: 0.030  time: 1.8935  data_time: 1.3351  lr: 0.000639  max_mem: 9421M
[03/28 11:25:32] d2.utils.events INFO:  eta: 7:54:36  iter: 659  total_loss: 0.188  loss_cls: 0.063  loss_box_reg: 0.055  loss_rpn_cls: 0.017  loss_rpn_loc: 0.039  time: 1.8878  data_time: 1.1430  lr: 0.000659  max_mem: 9421M
[03/28 11:26:06] d2.utils.events INFO:  eta: 7:54:04  iter: 679  total_loss: 0.189  loss_cls: 0.065  loss_box_reg: 0.056  loss_rpn_cls: 0.022  loss_rpn_loc: 0.031  time: 1.8809  data_time: 1.0804  lr: 0.000679  max_mem: 9421M
[03/28 11:26:44] d2.utils.events INFO:  eta: 7:53:57  iter: 699  total_loss: 0.170  loss_cls: 0.065  loss_box_reg: 0.052  loss_rpn_cls: 0.016  loss_rpn_loc: 0.029  time: 1.8825  data_time: 1.3818  lr: 0.000699  max_mem: 9421M
[03/28 11:27:21] d2.utils.events INFO:  eta: 7:52:57  iter: 719  total_loss: 0.194  loss_cls: 0.073  loss_box_reg: 0.057  loss_rpn_cls: 0.018  loss_rpn_loc: 0.035  time: 1.8812  data_time: 1.2586  lr: 0.000719  max_mem: 9421M
[03/28 11:27:59] d2.utils.events INFO:  eta: 7:52:51  iter: 739  total_loss: 0.179  loss_cls: 0.065  loss_box_reg: 0.054  loss_rpn_cls: 0.016  loss_rpn_loc: 0.031  time: 1.8813  data_time: 1.2886  lr: 0.000739  max_mem: 9421M
[03/28 11:28:42] d2.utils.events INFO:  eta: 7:53:31  iter: 759  total_loss: 0.188  loss_cls: 0.071  loss_box_reg: 0.058  loss_rpn_cls: 0.017  loss_rpn_loc: 0.031  time: 1.8887  data_time: 1.5854  lr: 0.000759  max_mem: 9421M
[03/28 11:29:17] d2.utils.events INFO:  eta: 7:53:41  iter: 779  total_loss: 0.167  loss_cls: 0.058  loss_box_reg: 0.054  loss_rpn_cls: 0.015  loss_rpn_loc: 0.034  time: 1.8845  data_time: 1.1446  lr: 0.000779  max_mem: 9421M
[03/28 11:29:50] d2.utils.events INFO:  eta: 7:53:08  iter: 799  total_loss: 0.173  loss_cls: 0.060  loss_box_reg: 0.057  loss_rpn_cls: 0.013  loss_rpn_loc: 0.026  time: 1.8785  data_time: 1.0592  lr: 0.000799  max_mem: 9421M
[03/28 11:30:27] d2.utils.events INFO:  eta: 7:51:52  iter: 819  total_loss: 0.180  loss_cls: 0.066  loss_box_reg: 0.054  loss_rpn_cls: 0.019  loss_rpn_loc: 0.034  time: 1.8779  data_time: 1.2379  lr: 0.000819  max_mem: 9421M
[03/28 11:31:05] d2.utils.events INFO:  eta: 7:51:19  iter: 839  total_loss: 0.168  loss_cls: 0.065  loss_box_reg: 0.054  loss_rpn_cls: 0.012  loss_rpn_loc: 0.033  time: 1.8787  data_time: 1.3327  lr: 0.000839  max_mem: 9421M
[03/28 11:31:45] d2.utils.events INFO:  eta: 7:50:56  iter: 859  total_loss: 0.172  loss_cls: 0.065  loss_box_reg: 0.050  loss_rpn_cls: 0.020  loss_rpn_loc: 0.039  time: 1.8815  data_time: 1.4325  lr: 0.000859  max_mem: 9421M
[03/28 11:32:24] d2.utils.events INFO:  eta: 7:50:56  iter: 879  total_loss: 0.170  loss_cls: 0.070  loss_box_reg: 0.055  loss_rpn_cls: 0.016  loss_rpn_loc: 0.027  time: 1.8824  data_time: 1.3600  lr: 0.000879  max_mem: 9421M
[03/28 11:32:59] d2.utils.events INFO:  eta: 7:50:23  iter: 899  total_loss: 0.157  loss_cls: 0.061  loss_box_reg: 0.054  loss_rpn_cls: 0.012  loss_rpn_loc: 0.024  time: 1.8797  data_time: 1.1898  lr: 0.000899  max_mem: 9421M
[03/28 11:33:43] d2.utils.events INFO:  eta: 7:50:32  iter: 919  total_loss: 0.167  loss_cls: 0.058  loss_box_reg: 0.046  loss_rpn_cls: 0.019  loss_rpn_loc: 0.031  time: 1.8871  data_time: 1.6527  lr: 0.000919  max_mem: 9421M
[03/28 11:34:18] d2.utils.events INFO:  eta: 7:50:17  iter: 939  total_loss: 0.162  loss_cls: 0.063  loss_box_reg: 0.053  loss_rpn_cls: 0.018  loss_rpn_loc: 0.037  time: 1.8840  data_time: 1.1623  lr: 0.000939  max_mem: 9421M
[03/28 11:34:56] d2.utils.events INFO:  eta: 7:49:26  iter: 959  total_loss: 0.159  loss_cls: 0.057  loss_box_reg: 0.053  loss_rpn_cls: 0.014  loss_rpn_loc: 0.026  time: 1.8841  data_time: 1.3339  lr: 0.000959  max_mem: 9421M
[03/28 11:35:40] d2.utils.events INFO:  eta: 7:48:53  iter: 979  total_loss: 0.164  loss_cls: 0.061  loss_box_reg: 0.055  loss_rpn_cls: 0.016  loss_rpn_loc: 0.032  time: 1.8904  data_time: 1.6075  lr: 0.000979  max_mem: 9421M
[03/28 11:36:17] d2.utils.events INFO:  eta: 7:47:38  iter: 999  total_loss: 0.146  loss_cls: 0.056  loss_box_reg: 0.056  loss_rpn_cls: 0.011  loss_rpn_loc: 0.023  time: 1.8896  data_time: 1.2572  lr: 0.000999  max_mem: 9421M
[03/28 11:36:52] d2.utils.events INFO:  eta: 7:47:47  iter: 1019  total_loss: 0.168  loss_cls: 0.063  loss_box_reg: 0.055  loss_rpn_cls: 0.015  loss_rpn_loc: 0.031  time: 1.8876  data_time: 1.2098  lr: 0.001000  max_mem: 9421M
[03/28 11:37:40] d2.utils.events INFO:  eta: 7:47:14  iter: 1039  total_loss: 0.153  loss_cls: 0.057  loss_box_reg: 0.047  loss_rpn_cls: 0.013  loss_rpn_loc: 0.021  time: 1.8973  data_time: 1.8031  lr: 0.001000  max_mem: 9421M
[03/28 11:38:23] d2.utils.events INFO:  eta: 7:46:59  iter: 1059  total_loss: 0.161  loss_cls: 0.060  loss_box_reg: 0.053  loss_rpn_cls: 0.019  loss_rpn_loc: 0.025  time: 1.9018  data_time: 1.5440  lr: 0.001000  max_mem: 9421M
[03/28 11:38:56] d2.utils.events INFO:  eta: 7:46:35  iter: 1079  total_loss: 0.179  loss_cls: 0.072  loss_box_reg: 0.063  loss_rpn_cls: 0.015  loss_rpn_loc: 0.026  time: 1.8968  data_time: 1.0456  lr: 0.001000  max_mem: 9421M
[03/28 11:39:31] d2.utils.events INFO:  eta: 7:46:01  iter: 1099  total_loss: 0.168  loss_cls: 0.064  loss_box_reg: 0.053  loss_rpn_cls: 0.015  loss_rpn_loc: 0.027  time: 1.8947  data_time: 1.1984  lr: 0.001000  max_mem: 9421M
[03/28 11:40:07] d2.utils.events INFO:  eta: 7:45:28  iter: 1119  total_loss: 0.193  loss_cls: 0.060  loss_box_reg: 0.052  loss_rpn_cls: 0.026  loss_rpn_loc: 0.034  time: 1.8929  data_time: 1.2158  lr: 0.001000  max_mem: 9421M
[03/28 11:40:48] d2.utils.events INFO:  eta: 7:44:47  iter: 1139  total_loss: 0.167  loss_cls: 0.057  loss_box_reg: 0.052  loss_rpn_cls: 0.018  loss_rpn_loc: 0.030  time: 1.8956  data_time: 1.4756  lr: 0.001000  max_mem: 9421M
[03/28 11:41:22] d2.utils.events INFO:  eta: 7:46:33  iter: 1159  total_loss: 0.151  loss_cls: 0.054  loss_box_reg: 0.054  loss_rpn_cls: 0.013  loss_rpn_loc: 0.022  time: 1.8917  data_time: 1.1082  lr: 0.001000  max_mem: 9421M
[03/28 11:41:56] d2.utils.events INFO:  eta: 7:46:09  iter: 1179  total_loss: 0.172  loss_cls: 0.065  loss_box_reg: 0.058  loss_rpn_cls: 0.015  loss_rpn_loc: 0.031  time: 1.8892  data_time: 1.1577  lr: 0.001000  max_mem: 9421M
[03/28 11:42:36] d2.utils.events INFO:  eta: 7:47:35  iter: 1199  total_loss: 0.170  loss_cls: 0.063  loss_box_reg: 0.057  loss_rpn_cls: 0.013  loss_rpn_loc: 0.026  time: 1.8906  data_time: 1.3953  lr: 0.001000  max_mem: 9421M
[03/28 11:43:15] d2.utils.events INFO:  eta: 7:45:27  iter: 1219  total_loss: 0.151  loss_cls: 0.051  loss_box_reg: 0.043  loss_rpn_cls: 0.012  loss_rpn_loc: 0.026  time: 1.8919  data_time: 1.4166  lr: 0.001000  max_mem: 9421M
[03/28 11:43:47] d2.utils.events INFO:  eta: 7:43:42  iter: 1239  total_loss: 0.163  loss_cls: 0.062  loss_box_reg: 0.052  loss_rpn_cls: 0.013  loss_rpn_loc: 0.024  time: 1.8867  data_time: 0.9964  lr: 0.001000  max_mem: 9421M
[03/28 11:44:30] d2.utils.events INFO:  eta: 7:43:56  iter: 1259  total_loss: 0.154  loss_cls: 0.062  loss_box_reg: 0.054  loss_rpn_cls: 0.015  loss_rpn_loc: 0.027  time: 1.8914  data_time: 1.6306  lr: 0.001000  max_mem: 9421M
[03/28 11:45:09] d2.utils.events INFO:  eta: 7:43:47  iter: 1279  total_loss: 0.152  loss_cls: 0.052  loss_box_reg: 0.056  loss_rpn_cls: 0.019  loss_rpn_loc: 0.027  time: 1.8916  data_time: 1.3500  lr: 0.001000  max_mem: 9421M
[03/28 11:45:44] d2.utils.events INFO:  eta: 7:45:22  iter: 1299  total_loss: 0.156  loss_cls: 0.055  loss_box_reg: 0.048  loss_rpn_cls: 0.012  loss_rpn_loc: 0.029  time: 1.8896  data_time: 1.1748  lr: 0.001000  max_mem: 9421M
[03/28 11:46:24] d2.utils.events INFO:  eta: 7:44:49  iter: 1319  total_loss: 0.163  loss_cls: 0.062  loss_box_reg: 0.052  loss_rpn_cls: 0.012  loss_rpn_loc: 0.028  time: 1.8915  data_time: 1.4597  lr: 0.001000  max_mem: 9421M
[03/28 11:47:02] d2.utils.events INFO:  eta: 7:43:46  iter: 1339  total_loss: 0.158  loss_cls: 0.065  loss_box_reg: 0.057  loss_rpn_cls: 0.012  loss_rpn_loc: 0.021  time: 1.8917  data_time: 1.3559  lr: 0.001000  max_mem: 9421M
[03/28 11:47:43] d2.utils.events INFO:  eta: 7:43:13  iter: 1359  total_loss: 0.152  loss_cls: 0.055  loss_box_reg: 0.060  loss_rpn_cls: 0.010  loss_rpn_loc: 0.024  time: 1.8935  data_time: 1.4308  lr: 0.001000  max_mem: 9421M
[03/28 11:48:15] d2.utils.events INFO:  eta: 7:42:21  iter: 1379  total_loss: 0.148  loss_cls: 0.057  loss_box_reg: 0.047  loss_rpn_cls: 0.012  loss_rpn_loc: 0.024  time: 1.8894  data_time: 1.0370  lr: 0.001000  max_mem: 9421M
[03/28 11:48:49] d2.utils.events INFO:  eta: 7:42:08  iter: 1399  total_loss: 0.169  loss_cls: 0.063  loss_box_reg: 0.057  loss_rpn_cls: 0.013  loss_rpn_loc: 0.028  time: 1.8870  data_time: 1.1493  lr: 0.001000  max_mem: 9421M
[03/28 11:49:23] d2.utils.events INFO:  eta: 7:41:35  iter: 1419  total_loss: 0.149  loss_cls: 0.054  loss_box_reg: 0.052  loss_rpn_cls: 0.016  loss_rpn_loc: 0.027  time: 1.8838  data_time: 1.0877  lr: 0.001000  max_mem: 9421M
[03/28 11:50:04] d2.utils.events INFO:  eta: 7:41:11  iter: 1439  total_loss: 0.163  loss_cls: 0.058  loss_box_reg: 0.051  loss_rpn_cls: 0.018  loss_rpn_loc: 0.031  time: 1.8863  data_time: 1.4848  lr: 0.001000  max_mem: 9421M
[03/28 11:50:44] d2.utils.events INFO:  eta: 7:40:22  iter: 1459  total_loss: 0.154  loss_cls: 0.059  loss_box_reg: 0.050  loss_rpn_cls: 0.011  loss_rpn_loc: 0.025  time: 1.8877  data_time: 1.3895  lr: 0.001000  max_mem: 9421M
[03/28 11:51:30] d2.utils.events INFO:  eta: 7:39:49  iter: 1479  total_loss: 0.139  loss_cls: 0.059  loss_box_reg: 0.046  loss_rpn_cls: 0.013  loss_rpn_loc: 0.023  time: 1.8930  data_time: 1.7006  lr: 0.001000  max_mem: 9421M
[03/28 11:52:16] d2.utils.events INFO:  eta: 7:37:11  iter: 1499  total_loss: 0.178  loss_cls: 0.062  loss_box_reg: 0.059  loss_rpn_cls: 0.013  loss_rpn_loc: 0.025  time: 1.8981  data_time: 1.7335  lr: 0.001000  max_mem: 9421M
[03/28 11:52:50] d2.utils.events INFO:  eta: 7:34:16  iter: 1519  total_loss: 0.166  loss_cls: 0.059  loss_box_reg: 0.052  loss_rpn_cls: 0.013  loss_rpn_loc: 0.023  time: 1.8954  data_time: 1.0898  lr: 0.001000  max_mem: 9421M
[03/28 11:53:29] d2.utils.events INFO:  eta: 7:34:07  iter: 1539  total_loss: 0.152  loss_cls: 0.054  loss_box_reg: 0.053  loss_rpn_cls: 0.014  loss_rpn_loc: 0.025  time: 1.8965  data_time: 1.4202  lr: 0.001000  max_mem: 9421M
[03/28 11:54:14] d2.utils.events INFO:  eta: 7:34:32  iter: 1559  total_loss: 0.153  loss_cls: 0.055  loss_box_reg: 0.057  loss_rpn_cls: 0.011  loss_rpn_loc: 0.021  time: 1.8980  data_time: 1.4706  lr: 0.001000  max_mem: 9421M
[03/28 11:54:49] d2.utils.events INFO:  eta: 7:33:59  iter: 1579  total_loss: 0.153  loss_cls: 0.059  loss_box_reg: 0.053  loss_rpn_cls: 0.013  loss_rpn_loc: 0.021  time: 1.8957  data_time: 1.1543  lr: 0.001000  max_mem: 9421M
[03/28 11:55:20] d2.utils.events INFO:  eta: 7:31:27  iter: 1599  total_loss: 0.152  loss_cls: 0.055  loss_box_reg: 0.054  loss_rpn_cls: 0.011  loss_rpn_loc: 0.023  time: 1.8912  data_time: 0.9571  lr: 0.001000  max_mem: 9421M
[03/28 11:55:56] d2.utils.events INFO:  eta: 7:30:54  iter: 1619  total_loss: 0.164  loss_cls: 0.056  loss_box_reg: 0.057  loss_rpn_cls: 0.018  loss_rpn_loc: 0.036  time: 1.8899  data_time: 1.2081  lr: 0.001000  max_mem: 9421M
[03/28 11:56:38] d2.utils.events INFO:  eta: 7:29:50  iter: 1639  total_loss: 0.154  loss_cls: 0.053  loss_box_reg: 0.050  loss_rpn_cls: 0.015  loss_rpn_loc: 0.031  time: 1.8924  data_time: 1.4850  lr: 0.001000  max_mem: 9421M
[03/28 11:57:12] d2.utils.events INFO:  eta: 7:29:01  iter: 1659  total_loss: 0.170  loss_cls: 0.057  loss_box_reg: 0.053  loss_rpn_cls: 0.011  loss_rpn_loc: 0.028  time: 1.8903  data_time: 1.1283  lr: 0.001000  max_mem: 9421M
[03/28 11:57:47] d2.utils.events INFO:  eta: 7:27:26  iter: 1679  total_loss: 0.169  loss_cls: 0.058  loss_box_reg: 0.059  loss_rpn_cls: 0.011  loss_rpn_loc: 0.030  time: 1.8888  data_time: 1.2046  lr: 0.001000  max_mem: 9421M
[03/28 11:58:26] d2.utils.events INFO:  eta: 7:26:48  iter: 1699  total_loss: 0.170  loss_cls: 0.061  loss_box_reg: 0.057  loss_rpn_cls: 0.010  loss_rpn_loc: 0.030  time: 1.8892  data_time: 1.3370  lr: 0.001000  max_mem: 9421M
[03/28 11:59:08] d2.utils.events INFO:  eta: 7:25:56  iter: 1719  total_loss: 0.172  loss_cls: 0.065  loss_box_reg: 0.061  loss_rpn_cls: 0.014  loss_rpn_loc: 0.033  time: 1.8921  data_time: 1.5240  lr: 0.001000  max_mem: 9421M
[03/28 11:59:47] d2.utils.events INFO:  eta: 7:25:23  iter: 1739  total_loss: 0.147  loss_cls: 0.055  loss_box_reg: 0.057  loss_rpn_cls: 0.012  loss_rpn_loc: 0.027  time: 1.8922  data_time: 1.3273  lr: 0.001000  max_mem: 9421M
[03/28 12:00:25] d2.utils.events INFO:  eta: 7:23:59  iter: 1759  total_loss: 0.166  loss_cls: 0.064  loss_box_reg: 0.055  loss_rpn_cls: 0.012  loss_rpn_loc: 0.024  time: 1.8925  data_time: 1.3353  lr: 0.001000  max_mem: 9421M
[03/28 12:01:08] d2.utils.events INFO:  eta: 7:23:40  iter: 1779  total_loss: 0.153  loss_cls: 0.066  loss_box_reg: 0.049  loss_rpn_cls: 0.013  loss_rpn_loc: 0.019  time: 1.8954  data_time: 1.5783  lr: 0.001000  max_mem: 9421M
[03/28 12:01:44] d2.utils.events INFO:  eta: 7:23:34  iter: 1799  total_loss: 0.152  loss_cls: 0.058  loss_box_reg: 0.049  loss_rpn_cls: 0.011  loss_rpn_loc: 0.021  time: 1.8944  data_time: 1.2436  lr: 0.001000  max_mem: 9421M
[03/28 12:02:21] d2.utils.events INFO:  eta: 7:23:02  iter: 1819  total_loss: 0.148  loss_cls: 0.058  loss_box_reg: 0.048  loss_rpn_cls: 0.013  loss_rpn_loc: 0.027  time: 1.8941  data_time: 1.3069  lr: 0.001000  max_mem: 9421M
[03/28 12:03:02] d2.utils.events INFO:  eta: 7:22:55  iter: 1839  total_loss: 0.163  loss_cls: 0.053  loss_box_reg: 0.054  loss_rpn_cls: 0.011  loss_rpn_loc: 0.025  time: 1.8956  data_time: 1.4690  lr: 0.001000  max_mem: 9421M
[03/28 12:03:43] d2.utils.events INFO:  eta: 7:21:56  iter: 1859  total_loss: 0.172  loss_cls: 0.058  loss_box_reg: 0.054  loss_rpn_cls: 0.013  loss_rpn_loc: 0.024  time: 1.8973  data_time: 1.4930  lr: 0.001000  max_mem: 9421M
[03/28 12:04:18] d2.utils.events INFO:  eta: 7:20:56  iter: 1879  total_loss: 0.169  loss_cls: 0.058  loss_box_reg: 0.050  loss_rpn_cls: 0.013  loss_rpn_loc: 0.040  time: 1.8957  data_time: 1.1718  lr: 0.001000  max_mem: 9421M
[03/28 12:04:53] d2.utils.events INFO:  eta: 7:21:02  iter: 1899  total_loss: 0.140  loss_cls: 0.051  loss_box_reg: 0.051  loss_rpn_cls: 0.011  loss_rpn_loc: 0.021  time: 1.8941  data_time: 1.1750  lr: 0.001000  max_mem: 9421M
[03/28 12:05:31] d2.utils.events INFO:  eta: 7:20:43  iter: 1919  total_loss: 0.182  loss_cls: 0.063  loss_box_reg: 0.057  loss_rpn_cls: 0.016  loss_rpn_loc: 0.037  time: 1.8941  data_time: 1.3192  lr: 0.001000  max_mem: 9421M
[03/28 12:06:13] d2.utils.events INFO:  eta: 7:19:56  iter: 1939  total_loss: 0.163  loss_cls: 0.062  loss_box_reg: 0.054  loss_rpn_cls: 0.014  loss_rpn_loc: 0.032  time: 1.8964  data_time: 1.5391  lr: 0.001000  max_mem: 9421M
[03/28 12:06:51] d2.utils.events INFO:  eta: 7:18:59  iter: 1959  total_loss: 0.154  loss_cls: 0.058  loss_box_reg: 0.059  loss_rpn_cls: 0.010  loss_rpn_loc: 0.024  time: 1.8964  data_time: 1.3294  lr: 0.001000  max_mem: 9421M
[03/28 12:07:33] d2.utils.events INFO:  eta: 7:17:23  iter: 1979  total_loss: 0.161  loss_cls: 0.056  loss_box_reg: 0.060  loss_rpn_cls: 0.013  loss_rpn_loc: 0.023  time: 1.8985  data_time: 1.5276  lr: 0.001000  max_mem: 9421M
[03/28 12:08:10] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/28 12:08:10] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   login    | 2862         |
|            |              |[0m
[03/28 12:08:10] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/28 12:08:10] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/28 12:08:10] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/28 12:08:13] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0490 s / img. ETA=0:03:13
[03/28 12:08:18] d2.evaluation.evaluator INFO: Inference done 30/1210. 0.0483 s / img. ETA=0:04:51
[03/28 12:08:23] d2.evaluation.evaluator INFO: Inference done 54/1210. 0.0472 s / img. ETA=0:04:33
[03/28 12:08:28] d2.evaluation.evaluator INFO: Inference done 74/1210. 0.0468 s / img. ETA=0:04:33
[03/28 12:08:33] d2.evaluation.evaluator INFO: Inference done 95/1210. 0.0465 s / img. ETA=0:04:29
[03/28 12:08:38] d2.evaluation.evaluator INFO: Inference done 117/1210. 0.0467 s / img. ETA=0:04:21
[03/28 12:08:44] d2.evaluation.evaluator INFO: Inference done 142/1210. 0.0466 s / img. ETA=0:04:08
[03/28 12:08:49] d2.evaluation.evaluator INFO: Inference done 164/1210. 0.0469 s / img. ETA=0:04:03
[03/28 12:08:54] d2.evaluation.evaluator INFO: Inference done 181/1210. 0.0469 s / img. ETA=0:04:05
[03/28 12:08:59] d2.evaluation.evaluator INFO: Inference done 200/1210. 0.0470 s / img. ETA=0:04:04
[03/28 12:09:04] d2.evaluation.evaluator INFO: Inference done 220/1210. 0.0469 s / img. ETA=0:04:00
[03/28 12:09:09] d2.evaluation.evaluator INFO: Inference done 239/1210. 0.0469 s / img. ETA=0:03:58
[03/28 12:09:17] d2.evaluation.evaluator INFO: Inference done 262/1210. 0.0471 s / img. ETA=0:04:02
[03/28 12:09:23] d2.evaluation.evaluator INFO: Inference done 286/1210. 0.0475 s / img. ETA=0:03:53
[03/28 12:09:28] d2.evaluation.evaluator INFO: Inference done 307/1210. 0.0476 s / img. ETA=0:03:47
[03/28 12:09:34] d2.evaluation.evaluator INFO: Inference done 312/1210. 0.0476 s / img. ETA=0:03:59
[03/28 12:09:39] d2.evaluation.evaluator INFO: Inference done 335/1210. 0.0477 s / img. ETA=0:03:51
[03/28 12:09:44] d2.evaluation.evaluator INFO: Inference done 360/1210. 0.0477 s / img. ETA=0:03:41
[03/28 12:09:50] d2.evaluation.evaluator INFO: Inference done 379/1210. 0.0476 s / img. ETA=0:03:38
[03/28 12:09:55] d2.evaluation.evaluator INFO: Inference done 386/1210. 0.0477 s / img. ETA=0:03:43
[03/28 12:10:01] d2.evaluation.evaluator INFO: Inference done 406/1210. 0.0476 s / img. ETA=0:03:39
[03/28 12:10:06] d2.evaluation.evaluator INFO: Inference done 429/1210. 0.0477 s / img. ETA=0:03:31
[03/28 12:10:12] d2.evaluation.evaluator INFO: Inference done 435/1210. 0.0477 s / img. ETA=0:03:37
[03/28 12:10:18] d2.evaluation.evaluator INFO: Inference done 455/1210. 0.0476 s / img. ETA=0:03:31
[03/28 12:10:24] d2.evaluation.evaluator INFO: Inference done 474/1210. 0.0475 s / img. ETA=0:03:26
[03/28 12:10:29] d2.evaluation.evaluator INFO: Inference done 498/1210. 0.0475 s / img. ETA=0:03:17
[03/28 12:10:34] d2.evaluation.evaluator INFO: Inference done 517/1210. 0.0474 s / img. ETA=0:03:12
[03/28 12:10:39] d2.evaluation.evaluator INFO: Inference done 534/1210. 0.0474 s / img. ETA=0:03:08
[03/28 12:10:44] d2.evaluation.evaluator INFO: Inference done 558/1210. 0.0474 s / img. ETA=0:02:59
[03/28 12:10:50] d2.evaluation.evaluator INFO: Inference done 577/1210. 0.0474 s / img. ETA=0:02:55
[03/28 12:10:55] d2.evaluation.evaluator INFO: Inference done 593/1210. 0.0473 s / img. ETA=0:02:51
[03/28 12:11:00] d2.evaluation.evaluator INFO: Inference done 616/1210. 0.0473 s / img. ETA=0:02:43
[03/28 12:11:05] d2.evaluation.evaluator INFO: Inference done 641/1210. 0.0472 s / img. ETA=0:02:35
[03/28 12:11:10] d2.evaluation.evaluator INFO: Inference done 667/1210. 0.0471 s / img. ETA=0:02:26
[03/28 12:11:15] d2.evaluation.evaluator INFO: Inference done 688/1210. 0.0471 s / img. ETA=0:02:20
[03/28 12:11:21] d2.evaluation.evaluator INFO: Inference done 703/1210. 0.0470 s / img. ETA=0:02:17
[03/28 12:11:26] d2.evaluation.evaluator INFO: Inference done 722/1210. 0.0469 s / img. ETA=0:02:12
[03/28 12:11:31] d2.evaluation.evaluator INFO: Inference done 748/1210. 0.0470 s / img. ETA=0:02:04
[03/28 12:11:36] d2.evaluation.evaluator INFO: Inference done 769/1210. 0.0472 s / img. ETA=0:01:58
[03/28 12:11:42] d2.evaluation.evaluator INFO: Inference done 790/1210. 0.0472 s / img. ETA=0:01:52
[03/28 12:11:47] d2.evaluation.evaluator INFO: Inference done 804/1210. 0.0472 s / img. ETA=0:01:49
[03/28 12:11:52] d2.evaluation.evaluator INFO: Inference done 819/1210. 0.0472 s / img. ETA=0:01:45
[03/28 12:12:01] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0472 s / img. ETA=0:01:48
[03/28 12:12:06] d2.evaluation.evaluator INFO: Inference done 842/1210. 0.0473 s / img. ETA=0:01:43
[03/28 12:12:11] d2.evaluation.evaluator INFO: Inference done 861/1210. 0.0473 s / img. ETA=0:01:37
[03/28 12:12:17] d2.evaluation.evaluator INFO: Inference done 864/1210. 0.0473 s / img. ETA=0:01:38
[03/28 12:12:22] d2.evaluation.evaluator INFO: Inference done 885/1210. 0.0474 s / img. ETA=0:01:32
[03/28 12:12:27] d2.evaluation.evaluator INFO: Inference done 907/1210. 0.0475 s / img. ETA=0:01:25
[03/28 12:12:37] d2.evaluation.evaluator INFO: Inference done 923/1210. 0.0475 s / img. ETA=0:01:22
[03/28 12:12:42] d2.evaluation.evaluator INFO: Inference done 944/1210. 0.0475 s / img. ETA=0:01:16
[03/28 12:12:48] d2.evaluation.evaluator INFO: Inference done 966/1210. 0.0475 s / img. ETA=0:01:10
[03/28 12:12:53] d2.evaluation.evaluator INFO: Inference done 987/1210. 0.0476 s / img. ETA=0:01:03
[03/28 12:12:58] d2.evaluation.evaluator INFO: Inference done 1000/1210. 0.0476 s / img. ETA=0:01:00
[03/28 12:13:03] d2.evaluation.evaluator INFO: Inference done 1017/1210. 0.0476 s / img. ETA=0:00:55
[03/28 12:13:08] d2.evaluation.evaluator INFO: Inference done 1035/1210. 0.0478 s / img. ETA=0:00:50
[03/28 12:13:13] d2.evaluation.evaluator INFO: Inference done 1056/1210. 0.0478 s / img. ETA=0:00:44
[03/28 12:13:18] d2.evaluation.evaluator INFO: Inference done 1079/1210. 0.0479 s / img. ETA=0:00:37
[03/28 12:13:23] d2.evaluation.evaluator INFO: Inference done 1097/1210. 0.0479 s / img. ETA=0:00:32
[03/28 12:13:29] d2.evaluation.evaluator INFO: Inference done 1119/1210. 0.0479 s / img. ETA=0:00:25
[03/28 12:13:34] d2.evaluation.evaluator INFO: Inference done 1140/1210. 0.0480 s / img. ETA=0:00:19
[03/28 12:13:39] d2.evaluation.evaluator INFO: Inference done 1160/1210. 0.0480 s / img. ETA=0:00:14
[03/28 12:13:44] d2.evaluation.evaluator INFO: Inference done 1179/1210. 0.0480 s / img. ETA=0:00:08
[03/28 12:13:49] d2.evaluation.evaluator INFO: Inference done 1195/1210. 0.0480 s / img. ETA=0:00:04
[03/28 12:13:54] d2.evaluation.evaluator INFO: Total inference time: 0:05:42.253324 (0.284028 s / img per device, on 1 devices)
[03/28 12:13:54] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:57 (0.048025 s / img per device, on 1 devices)
[03/28 12:13:54] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/28 12:13:54] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/28 12:13:54] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/28 12:13:56] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.489 | 59.235 | 51.244 | 31.748 | 14.749 | 39.248 |
[03/28 12:13:56] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/28 12:13:56] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/28 12:13:56] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/28 12:13:56] d2.evaluation.testing INFO: copypaste: 41.4889,59.2353,51.2444,31.7477,14.7495,39.2480
[03/28 12:13:56] d2.utils.events INFO:  eta: 7:17:08  iter: 1999  total_loss: 0.156  loss_cls: 0.053  loss_box_reg: 0.054  loss_rpn_cls: 0.008  loss_rpn_loc: 0.025  time: 1.8974  data_time: 1.2101  lr: 0.001000  max_mem: 9421M
[03/28 12:14:43] d2.utils.events INFO:  eta: 7:16:18  iter: 2019  total_loss: 0.167  loss_cls: 0.062  loss_box_reg: 0.058  loss_rpn_cls: 0.012  loss_rpn_loc: 0.033  time: 1.9017  data_time: 1.7378  lr: 0.001000  max_mem: 9421M
[03/28 12:15:23] d2.utils.events INFO:  eta: 7:16:48  iter: 2039  total_loss: 0.162  loss_cls: 0.058  loss_box_reg: 0.059  loss_rpn_cls: 0.014  loss_rpn_loc: 0.023  time: 1.9030  data_time: 1.4718  lr: 0.001000  max_mem: 9421M
[03/28 12:16:00] d2.utils.events INFO:  eta: 7:17:03  iter: 2059  total_loss: 0.128  loss_cls: 0.052  loss_box_reg: 0.054  loss_rpn_cls: 0.007  loss_rpn_loc: 0.020  time: 1.9024  data_time: 1.2691  lr: 0.001000  max_mem: 9421M
[03/28 12:16:54] d2.utils.events INFO:  eta: 7:18:43  iter: 2079  total_loss: 0.143  loss_cls: 0.056  loss_box_reg: 0.053  loss_rpn_cls: 0.012  loss_rpn_loc: 0.025  time: 1.9100  data_time: 2.1170  lr: 0.001000  max_mem: 9421M
[03/28 12:17:33] d2.utils.events INFO:  eta: 7:19:22  iter: 2099  total_loss: 0.142  loss_cls: 0.055  loss_box_reg: 0.049  loss_rpn_cls: 0.009  loss_rpn_loc: 0.024  time: 1.9102  data_time: 1.3873  lr: 0.001000  max_mem: 9421M
[03/28 12:18:14] d2.utils.events INFO:  eta: 7:18:22  iter: 2119  total_loss: 0.166  loss_cls: 0.059  loss_box_reg: 0.060  loss_rpn_cls: 0.010  loss_rpn_loc: 0.033  time: 1.9117  data_time: 1.5025  lr: 0.001000  max_mem: 9421M
[03/28 12:19:04] d2.utils.events INFO:  eta: 7:21:06  iter: 2139  total_loss: 0.162  loss_cls: 0.067  loss_box_reg: 0.055  loss_rpn_cls: 0.010  loss_rpn_loc: 0.021  time: 1.9170  data_time: 1.9173  lr: 0.001000  max_mem: 9421M
[03/28 12:19:39] d2.utils.events INFO:  eta: 7:19:24  iter: 2159  total_loss: 0.149  loss_cls: 0.049  loss_box_reg: 0.053  loss_rpn_cls: 0.011  loss_rpn_loc: 0.025  time: 1.9156  data_time: 1.2047  lr: 0.001000  max_mem: 9421M
[03/28 12:20:12] d2.utils.events INFO:  eta: 7:17:10  iter: 2179  total_loss: 0.172  loss_cls: 0.062  loss_box_reg: 0.056  loss_rpn_cls: 0.013  loss_rpn_loc: 0.031  time: 1.9133  data_time: 1.0822  lr: 0.001000  max_mem: 9421M
[03/28 12:20:52] d2.utils.events INFO:  eta: 7:16:45  iter: 2199  total_loss: 0.150  loss_cls: 0.056  loss_box_reg: 0.059  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9139  data_time: 1.4145  lr: 0.001000  max_mem: 9421M
[03/28 12:21:36] d2.utils.events INFO:  eta: 7:19:00  iter: 2219  total_loss: 0.141  loss_cls: 0.055  loss_box_reg: 0.054  loss_rpn_cls: 0.008  loss_rpn_loc: 0.020  time: 1.9167  data_time: 1.6736  lr: 0.001000  max_mem: 9421M
[03/28 12:22:21] d2.utils.events INFO:  eta: 7:21:58  iter: 2239  total_loss: 0.170  loss_cls: 0.063  loss_box_reg: 0.062  loss_rpn_cls: 0.011  loss_rpn_loc: 0.028  time: 1.9195  data_time: 1.6847  lr: 0.001000  max_mem: 9421M
[03/28 12:23:00] d2.utils.events INFO:  eta: 7:19:48  iter: 2259  total_loss: 0.139  loss_cls: 0.054  loss_box_reg: 0.052  loss_rpn_cls: 0.008  loss_rpn_loc: 0.026  time: 1.9197  data_time: 1.3813  lr: 0.001000  max_mem: 9421M
[03/28 12:23:41] d2.utils.events INFO:  eta: 7:20:54  iter: 2279  total_loss: 0.147  loss_cls: 0.053  loss_box_reg: 0.059  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9209  data_time: 1.4692  lr: 0.001000  max_mem: 9421M
[03/28 12:24:22] d2.utils.events INFO:  eta: 7:20:20  iter: 2299  total_loss: 0.144  loss_cls: 0.058  loss_box_reg: 0.056  loss_rpn_cls: 0.009  loss_rpn_loc: 0.018  time: 1.9203  data_time: 1.2752  lr: 0.001000  max_mem: 9421M
[03/28 12:24:54] d2.utils.events INFO:  eta: 7:19:46  iter: 2319  total_loss: 0.160  loss_cls: 0.060  loss_box_reg: 0.056  loss_rpn_cls: 0.012  loss_rpn_loc: 0.027  time: 1.9175  data_time: 1.0564  lr: 0.001000  max_mem: 9421M
[03/28 12:25:43] d2.utils.events INFO:  eta: 7:20:21  iter: 2339  total_loss: 0.144  loss_cls: 0.055  loss_box_reg: 0.057  loss_rpn_cls: 0.009  loss_rpn_loc: 0.023  time: 1.9220  data_time: 1.8569  lr: 0.001000  max_mem: 9421M
[03/28 12:26:28] d2.utils.events INFO:  eta: 7:21:48  iter: 2359  total_loss: 0.146  loss_cls: 0.046  loss_box_reg: 0.052  loss_rpn_cls: 0.010  loss_rpn_loc: 0.020  time: 1.9246  data_time: 1.6648  lr: 0.001000  max_mem: 9421M
[03/28 12:27:05] d2.utils.events INFO:  eta: 7:21:35  iter: 2379  total_loss: 0.155  loss_cls: 0.056  loss_box_reg: 0.058  loss_rpn_cls: 0.010  loss_rpn_loc: 0.025  time: 1.9239  data_time: 1.2731  lr: 0.001000  max_mem: 9421M
[03/28 12:27:40] d2.utils.events INFO:  eta: 7:20:41  iter: 2399  total_loss: 0.150  loss_cls: 0.059  loss_box_reg: 0.058  loss_rpn_cls: 0.009  loss_rpn_loc: 0.026  time: 1.9224  data_time: 1.2029  lr: 0.001000  max_mem: 9421M
[03/28 12:28:20] d2.utils.events INFO:  eta: 7:20:56  iter: 2419  total_loss: 0.146  loss_cls: 0.059  loss_box_reg: 0.053  loss_rpn_cls: 0.010  loss_rpn_loc: 0.019  time: 1.9232  data_time: 1.4640  lr: 0.001000  max_mem: 9421M
[03/28 12:29:02] d2.utils.events INFO:  eta: 7:20:08  iter: 2439  total_loss: 0.145  loss_cls: 0.052  loss_box_reg: 0.055  loss_rpn_cls: 0.011  loss_rpn_loc: 0.024  time: 1.9244  data_time: 1.5047  lr: 0.001000  max_mem: 9421M
[03/28 12:29:39] d2.utils.events INFO:  eta: 7:19:55  iter: 2459  total_loss: 0.175  loss_cls: 0.060  loss_box_reg: 0.060  loss_rpn_cls: 0.010  loss_rpn_loc: 0.027  time: 1.9238  data_time: 1.2907  lr: 0.001000  max_mem: 9421M
[03/28 12:30:13] d2.utils.events INFO:  eta: 7:19:00  iter: 2479  total_loss: 0.173  loss_cls: 0.067  loss_box_reg: 0.061  loss_rpn_cls: 0.013  loss_rpn_loc: 0.036  time: 1.9223  data_time: 1.1936  lr: 0.001000  max_mem: 9421M
[03/28 12:30:53] d2.utils.events INFO:  eta: 7:18:53  iter: 2499  total_loss: 0.149  loss_cls: 0.056  loss_box_reg: 0.056  loss_rpn_cls: 0.009  loss_rpn_loc: 0.028  time: 1.9230  data_time: 1.4242  lr: 0.001000  max_mem: 9421M
[03/28 12:31:31] d2.utils.events INFO:  eta: 7:19:30  iter: 2519  total_loss: 0.152  loss_cls: 0.057  loss_box_reg: 0.057  loss_rpn_cls: 0.011  loss_rpn_loc: 0.029  time: 1.9227  data_time: 1.3349  lr: 0.001000  max_mem: 9421M
[03/28 12:32:07] d2.utils.events INFO:  eta: 7:17:45  iter: 2539  total_loss: 0.148  loss_cls: 0.058  loss_box_reg: 0.062  loss_rpn_cls: 0.011  loss_rpn_loc: 0.021  time: 1.9217  data_time: 1.1932  lr: 0.001000  max_mem: 9421M
[03/28 12:32:51] d2.utils.events INFO:  eta: 7:17:05  iter: 2559  total_loss: 0.146  loss_cls: 0.055  loss_box_reg: 0.051  loss_rpn_cls: 0.011  loss_rpn_loc: 0.024  time: 1.9237  data_time: 1.6220  lr: 0.001000  max_mem: 9421M
[03/28 12:33:25] d2.utils.events INFO:  eta: 7:17:28  iter: 2579  total_loss: 0.151  loss_cls: 0.056  loss_box_reg: 0.057  loss_rpn_cls: 0.007  loss_rpn_loc: 0.021  time: 1.9219  data_time: 1.1597  lr: 0.001000  max_mem: 9421M
[03/28 12:34:13] d2.utils.events INFO:  eta: 7:17:59  iter: 2599  total_loss: 0.147  loss_cls: 0.055  loss_box_reg: 0.056  loss_rpn_cls: 0.009  loss_rpn_loc: 0.024  time: 1.9256  data_time: 1.8395  lr: 0.001000  max_mem: 9421M
[03/28 12:34:54] d2.utils.events INFO:  eta: 7:17:24  iter: 2619  total_loss: 0.135  loss_cls: 0.046  loss_box_reg: 0.049  loss_rpn_cls: 0.008  loss_rpn_loc: 0.022  time: 1.9268  data_time: 1.5166  lr: 0.001000  max_mem: 9421M
[03/28 12:35:34] d2.utils.events INFO:  eta: 7:16:50  iter: 2639  total_loss: 0.139  loss_cls: 0.056  loss_box_reg: 0.052  loss_rpn_cls: 0.009  loss_rpn_loc: 0.017  time: 1.9271  data_time: 1.4159  lr: 0.001000  max_mem: 9421M
[03/28 12:36:15] d2.utils.events INFO:  eta: 7:18:08  iter: 2659  total_loss: 0.148  loss_cls: 0.054  loss_box_reg: 0.054  loss_rpn_cls: 0.010  loss_rpn_loc: 0.025  time: 1.9282  data_time: 1.5020  lr: 0.001000  max_mem: 9421M
[03/28 12:36:58] d2.utils.events INFO:  eta: 7:18:40  iter: 2679  total_loss: 0.139  loss_cls: 0.054  loss_box_reg: 0.056  loss_rpn_cls: 0.008  loss_rpn_loc: 0.018  time: 1.9299  data_time: 1.5709  lr: 0.001000  max_mem: 9421M
[03/28 12:37:35] d2.utils.events INFO:  eta: 7:18:06  iter: 2699  total_loss: 0.164  loss_cls: 0.066  loss_box_reg: 0.060  loss_rpn_cls: 0.010  loss_rpn_loc: 0.019  time: 1.9292  data_time: 1.2616  lr: 0.001000  max_mem: 9421M
[03/28 12:38:19] d2.utils.events INFO:  eta: 7:20:24  iter: 2719  total_loss: 0.155  loss_cls: 0.061  loss_box_reg: 0.059  loss_rpn_cls: 0.009  loss_rpn_loc: 0.025  time: 1.9313  data_time: 1.6287  lr: 0.001000  max_mem: 9421M
[03/28 12:39:02] d2.utils.events INFO:  eta: 7:19:32  iter: 2739  total_loss: 0.141  loss_cls: 0.052  loss_box_reg: 0.055  loss_rpn_cls: 0.008  loss_rpn_loc: 0.019  time: 1.9326  data_time: 1.5601  lr: 0.001000  max_mem: 9421M
[03/28 12:39:51] d2.utils.events INFO:  eta: 7:17:36  iter: 2759  total_loss: 0.161  loss_cls: 0.061  loss_box_reg: 0.064  loss_rpn_cls: 0.009  loss_rpn_loc: 0.021  time: 1.9363  data_time: 1.8806  lr: 0.001000  max_mem: 9421M
[03/28 12:40:26] d2.utils.events INFO:  eta: 7:14:38  iter: 2779  total_loss: 0.147  loss_cls: 0.055  loss_box_reg: 0.053  loss_rpn_cls: 0.009  loss_rpn_loc: 0.027  time: 1.9352  data_time: 1.2213  lr: 0.001000  max_mem: 9421M
[03/28 12:41:04] d2.utils.events INFO:  eta: 7:15:14  iter: 2799  total_loss: 0.146  loss_cls: 0.052  loss_box_reg: 0.055  loss_rpn_cls: 0.009  loss_rpn_loc: 0.025  time: 1.9347  data_time: 1.2924  lr: 0.001000  max_mem: 9421M
[03/28 12:41:45] d2.utils.events INFO:  eta: 7:12:31  iter: 2819  total_loss: 0.152  loss_cls: 0.054  loss_box_reg: 0.056  loss_rpn_cls: 0.009  loss_rpn_loc: 0.021  time: 1.9356  data_time: 1.4773  lr: 0.001000  max_mem: 9421M
[03/28 12:42:29] d2.utils.events INFO:  eta: 7:15:12  iter: 2839  total_loss: 0.160  loss_cls: 0.056  loss_box_reg: 0.051  loss_rpn_cls: 0.009  loss_rpn_loc: 0.027  time: 1.9376  data_time: 1.6376  lr: 0.001000  max_mem: 9421M
[03/28 12:43:06] d2.utils.events INFO:  eta: 7:15:33  iter: 2859  total_loss: 0.162  loss_cls: 0.062  loss_box_reg: 0.056  loss_rpn_cls: 0.010  loss_rpn_loc: 0.026  time: 1.9370  data_time: 1.2876  lr: 0.001000  max_mem: 9421M
[03/28 12:43:42] d2.utils.events INFO:  eta: 7:15:47  iter: 2879  total_loss: 0.146  loss_cls: 0.055  loss_box_reg: 0.056  loss_rpn_cls: 0.010  loss_rpn_loc: 0.023  time: 1.9359  data_time: 1.1910  lr: 0.001000  max_mem: 9421M
[03/28 12:44:29] d2.utils.events INFO:  eta: 7:15:49  iter: 2899  total_loss: 0.162  loss_cls: 0.060  loss_box_reg: 0.058  loss_rpn_cls: 0.010  loss_rpn_loc: 0.024  time: 1.9389  data_time: 1.8039  lr: 0.001000  max_mem: 9421M
[03/28 12:45:11] d2.utils.events INFO:  eta: 7:14:48  iter: 2919  total_loss: 0.155  loss_cls: 0.057  loss_box_reg: 0.057  loss_rpn_cls: 0.009  loss_rpn_loc: 0.030  time: 1.9397  data_time: 1.4951  lr: 0.001000  max_mem: 9421M
[03/28 12:45:45] d2.utils.events INFO:  eta: 7:14:20  iter: 2939  total_loss: 0.141  loss_cls: 0.054  loss_box_reg: 0.049  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9383  data_time: 1.1609  lr: 0.001000  max_mem: 9421M
[03/28 12:46:21] d2.utils.events INFO:  eta: 7:13:58  iter: 2959  total_loss: 0.136  loss_cls: 0.048  loss_box_reg: 0.058  loss_rpn_cls: 0.008  loss_rpn_loc: 0.018  time: 1.9371  data_time: 1.2104  lr: 0.001000  max_mem: 9421M
[03/28 12:47:02] d2.utils.events INFO:  eta: 7:14:04  iter: 2979  total_loss: 0.160  loss_cls: 0.062  loss_box_reg: 0.057  loss_rpn_cls: 0.009  loss_rpn_loc: 0.021  time: 1.9380  data_time: 1.4847  lr: 0.001000  max_mem: 9421M
[03/28 12:47:39] d2.utils.events INFO:  eta: 7:14:37  iter: 2999  total_loss: 0.145  loss_cls: 0.056  loss_box_reg: 0.062  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9373  data_time: 1.2949  lr: 0.001000  max_mem: 9421M
[03/28 12:48:16] d2.utils.events INFO:  eta: 7:15:14  iter: 3019  total_loss: 0.150  loss_cls: 0.061  loss_box_reg: 0.059  loss_rpn_cls: 0.008  loss_rpn_loc: 0.024  time: 1.9367  data_time: 1.2942  lr: 0.001000  max_mem: 9421M
[03/28 12:48:56] d2.utils.events INFO:  eta: 7:11:46  iter: 3039  total_loss: 0.147  loss_cls: 0.056  loss_box_reg: 0.056  loss_rpn_cls: 0.006  loss_rpn_loc: 0.022  time: 1.9372  data_time: 1.4615  lr: 0.001000  max_mem: 9421M
[03/28 12:49:41] d2.utils.events INFO:  eta: 7:10:52  iter: 3059  total_loss: 0.145  loss_cls: 0.054  loss_box_reg: 0.057  loss_rpn_cls: 0.008  loss_rpn_loc: 0.030  time: 1.9392  data_time: 1.6776  lr: 0.001000  max_mem: 9421M
[03/28 12:50:19] d2.utils.events INFO:  eta: 7:06:04  iter: 3079  total_loss: 0.154  loss_cls: 0.056  loss_box_reg: 0.052  loss_rpn_cls: 0.009  loss_rpn_loc: 0.023  time: 1.9389  data_time: 1.3351  lr: 0.001000  max_mem: 9421M
[03/28 12:51:07] d2.utils.events INFO:  eta: 7:04:33  iter: 3099  total_loss: 0.145  loss_cls: 0.061  loss_box_reg: 0.067  loss_rpn_cls: 0.009  loss_rpn_loc: 0.020  time: 1.9417  data_time: 1.8129  lr: 0.001000  max_mem: 9421M
[03/28 12:51:48] d2.utils.events INFO:  eta: 7:08:04  iter: 3119  total_loss: 0.146  loss_cls: 0.054  loss_box_reg: 0.058  loss_rpn_cls: 0.008  loss_rpn_loc: 0.021  time: 1.9425  data_time: 1.5078  lr: 0.001000  max_mem: 9421M
[03/28 12:52:26] d2.utils.events INFO:  eta: 7:05:54  iter: 3139  total_loss: 0.125  loss_cls: 0.049  loss_box_reg: 0.046  loss_rpn_cls: 0.007  loss_rpn_loc: 0.019  time: 1.9423  data_time: 1.3526  lr: 0.001000  max_mem: 9421M
[03/28 12:53:01] d2.utils.events INFO:  eta: 7:05:20  iter: 3159  total_loss: 0.151  loss_cls: 0.055  loss_box_reg: 0.059  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9410  data_time: 1.1639  lr: 0.001000  max_mem: 9421M
[03/28 12:53:49] d2.utils.events INFO:  eta: 7:07:22  iter: 3179  total_loss: 0.151  loss_cls: 0.052  loss_box_reg: 0.050  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9439  data_time: 1.7958  lr: 0.001000  max_mem: 9421M
[03/28 12:54:32] d2.utils.events INFO:  eta: 7:06:56  iter: 3199  total_loss: 0.158  loss_cls: 0.057  loss_box_reg: 0.058  loss_rpn_cls: 0.009  loss_rpn_loc: 0.025  time: 1.9452  data_time: 1.5932  lr: 0.001000  max_mem: 9421M
[03/28 12:55:12] d2.utils.events INFO:  eta: 7:05:24  iter: 3219  total_loss: 0.142  loss_cls: 0.058  loss_box_reg: 0.059  loss_rpn_cls: 0.009  loss_rpn_loc: 0.020  time: 1.9457  data_time: 1.4583  lr: 0.001000  max_mem: 9421M
[03/28 12:55:57] d2.utils.events INFO:  eta: 7:04:50  iter: 3239  total_loss: 0.156  loss_cls: 0.058  loss_box_reg: 0.059  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9474  data_time: 1.6583  lr: 0.001000  max_mem: 9421M
[03/28 12:56:34] d2.utils.events INFO:  eta: 7:04:30  iter: 3259  total_loss: 0.149  loss_cls: 0.053  loss_box_reg: 0.058  loss_rpn_cls: 0.007  loss_rpn_loc: 0.025  time: 1.9467  data_time: 1.2648  lr: 0.001000  max_mem: 9421M
[03/28 12:57:10] d2.utils.events INFO:  eta: 7:03:41  iter: 3279  total_loss: 0.150  loss_cls: 0.061  loss_box_reg: 0.055  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9460  data_time: 1.2545  lr: 0.001000  max_mem: 9421M
[03/28 12:57:57] d2.utils.events INFO:  eta: 7:03:21  iter: 3299  total_loss: 0.165  loss_cls: 0.061  loss_box_reg: 0.061  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9485  data_time: 1.7921  lr: 0.001000  max_mem: 9421M
[03/28 12:58:41] d2.utils.events INFO:  eta: 7:03:39  iter: 3319  total_loss: 0.121  loss_cls: 0.047  loss_box_reg: 0.048  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 1.9499  data_time: 1.6392  lr: 0.001000  max_mem: 9421M
[03/28 12:59:21] d2.utils.events INFO:  eta: 7:05:10  iter: 3339  total_loss: 0.174  loss_cls: 0.062  loss_box_reg: 0.057  loss_rpn_cls: 0.012  loss_rpn_loc: 0.026  time: 1.9501  data_time: 1.4045  lr: 0.001000  max_mem: 9421M
[03/28 12:59:56] d2.utils.events INFO:  eta: 7:02:30  iter: 3359  total_loss: 0.134  loss_cls: 0.053  loss_box_reg: 0.059  loss_rpn_cls: 0.008  loss_rpn_loc: 0.025  time: 1.9491  data_time: 1.2059  lr: 0.001000  max_mem: 9421M
[03/28 13:00:40] d2.utils.events INFO:  eta: 7:04:00  iter: 3379  total_loss: 0.157  loss_cls: 0.057  loss_box_reg: 0.060  loss_rpn_cls: 0.008  loss_rpn_loc: 0.030  time: 1.9505  data_time: 1.5968  lr: 0.001000  max_mem: 9421M
[03/28 13:01:23] d2.utils.events INFO:  eta: 7:04:15  iter: 3399  total_loss: 0.161  loss_cls: 0.056  loss_box_reg: 0.062  loss_rpn_cls: 0.008  loss_rpn_loc: 0.021  time: 1.9516  data_time: 1.5619  lr: 0.001000  max_mem: 9421M
[03/28 13:02:00] d2.utils.events INFO:  eta: 7:04:26  iter: 3419  total_loss: 0.150  loss_cls: 0.058  loss_box_reg: 0.060  loss_rpn_cls: 0.008  loss_rpn_loc: 0.021  time: 1.9509  data_time: 1.2653  lr: 0.001000  max_mem: 9421M
[03/28 13:02:39] d2.utils.events INFO:  eta: 7:03:51  iter: 3439  total_loss: 0.160  loss_cls: 0.065  loss_box_reg: 0.059  loss_rpn_cls: 0.007  loss_rpn_loc: 0.019  time: 1.9511  data_time: 1.4239  lr: 0.001000  max_mem: 9421M
[03/28 13:03:23] d2.utils.events INFO:  eta: 7:03:42  iter: 3459  total_loss: 0.144  loss_cls: 0.056  loss_box_reg: 0.055  loss_rpn_cls: 0.006  loss_rpn_loc: 0.017  time: 1.9525  data_time: 1.6341  lr: 0.001000  max_mem: 9421M
[03/28 13:04:02] d2.utils.events INFO:  eta: 7:03:07  iter: 3479  total_loss: 0.143  loss_cls: 0.053  loss_box_reg: 0.058  loss_rpn_cls: 0.009  loss_rpn_loc: 0.024  time: 1.9525  data_time: 1.3842  lr: 0.001000  max_mem: 9421M
[03/28 13:04:45] d2.utils.events INFO:  eta: 7:01:21  iter: 3499  total_loss: 0.160  loss_cls: 0.060  loss_box_reg: 0.056  loss_rpn_cls: 0.008  loss_rpn_loc: 0.021  time: 1.9535  data_time: 1.5700  lr: 0.001000  max_mem: 9421M
[03/28 13:05:21] d2.utils.events INFO:  eta: 7:00:02  iter: 3519  total_loss: 0.159  loss_cls: 0.063  loss_box_reg: 0.062  loss_rpn_cls: 0.009  loss_rpn_loc: 0.021  time: 1.9526  data_time: 1.2263  lr: 0.001000  max_mem: 9421M
[03/28 13:05:57] d2.utils.events INFO:  eta: 7:00:38  iter: 3539  total_loss: 0.138  loss_cls: 0.051  loss_box_reg: 0.058  loss_rpn_cls: 0.009  loss_rpn_loc: 0.024  time: 1.9518  data_time: 1.2308  lr: 0.001000  max_mem: 9421M
[03/28 13:06:42] d2.utils.events INFO:  eta: 7:00:47  iter: 3559  total_loss: 0.146  loss_cls: 0.053  loss_box_reg: 0.054  loss_rpn_cls: 0.010  loss_rpn_loc: 0.021  time: 1.9534  data_time: 1.6953  lr: 0.001000  max_mem: 9421M
[03/28 13:07:19] d2.utils.events INFO:  eta: 7:00:12  iter: 3579  total_loss: 0.143  loss_cls: 0.055  loss_box_reg: 0.059  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 1.9528  data_time: 1.2560  lr: 0.001000  max_mem: 9421M
[03/28 13:07:53] d2.utils.events INFO:  eta: 6:57:43  iter: 3599  total_loss: 0.140  loss_cls: 0.044  loss_box_reg: 0.058  loss_rpn_cls: 0.007  loss_rpn_loc: 0.021  time: 1.9514  data_time: 1.1341  lr: 0.001000  max_mem: 9421M
[03/28 13:08:31] d2.utils.events INFO:  eta: 6:57:57  iter: 3619  total_loss: 0.152  loss_cls: 0.054  loss_box_reg: 0.060  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 1.9512  data_time: 1.3338  lr: 0.001000  max_mem: 9421M
[03/28 13:09:09] d2.utils.events INFO:  eta: 6:58:27  iter: 3639  total_loss: 0.157  loss_cls: 0.057  loss_box_reg: 0.057  loss_rpn_cls: 0.009  loss_rpn_loc: 0.026  time: 1.9508  data_time: 1.2855  lr: 0.001000  max_mem: 9421M
[03/28 13:09:46] d2.utils.events INFO:  eta: 6:56:47  iter: 3659  total_loss: 0.158  loss_cls: 0.055  loss_box_reg: 0.058  loss_rpn_cls: 0.007  loss_rpn_loc: 0.021  time: 1.9503  data_time: 1.3066  lr: 0.001000  max_mem: 9421M
[03/28 13:10:26] d2.utils.events INFO:  eta: 6:55:23  iter: 3679  total_loss: 0.137  loss_cls: 0.048  loss_box_reg: 0.055  loss_rpn_cls: 0.007  loss_rpn_loc: 0.017  time: 1.9507  data_time: 1.4480  lr: 0.001000  max_mem: 9421M
[03/28 13:11:11] d2.utils.events INFO:  eta: 6:55:37  iter: 3699  total_loss: 0.144  loss_cls: 0.057  loss_box_reg: 0.058  loss_rpn_cls: 0.010  loss_rpn_loc: 0.021  time: 1.9521  data_time: 1.6357  lr: 0.001000  max_mem: 9421M
[03/28 13:11:56] d2.utils.events INFO:  eta: 6:54:36  iter: 3719  total_loss: 0.123  loss_cls: 0.044  loss_box_reg: 0.051  loss_rpn_cls: 0.009  loss_rpn_loc: 0.020  time: 1.9535  data_time: 1.6678  lr: 0.001000  max_mem: 9421M
[03/28 13:12:29] d2.utils.events INFO:  eta: 6:53:23  iter: 3739  total_loss: 0.140  loss_cls: 0.053  loss_box_reg: 0.058  loss_rpn_cls: 0.008  loss_rpn_loc: 0.018  time: 1.9518  data_time: 1.0461  lr: 0.001000  max_mem: 9421M
[03/28 13:13:07] d2.utils.events INFO:  eta: 6:53:04  iter: 3759  total_loss: 0.133  loss_cls: 0.048  loss_box_reg: 0.053  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9514  data_time: 1.3135  lr: 0.001000  max_mem: 9421M
[03/28 13:13:56] d2.utils.events INFO:  eta: 6:52:29  iter: 3779  total_loss: 0.142  loss_cls: 0.048  loss_box_reg: 0.053  loss_rpn_cls: 0.009  loss_rpn_loc: 0.023  time: 1.9541  data_time: 1.8932  lr: 0.001000  max_mem: 9421M
[03/28 13:14:34] d2.utils.events INFO:  eta: 6:51:39  iter: 3799  total_loss: 0.149  loss_cls: 0.059  loss_box_reg: 0.057  loss_rpn_cls: 0.010  loss_rpn_loc: 0.025  time: 1.9539  data_time: 1.3636  lr: 0.001000  max_mem: 9421M
[03/28 13:15:11] d2.utils.events INFO:  eta: 6:51:42  iter: 3819  total_loss: 0.140  loss_cls: 0.050  loss_box_reg: 0.053  loss_rpn_cls: 0.008  loss_rpn_loc: 0.024  time: 1.9534  data_time: 1.3071  lr: 0.001000  max_mem: 9421M
[03/28 13:15:50] d2.utils.events INFO:  eta: 6:50:45  iter: 3839  total_loss: 0.152  loss_cls: 0.062  loss_box_reg: 0.057  loss_rpn_cls: 0.007  loss_rpn_loc: 0.024  time: 1.9532  data_time: 1.3503  lr: 0.001000  max_mem: 9421M
[03/28 13:16:29] d2.utils.events INFO:  eta: 6:50:10  iter: 3859  total_loss: 0.171  loss_cls: 0.056  loss_box_reg: 0.062  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9534  data_time: 1.4311  lr: 0.001000  max_mem: 9421M
[03/28 13:17:10] d2.utils.events INFO:  eta: 6:49:35  iter: 3879  total_loss: 0.160  loss_cls: 0.062  loss_box_reg: 0.061  loss_rpn_cls: 0.008  loss_rpn_loc: 0.024  time: 1.9537  data_time: 1.4444  lr: 0.001000  max_mem: 9421M
[03/28 13:17:43] d2.utils.events INFO:  eta: 6:47:01  iter: 3899  total_loss: 0.139  loss_cls: 0.053  loss_box_reg: 0.055  loss_rpn_cls: 0.009  loss_rpn_loc: 0.021  time: 1.9521  data_time: 1.0775  lr: 0.001000  max_mem: 9421M
[03/28 13:18:21] d2.utils.events INFO:  eta: 6:47:30  iter: 3919  total_loss: 0.143  loss_cls: 0.049  loss_box_reg: 0.060  loss_rpn_cls: 0.006  loss_rpn_loc: 0.024  time: 1.9520  data_time: 1.3331  lr: 0.001000  max_mem: 9421M
[03/28 13:19:08] d2.utils.events INFO:  eta: 6:47:20  iter: 3939  total_loss: 0.140  loss_cls: 0.052  loss_box_reg: 0.060  loss_rpn_cls: 0.006  loss_rpn_loc: 0.022  time: 1.9540  data_time: 1.7534  lr: 0.001000  max_mem: 9421M
[03/28 13:19:49] d2.utils.events INFO:  eta: 6:47:01  iter: 3959  total_loss: 0.132  loss_cls: 0.055  loss_box_reg: 0.052  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9543  data_time: 1.4580  lr: 0.001000  max_mem: 9421M
[03/28 13:20:28] d2.utils.events INFO:  eta: 6:46:10  iter: 3979  total_loss: 0.143  loss_cls: 0.055  loss_box_reg: 0.065  loss_rpn_cls: 0.007  loss_rpn_loc: 0.017  time: 1.9545  data_time: 1.4276  lr: 0.001000  max_mem: 9421M
[03/28 13:21:05] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/lr0.001_finetune/model_0003999.pth
[03/28 13:21:09] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/28 13:21:09] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/28 13:21:09] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/28 13:21:09] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/28 13:21:11] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0476 s / img. ETA=0:02:39
[03/28 13:21:16] d2.evaluation.evaluator INFO: Inference done 28/1210. 0.0461 s / img. ETA=0:04:58
[03/28 13:21:21] d2.evaluation.evaluator INFO: Inference done 54/1210. 0.0466 s / img. ETA=0:04:23
[03/28 13:21:26] d2.evaluation.evaluator INFO: Inference done 74/1210. 0.0461 s / img. ETA=0:04:27
[03/28 13:21:31] d2.evaluation.evaluator INFO: Inference done 88/1210. 0.0462 s / img. ETA=0:04:48
[03/28 13:21:36] d2.evaluation.evaluator INFO: Inference done 110/1210. 0.0465 s / img. ETA=0:04:37
[03/28 13:21:43] d2.evaluation.evaluator INFO: Inference done 119/1210. 0.0468 s / img. ETA=0:05:18
[03/28 13:21:48] d2.evaluation.evaluator INFO: Inference done 141/1210. 0.0471 s / img. ETA=0:05:04
[03/28 13:21:54] d2.evaluation.evaluator INFO: Inference done 160/1210. 0.0473 s / img. ETA=0:04:56
[03/28 13:21:59] d2.evaluation.evaluator INFO: Inference done 173/1210. 0.0471 s / img. ETA=0:05:01
[03/28 13:22:07] d2.evaluation.evaluator INFO: Inference done 186/1210. 0.0472 s / img. ETA=0:05:21
[03/28 13:22:12] d2.evaluation.evaluator INFO: Inference done 207/1210. 0.0476 s / img. ETA=0:05:07
[03/28 13:22:17] d2.evaluation.evaluator INFO: Inference done 230/1210. 0.0479 s / img. ETA=0:04:52
[03/28 13:22:23] d2.evaluation.evaluator INFO: Inference done 249/1210. 0.0479 s / img. ETA=0:04:46
[03/28 13:22:28] d2.evaluation.evaluator INFO: Inference done 270/1210. 0.0480 s / img. ETA=0:04:36
[03/28 13:22:33] d2.evaluation.evaluator INFO: Inference done 293/1210. 0.0481 s / img. ETA=0:04:24
[03/28 13:22:38] d2.evaluation.evaluator INFO: Inference done 314/1210. 0.0482 s / img. ETA=0:04:15
[03/28 13:22:43] d2.evaluation.evaluator INFO: Inference done 336/1210. 0.0480 s / img. ETA=0:04:06
[03/28 13:22:48] d2.evaluation.evaluator INFO: Inference done 357/1210. 0.0480 s / img. ETA=0:03:58
[03/28 13:22:53] d2.evaluation.evaluator INFO: Inference done 378/1210. 0.0481 s / img. ETA=0:03:50
[03/28 13:22:58] d2.evaluation.evaluator INFO: Inference done 388/1210. 0.0481 s / img. ETA=0:03:52
[03/28 13:23:04] d2.evaluation.evaluator INFO: Inference done 406/1210. 0.0482 s / img. ETA=0:03:48
[03/28 13:23:09] d2.evaluation.evaluator INFO: Inference done 427/1210. 0.0483 s / img. ETA=0:03:41
[03/28 13:23:14] d2.evaluation.evaluator INFO: Inference done 448/1210. 0.0483 s / img. ETA=0:03:34
[03/28 13:23:19] d2.evaluation.evaluator INFO: Inference done 464/1210. 0.0482 s / img. ETA=0:03:30
[03/28 13:23:25] d2.evaluation.evaluator INFO: Inference done 481/1210. 0.0483 s / img. ETA=0:03:26
[03/28 13:23:30] d2.evaluation.evaluator INFO: Inference done 505/1210. 0.0483 s / img. ETA=0:03:17
[03/28 13:23:36] d2.evaluation.evaluator INFO: Inference done 522/1210. 0.0483 s / img. ETA=0:03:14
[03/28 13:23:41] d2.evaluation.evaluator INFO: Inference done 543/1210. 0.0483 s / img. ETA=0:03:07
[03/28 13:23:46] d2.evaluation.evaluator INFO: Inference done 560/1210. 0.0484 s / img. ETA=0:03:02
[03/28 13:23:53] d2.evaluation.evaluator INFO: Inference done 578/1210. 0.0484 s / img. ETA=0:02:59
[03/28 13:23:58] d2.evaluation.evaluator INFO: Inference done 604/1210. 0.0484 s / img. ETA=0:02:50
[03/28 13:24:03] d2.evaluation.evaluator INFO: Inference done 624/1210. 0.0484 s / img. ETA=0:02:43
[03/28 13:24:08] d2.evaluation.evaluator INFO: Inference done 642/1210. 0.0484 s / img. ETA=0:02:38
[03/28 13:24:13] d2.evaluation.evaluator INFO: Inference done 666/1210. 0.0483 s / img. ETA=0:02:30
[03/28 13:24:18] d2.evaluation.evaluator INFO: Inference done 687/1210. 0.0483 s / img. ETA=0:02:24
[03/28 13:24:24] d2.evaluation.evaluator INFO: Inference done 702/1210. 0.0483 s / img. ETA=0:02:21
[03/28 13:24:29] d2.evaluation.evaluator INFO: Inference done 716/1210. 0.0483 s / img. ETA=0:02:18
[03/28 13:24:34] d2.evaluation.evaluator INFO: Inference done 740/1210. 0.0483 s / img. ETA=0:02:10
[03/28 13:24:39] d2.evaluation.evaluator INFO: Inference done 764/1210. 0.0483 s / img. ETA=0:02:02
[03/28 13:24:44] d2.evaluation.evaluator INFO: Inference done 786/1210. 0.0483 s / img. ETA=0:01:56
[03/28 13:24:49] d2.evaluation.evaluator INFO: Inference done 802/1210. 0.0482 s / img. ETA=0:01:52
[03/28 13:24:54] d2.evaluation.evaluator INFO: Inference done 818/1210. 0.0482 s / img. ETA=0:01:48
[03/28 13:25:02] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0481 s / img. ETA=0:01:50
[03/28 13:25:07] d2.evaluation.evaluator INFO: Inference done 842/1210. 0.0481 s / img. ETA=0:01:44
[03/28 13:25:12] d2.evaluation.evaluator INFO: Inference done 863/1210. 0.0482 s / img. ETA=0:01:38
[03/28 13:25:17] d2.evaluation.evaluator INFO: Inference done 883/1210. 0.0481 s / img. ETA=0:01:32
[03/28 13:25:23] d2.evaluation.evaluator INFO: Inference done 908/1210. 0.0480 s / img. ETA=0:01:24
[03/28 13:25:28] d2.evaluation.evaluator INFO: Inference done 927/1210. 0.0480 s / img. ETA=0:01:19
[03/28 13:25:33] d2.evaluation.evaluator INFO: Inference done 947/1210. 0.0480 s / img. ETA=0:01:13
[03/28 13:25:38] d2.evaluation.evaluator INFO: Inference done 967/1210. 0.0481 s / img. ETA=0:01:07
[03/28 13:25:43] d2.evaluation.evaluator INFO: Inference done 987/1210. 0.0480 s / img. ETA=0:01:02
[03/28 13:25:48] d2.evaluation.evaluator INFO: Inference done 998/1210. 0.0481 s / img. ETA=0:00:59
[03/28 13:25:55] d2.evaluation.evaluator INFO: Inference done 1006/1210. 0.0481 s / img. ETA=0:00:58
[03/28 13:26:01] d2.evaluation.evaluator INFO: Inference done 1017/1210. 0.0481 s / img. ETA=0:00:55
[03/28 13:26:06] d2.evaluation.evaluator INFO: Inference done 1036/1210. 0.0481 s / img. ETA=0:00:49
[03/28 13:26:11] d2.evaluation.evaluator INFO: Inference done 1049/1210. 0.0481 s / img. ETA=0:00:46
[03/28 13:26:16] d2.evaluation.evaluator INFO: Inference done 1070/1210. 0.0481 s / img. ETA=0:00:40
[03/28 13:26:21] d2.evaluation.evaluator INFO: Inference done 1090/1210. 0.0482 s / img. ETA=0:00:34
[03/28 13:26:26] d2.evaluation.evaluator INFO: Inference done 1113/1210. 0.0482 s / img. ETA=0:00:27
[03/28 13:26:31] d2.evaluation.evaluator INFO: Inference done 1134/1210. 0.0484 s / img. ETA=0:00:21
[03/28 13:26:36] d2.evaluation.evaluator INFO: Inference done 1156/1210. 0.0484 s / img. ETA=0:00:15
[03/28 13:26:44] d2.evaluation.evaluator INFO: Inference done 1167/1210. 0.0484 s / img. ETA=0:00:12
[03/28 13:26:49] d2.evaluation.evaluator INFO: Inference done 1183/1210. 0.0485 s / img. ETA=0:00:07
[03/28 13:26:55] d2.evaluation.evaluator INFO: Inference done 1199/1210. 0.0485 s / img. ETA=0:00:03
[03/28 13:26:59] d2.evaluation.evaluator INFO: Total inference time: 0:05:48.823598 (0.289480 s / img per device, on 1 devices)
[03/28 13:26:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:58 (0.048524 s / img per device, on 1 devices)
[03/28 13:26:59] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/28 13:26:59] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/28 13:26:59] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/28 13:27:01] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.239 | 61.974 | 53.983 | 31.469 | 15.980 | 40.976 |
[03/28 13:27:01] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/28 13:27:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/28 13:27:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/28 13:27:01] d2.evaluation.testing INFO: copypaste: 43.2393,61.9744,53.9829,31.4687,15.9800,40.9761
[03/28 13:27:01] d2.utils.events INFO:  eta: 6:44:05  iter: 3999  total_loss: 0.141  loss_cls: 0.055  loss_box_reg: 0.059  loss_rpn_cls: 0.007  loss_rpn_loc: 0.023  time: 1.9539  data_time: 1.2510  lr: 0.001000  max_mem: 9421M
[03/28 13:27:54] d2.utils.events INFO:  eta: 6:44:00  iter: 4019  total_loss: 0.151  loss_cls: 0.058  loss_box_reg: 0.062  loss_rpn_cls: 0.007  loss_rpn_loc: 0.024  time: 1.9574  data_time: 2.0607  lr: 0.001000  max_mem: 9421M
[03/28 13:28:33] d2.utils.events INFO:  eta: 6:44:36  iter: 4039  total_loss: 0.119  loss_cls: 0.046  loss_box_reg: 0.054  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9573  data_time: 1.3612  lr: 0.001000  max_mem: 9421M
[03/28 13:29:13] d2.utils.events INFO:  eta: 6:43:51  iter: 4059  total_loss: 0.130  loss_cls: 0.053  loss_box_reg: 0.059  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 1.9574  data_time: 1.4380  lr: 0.001000  max_mem: 9421M
[03/28 13:30:04] d2.utils.events INFO:  eta: 6:43:16  iter: 4079  total_loss: 0.155  loss_cls: 0.051  loss_box_reg: 0.058  loss_rpn_cls: 0.006  loss_rpn_loc: 0.027  time: 1.9604  data_time: 2.0050  lr: 0.001000  max_mem: 9421M
[03/28 13:30:48] d2.utils.events INFO:  eta: 6:42:52  iter: 4099  total_loss: 0.157  loss_cls: 0.059  loss_box_reg: 0.059  loss_rpn_cls: 0.007  loss_rpn_loc: 0.028  time: 1.9615  data_time: 1.6523  lr: 0.001000  max_mem: 9421M
[03/28 13:31:25] d2.utils.events INFO:  eta: 6:42:17  iter: 4119  total_loss: 0.151  loss_cls: 0.059  loss_box_reg: 0.059  loss_rpn_cls: 0.007  loss_rpn_loc: 0.021  time: 1.9611  data_time: 1.3006  lr: 0.001000  max_mem: 9421M
[03/28 13:32:04] d2.utils.events INFO:  eta: 6:41:42  iter: 4139  total_loss: 0.169  loss_cls: 0.060  loss_box_reg: 0.066  loss_rpn_cls: 0.008  loss_rpn_loc: 0.026  time: 1.9609  data_time: 1.3607  lr: 0.001000  max_mem: 9421M
[03/28 13:32:43] d2.utils.events INFO:  eta: 6:41:08  iter: 4159  total_loss: 0.147  loss_cls: 0.050  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.027  time: 1.9610  data_time: 1.4304  lr: 0.001000  max_mem: 9421M
[03/28 13:33:20] d2.utils.events INFO:  eta: 6:39:23  iter: 4179  total_loss: 0.149  loss_cls: 0.054  loss_box_reg: 0.067  loss_rpn_cls: 0.008  loss_rpn_loc: 0.019  time: 1.9603  data_time: 1.2182  lr: 0.001000  max_mem: 9421M
[03/28 13:33:56] d2.utils.events INFO:  eta: 6:37:56  iter: 4199  total_loss: 0.141  loss_cls: 0.051  loss_box_reg: 0.055  loss_rpn_cls: 0.008  loss_rpn_loc: 0.021  time: 1.9595  data_time: 1.2109  lr: 0.001000  max_mem: 9421M
[03/28 13:34:35] d2.utils.events INFO:  eta: 6:38:49  iter: 4219  total_loss: 0.145  loss_cls: 0.057  loss_box_reg: 0.057  loss_rpn_cls: 0.007  loss_rpn_loc: 0.020  time: 1.9595  data_time: 1.3854  lr: 0.001000  max_mem: 9421M
[03/28 13:35:21] d2.utils.events INFO:  eta: 6:37:10  iter: 4239  total_loss: 0.140  loss_cls: 0.051  loss_box_reg: 0.054  loss_rpn_cls: 0.005  loss_rpn_loc: 0.026  time: 1.9611  data_time: 1.7535  lr: 0.001000  max_mem: 9421M
[03/28 13:35:53] d2.utils.events INFO:  eta: 6:34:34  iter: 4259  total_loss: 0.148  loss_cls: 0.052  loss_box_reg: 0.053  loss_rpn_cls: 0.007  loss_rpn_loc: 0.020  time: 1.9595  data_time: 1.0375  lr: 0.001000  max_mem: 9421M
[03/28 13:36:26] d2.utils.events INFO:  eta: 6:33:24  iter: 4279  total_loss: 0.145  loss_cls: 0.053  loss_box_reg: 0.058  loss_rpn_cls: 0.007  loss_rpn_loc: 0.025  time: 1.9581  data_time: 1.0984  lr: 0.001000  max_mem: 9421M
[03/28 13:37:08] d2.utils.events INFO:  eta: 6:32:41  iter: 4299  total_loss: 0.153  loss_cls: 0.053  loss_box_reg: 0.059  loss_rpn_cls: 0.007  loss_rpn_loc: 0.026  time: 1.9586  data_time: 1.5351  lr: 0.001000  max_mem: 9421M
[03/28 13:37:44] d2.utils.events INFO:  eta: 6:29:32  iter: 4319  total_loss: 0.148  loss_cls: 0.049  loss_box_reg: 0.056  loss_rpn_cls: 0.006  loss_rpn_loc: 0.027  time: 1.9579  data_time: 1.2459  lr: 0.001000  max_mem: 9421M
[03/28 13:38:28] d2.utils.events INFO:  eta: 6:27:29  iter: 4339  total_loss: 0.143  loss_cls: 0.052  loss_box_reg: 0.059  loss_rpn_cls: 0.007  loss_rpn_loc: 0.020  time: 1.9589  data_time: 1.5973  lr: 0.001000  max_mem: 9421M
[03/28 13:39:02] d2.utils.events INFO:  eta: 6:26:48  iter: 4359  total_loss: 0.151  loss_cls: 0.056  loss_box_reg: 0.062  loss_rpn_cls: 0.007  loss_rpn_loc: 0.018  time: 1.9579  data_time: 1.1905  lr: 0.001000  max_mem: 9421M
[03/28 13:39:36] d2.utils.events INFO:  eta: 6:24:58  iter: 4379  total_loss: 0.148  loss_cls: 0.062  loss_box_reg: 0.057  loss_rpn_cls: 0.009  loss_rpn_loc: 0.017  time: 1.9567  data_time: 1.1224  lr: 0.001000  max_mem: 9421M
[03/28 13:40:14] d2.utils.events INFO:  eta: 6:24:24  iter: 4399  total_loss: 0.151  loss_cls: 0.058  loss_box_reg: 0.056  loss_rpn_cls: 0.010  loss_rpn_loc: 0.030  time: 1.9564  data_time: 1.3108  lr: 0.001000  max_mem: 9421M
[03/28 13:40:51] d2.utils.events INFO:  eta: 6:23:33  iter: 4419  total_loss: 0.144  loss_cls: 0.052  loss_box_reg: 0.060  loss_rpn_cls: 0.007  loss_rpn_loc: 0.024  time: 1.9560  data_time: 1.2827  lr: 0.001000  max_mem: 9421M
[03/28 13:41:26] d2.utils.events INFO:  eta: 6:22:59  iter: 4439  total_loss: 0.145  loss_cls: 0.047  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 1.9550  data_time: 1.1819  lr: 0.001000  max_mem: 9421M
[03/28 13:42:04] d2.utils.events INFO:  eta: 6:22:00  iter: 4459  total_loss: 0.127  loss_cls: 0.046  loss_box_reg: 0.048  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9546  data_time: 1.2931  lr: 0.001000  max_mem: 9421M
[03/28 13:43:01] d2.utils.events INFO:  eta: 6:22:09  iter: 4479  total_loss: 0.127  loss_cls: 0.046  loss_box_reg: 0.057  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 1.9576  data_time: 2.0536  lr: 0.001000  max_mem: 9421M
[03/28 13:43:41] d2.utils.events INFO:  eta: 6:21:35  iter: 4499  total_loss: 0.133  loss_cls: 0.045  loss_box_reg: 0.050  loss_rpn_cls: 0.006  loss_rpn_loc: 0.027  time: 1.9577  data_time: 1.4061  lr: 0.001000  max_mem: 9421M
[03/28 13:44:19] d2.utils.events INFO:  eta: 6:19:51  iter: 4519  total_loss: 0.129  loss_cls: 0.047  loss_box_reg: 0.056  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 1.9574  data_time: 1.3181  lr: 0.001000  max_mem: 9421M
[03/28 13:44:56] d2.utils.events INFO:  eta: 6:18:47  iter: 4539  total_loss: 0.139  loss_cls: 0.054  loss_box_reg: 0.057  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  time: 1.9570  data_time: 1.3153  lr: 0.001000  max_mem: 9421M
[03/28 13:45:37] d2.utils.events INFO:  eta: 6:17:35  iter: 4559  total_loss: 0.156  loss_cls: 0.054  loss_box_reg: 0.063  loss_rpn_cls: 0.008  loss_rpn_loc: 0.021  time: 1.9574  data_time: 1.4651  lr: 0.001000  max_mem: 9421M
[03/28 13:46:21] d2.utils.events INFO:  eta: 6:16:52  iter: 4579  total_loss: 0.136  loss_cls: 0.052  loss_box_reg: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  time: 1.9585  data_time: 1.6077  lr: 0.001000  max_mem: 9421M
[03/28 13:46:56] d2.utils.events INFO:  eta: 6:16:24  iter: 4599  total_loss: 0.135  loss_cls: 0.053  loss_box_reg: 0.054  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9576  data_time: 1.1901  lr: 0.001000  max_mem: 9421M
[03/28 13:47:33] d2.utils.events INFO:  eta: 6:15:50  iter: 4619  total_loss: 0.150  loss_cls: 0.053  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.025  time: 1.9569  data_time: 1.2493  lr: 0.001000  max_mem: 9421M
[03/28 13:48:11] d2.utils.events INFO:  eta: 6:15:11  iter: 4639  total_loss: 0.148  loss_cls: 0.055  loss_box_reg: 0.063  loss_rpn_cls: 0.007  loss_rpn_loc: 0.021  time: 1.9567  data_time: 1.3245  lr: 0.001000  max_mem: 9421M
[03/28 13:48:51] d2.utils.events INFO:  eta: 6:13:38  iter: 4659  total_loss: 0.148  loss_cls: 0.059  loss_box_reg: 0.063  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 1.9569  data_time: 1.4573  lr: 0.001000  max_mem: 9421M
[03/28 13:49:30] d2.utils.events INFO:  eta: 6:13:51  iter: 4679  total_loss: 0.150  loss_cls: 0.057  loss_box_reg: 0.063  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 1.9569  data_time: 1.3984  lr: 0.001000  max_mem: 9421M
[03/28 13:50:12] d2.utils.events INFO:  eta: 6:13:17  iter: 4699  total_loss: 0.152  loss_cls: 0.058  loss_box_reg: 0.058  loss_rpn_cls: 0.006  loss_rpn_loc: 0.024  time: 1.9575  data_time: 1.5179  lr: 0.001000  max_mem: 9421M
[03/28 13:50:57] d2.utils.events INFO:  eta: 6:12:43  iter: 4719  total_loss: 0.134  loss_cls: 0.048  loss_box_reg: 0.055  loss_rpn_cls: 0.008  loss_rpn_loc: 0.020  time: 1.9586  data_time: 1.6594  lr: 0.001000  max_mem: 9421M
[03/28 13:51:51] d2.utils.events INFO:  eta: 6:14:31  iter: 4739  total_loss: 0.146  loss_cls: 0.050  loss_box_reg: 0.060  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9617  data_time: 2.1005  lr: 0.001000  max_mem: 9421M
[03/28 13:52:25] d2.utils.events INFO:  eta: 6:13:08  iter: 4759  total_loss: 0.148  loss_cls: 0.053  loss_box_reg: 0.057  loss_rpn_cls: 0.009  loss_rpn_loc: 0.019  time: 1.9606  data_time: 1.1125  lr: 0.001000  max_mem: 9421M
[03/28 13:53:01] d2.utils.events INFO:  eta: 6:11:59  iter: 4779  total_loss: 0.149  loss_cls: 0.052  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.022  time: 1.9599  data_time: 1.2455  lr: 0.001000  max_mem: 9421M
[03/28 13:53:35] d2.utils.events INFO:  eta: 6:09:24  iter: 4799  total_loss: 0.154  loss_cls: 0.052  loss_box_reg: 0.063  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9587  data_time: 1.1073  lr: 0.001000  max_mem: 9421M
[03/28 13:54:26] d2.utils.events INFO:  eta: 6:09:09  iter: 4819  total_loss: 0.153  loss_cls: 0.055  loss_box_reg: 0.059  loss_rpn_cls: 0.007  loss_rpn_loc: 0.031  time: 1.9611  data_time: 1.9826  lr: 0.001000  max_mem: 9421M
[03/28 13:55:01] d2.utils.events INFO:  eta: 6:08:35  iter: 4839  total_loss: 0.160  loss_cls: 0.051  loss_box_reg: 0.068  loss_rpn_cls: 0.008  loss_rpn_loc: 0.027  time: 1.9604  data_time: 1.2283  lr: 0.001000  max_mem: 9421M
[03/28 13:55:39] d2.utils.events INFO:  eta: 6:07:17  iter: 4859  total_loss: 0.120  loss_cls: 0.039  loss_box_reg: 0.056  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9601  data_time: 1.2987  lr: 0.001000  max_mem: 9421M
[03/28 13:56:17] d2.utils.events INFO:  eta: 6:06:44  iter: 4879  total_loss: 0.151  loss_cls: 0.054  loss_box_reg: 0.057  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 1.9598  data_time: 1.3172  lr: 0.001000  max_mem: 9421M
[03/28 13:56:59] d2.utils.events INFO:  eta: 6:08:02  iter: 4899  total_loss: 0.137  loss_cls: 0.049  loss_box_reg: 0.053  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9604  data_time: 1.5285  lr: 0.001000  max_mem: 9421M
[03/28 13:57:41] d2.utils.events INFO:  eta: 6:08:44  iter: 4919  total_loss: 0.129  loss_cls: 0.052  loss_box_reg: 0.056  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 1.9609  data_time: 1.5241  lr: 0.001000  max_mem: 9421M
[03/28 13:58:26] d2.utils.events INFO:  eta: 6:08:28  iter: 4939  total_loss: 0.149  loss_cls: 0.059  loss_box_reg: 0.063  loss_rpn_cls: 0.007  loss_rpn_loc: 0.023  time: 1.9622  data_time: 1.7228  lr: 0.001000  max_mem: 9421M
[03/28 13:59:10] d2.utils.events INFO:  eta: 6:07:30  iter: 4959  total_loss: 0.130  loss_cls: 0.047  loss_box_reg: 0.059  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 1.9631  data_time: 1.6092  lr: 0.001000  max_mem: 9421M
[03/28 13:59:54] d2.utils.events INFO:  eta: 6:06:56  iter: 4979  total_loss: 0.165  loss_cls: 0.055  loss_box_reg: 0.066  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9640  data_time: 1.6169  lr: 0.001000  max_mem: 9421M
[03/28 14:00:34] d2.utils.events INFO:  eta: 6:06:31  iter: 4999  total_loss: 0.143  loss_cls: 0.053  loss_box_reg: 0.060  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  time: 1.9641  data_time: 1.4084  lr: 0.001000  max_mem: 9421M
[03/28 14:01:10] d2.utils.events INFO:  eta: 6:05:53  iter: 5019  total_loss: 0.154  loss_cls: 0.057  loss_box_reg: 0.064  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9634  data_time: 1.2412  lr: 0.001000  max_mem: 9421M
[03/28 14:01:58] d2.utils.events INFO:  eta: 6:04:40  iter: 5039  total_loss: 0.147  loss_cls: 0.058  loss_box_reg: 0.057  loss_rpn_cls: 0.007  loss_rpn_loc: 0.017  time: 1.9652  data_time: 1.8623  lr: 0.001000  max_mem: 9421M
[03/28 14:02:41] d2.utils.events INFO:  eta: 6:04:50  iter: 5059  total_loss: 0.143  loss_cls: 0.053  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9657  data_time: 1.5430  lr: 0.001000  max_mem: 9421M
[03/28 14:03:21] d2.utils.events INFO:  eta: 6:04:51  iter: 5079  total_loss: 0.137  loss_cls: 0.046  loss_box_reg: 0.053  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9660  data_time: 1.4943  lr: 0.001000  max_mem: 9421M
[03/28 14:03:56] d2.utils.events INFO:  eta: 6:03:37  iter: 5099  total_loss: 0.149  loss_cls: 0.050  loss_box_reg: 0.063  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9651  data_time: 1.1553  lr: 0.001000  max_mem: 9421M
[03/28 14:04:39] d2.utils.events INFO:  eta: 6:01:35  iter: 5119  total_loss: 0.145  loss_cls: 0.058  loss_box_reg: 0.065  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 1.9658  data_time: 1.5716  lr: 0.001000  max_mem: 9421M
[03/28 14:05:16] d2.utils.events INFO:  eta: 6:00:11  iter: 5139  total_loss: 0.155  loss_cls: 0.052  loss_box_reg: 0.061  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9654  data_time: 1.2969  lr: 0.001000  max_mem: 9421M
[03/28 14:05:55] d2.utils.events INFO:  eta: 6:00:41  iter: 5159  total_loss: 0.152  loss_cls: 0.060  loss_box_reg: 0.066  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9652  data_time: 1.3680  lr: 0.001000  max_mem: 9421M
[03/28 14:06:39] d2.utils.events INFO:  eta: 6:00:09  iter: 5179  total_loss: 0.145  loss_cls: 0.054  loss_box_reg: 0.059  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 1.9662  data_time: 1.6629  lr: 0.001000  max_mem: 9421M
[03/28 14:07:32] d2.utils.events INFO:  eta: 6:00:48  iter: 5199  total_loss: 0.161  loss_cls: 0.059  loss_box_reg: 0.056  loss_rpn_cls: 0.008  loss_rpn_loc: 0.022  time: 1.9688  data_time: 2.0634  lr: 0.001000  max_mem: 9421M
[03/28 14:08:25] d2.utils.events INFO:  eta: 6:00:10  iter: 5219  total_loss: 0.141  loss_cls: 0.046  loss_box_reg: 0.051  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9714  data_time: 2.0866  lr: 0.001000  max_mem: 9421M
[03/28 14:09:03] d2.utils.events INFO:  eta: 5:59:41  iter: 5239  total_loss: 0.162  loss_cls: 0.060  loss_box_reg: 0.076  loss_rpn_cls: 0.007  loss_rpn_loc: 0.026  time: 1.9711  data_time: 1.3139  lr: 0.001000  max_mem: 9421M
[03/28 14:09:48] d2.utils.events INFO:  eta: 6:00:38  iter: 5259  total_loss: 0.138  loss_cls: 0.050  loss_box_reg: 0.055  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9722  data_time: 1.6825  lr: 0.001000  max_mem: 9421M
[03/28 14:10:24] d2.utils.events INFO:  eta: 6:00:04  iter: 5279  total_loss: 0.155  loss_cls: 0.054  loss_box_reg: 0.062  loss_rpn_cls: 0.007  loss_rpn_loc: 0.017  time: 1.9714  data_time: 1.2027  lr: 0.001000  max_mem: 9421M
[03/28 14:10:59] d2.utils.events INFO:  eta: 5:58:55  iter: 5299  total_loss: 0.158  loss_cls: 0.057  loss_box_reg: 0.064  loss_rpn_cls: 0.006  loss_rpn_loc: 0.028  time: 1.9706  data_time: 1.2008  lr: 0.001000  max_mem: 9421M
[03/28 14:11:43] d2.utils.events INFO:  eta: 5:59:17  iter: 5319  total_loss: 0.146  loss_cls: 0.048  loss_box_reg: 0.060  loss_rpn_cls: 0.007  loss_rpn_loc: 0.023  time: 1.9716  data_time: 1.6433  lr: 0.001000  max_mem: 9421M
[03/28 14:12:20] d2.utils.events INFO:  eta: 5:59:50  iter: 5339  total_loss: 0.139  loss_cls: 0.049  loss_box_reg: 0.065  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  time: 1.9710  data_time: 1.2621  lr: 0.001000  max_mem: 9421M
[03/28 14:12:55] d2.utils.events INFO:  eta: 6:00:13  iter: 5359  total_loss: 0.139  loss_cls: 0.047  loss_box_reg: 0.054  loss_rpn_cls: 0.007  loss_rpn_loc: 0.026  time: 1.9702  data_time: 1.2044  lr: 0.001000  max_mem: 9421M
[03/28 14:13:34] d2.utils.events INFO:  eta: 6:02:17  iter: 5379  total_loss: 0.141  loss_cls: 0.050  loss_box_reg: 0.060  loss_rpn_cls: 0.007  loss_rpn_loc: 0.019  time: 1.9702  data_time: 1.4182  lr: 0.001000  max_mem: 9421M
[03/28 14:14:27] d2.utils.events INFO:  eta: 6:01:43  iter: 5399  total_loss: 0.141  loss_cls: 0.051  loss_box_reg: 0.051  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9726  data_time: 2.0500  lr: 0.001000  max_mem: 9421M
[03/28 14:15:12] d2.utils.events INFO:  eta: 6:00:27  iter: 5419  total_loss: 0.153  loss_cls: 0.056  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.025  time: 1.9736  data_time: 1.6955  lr: 0.001000  max_mem: 9421M
[03/28 14:15:56] d2.utils.events INFO:  eta: 6:00:34  iter: 5439  total_loss: 0.156  loss_cls: 0.058  loss_box_reg: 0.062  loss_rpn_cls: 0.007  loss_rpn_loc: 0.023  time: 1.9744  data_time: 1.5941  lr: 0.001000  max_mem: 9421M
[03/28 14:16:34] d2.utils.events INFO:  eta: 6:00:31  iter: 5459  total_loss: 0.140  loss_cls: 0.052  loss_box_reg: 0.060  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9742  data_time: 1.3270  lr: 0.001000  max_mem: 9421M
[03/28 14:17:14] d2.utils.events INFO:  eta: 5:59:56  iter: 5479  total_loss: 0.145  loss_cls: 0.051  loss_box_reg: 0.059  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  time: 1.9743  data_time: 1.4448  lr: 0.001000  max_mem: 9421M
[03/28 14:18:07] d2.utils.events INFO:  eta: 5:59:53  iter: 5499  total_loss: 0.126  loss_cls: 0.048  loss_box_reg: 0.060  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 1.9768  data_time: 2.1132  lr: 0.001000  max_mem: 9421M
[03/28 14:18:54] d2.utils.events INFO:  eta: 6:02:37  iter: 5519  total_loss: 0.145  loss_cls: 0.053  loss_box_reg: 0.059  loss_rpn_cls: 0.006  loss_rpn_loc: 0.017  time: 1.9781  data_time: 1.7241  lr: 0.001000  max_mem: 9421M
[03/28 14:19:32] d2.utils.events INFO:  eta: 6:03:07  iter: 5539  total_loss: 0.127  loss_cls: 0.048  loss_box_reg: 0.059  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9778  data_time: 1.2890  lr: 0.001000  max_mem: 9421M
[03/28 14:20:11] d2.utils.events INFO:  eta: 6:03:01  iter: 5559  total_loss: 0.147  loss_cls: 0.058  loss_box_reg: 0.054  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9777  data_time: 1.3772  lr: 0.001000  max_mem: 9421M
[03/28 14:20:55] d2.utils.events INFO:  eta: 6:02:26  iter: 5579  total_loss: 0.145  loss_cls: 0.051  loss_box_reg: 0.062  loss_rpn_cls: 0.008  loss_rpn_loc: 0.021  time: 1.9785  data_time: 1.5998  lr: 0.001000  max_mem: 9421M
[03/28 14:21:30] d2.utils.events INFO:  eta: 6:01:35  iter: 5599  total_loss: 0.150  loss_cls: 0.045  loss_box_reg: 0.058  loss_rpn_cls: 0.008  loss_rpn_loc: 0.032  time: 1.9776  data_time: 1.1647  lr: 0.001000  max_mem: 9421M
[03/28 14:22:07] d2.utils.events INFO:  eta: 5:59:44  iter: 5619  total_loss: 0.149  loss_cls: 0.052  loss_box_reg: 0.065  loss_rpn_cls: 0.007  loss_rpn_loc: 0.021  time: 1.9772  data_time: 1.2800  lr: 0.001000  max_mem: 9421M
[03/28 14:22:47] d2.utils.events INFO:  eta: 5:59:42  iter: 5639  total_loss: 0.121  loss_cls: 0.045  loss_box_reg: 0.056  loss_rpn_cls: 0.006  loss_rpn_loc: 0.014  time: 1.9773  data_time: 1.4141  lr: 0.001000  max_mem: 9421M
[03/28 14:23:25] d2.utils.events INFO:  eta: 5:59:45  iter: 5659  total_loss: 0.139  loss_cls: 0.053  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.023  time: 1.9770  data_time: 1.3292  lr: 0.001000  max_mem: 9421M
[03/28 14:24:08] d2.utils.events INFO:  eta: 5:59:02  iter: 5679  total_loss: 0.140  loss_cls: 0.053  loss_box_reg: 0.054  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  time: 1.9776  data_time: 1.5971  lr: 0.001000  max_mem: 9421M
[03/28 14:24:51] d2.utils.events INFO:  eta: 5:58:25  iter: 5699  total_loss: 0.135  loss_cls: 0.050  loss_box_reg: 0.062  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 1.9782  data_time: 1.5607  lr: 0.001000  max_mem: 9421M
[03/28 14:25:30] d2.utils.events INFO:  eta: 5:57:23  iter: 5719  total_loss: 0.147  loss_cls: 0.049  loss_box_reg: 0.061  loss_rpn_cls: 0.006  loss_rpn_loc: 0.022  time: 1.9781  data_time: 1.3709  lr: 0.001000  max_mem: 9421M
[03/28 14:26:17] d2.utils.events INFO:  eta: 5:55:00  iter: 5739  total_loss: 0.169  loss_cls: 0.053  loss_box_reg: 0.063  loss_rpn_cls: 0.007  loss_rpn_loc: 0.027  time: 1.9793  data_time: 1.7478  lr: 0.001000  max_mem: 9421M
[03/28 14:26:58] d2.utils.events INFO:  eta: 5:55:45  iter: 5759  total_loss: 0.140  loss_cls: 0.051  loss_box_reg: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 1.9795  data_time: 1.4662  lr: 0.001000  max_mem: 9421M
[03/28 14:27:34] d2.utils.events INFO:  eta: 5:55:38  iter: 5779  total_loss: 0.149  loss_cls: 0.049  loss_box_reg: 0.056  loss_rpn_cls: 0.006  loss_rpn_loc: 0.028  time: 1.9789  data_time: 1.2209  lr: 0.001000  max_mem: 9421M
[03/28 14:28:13] d2.utils.events INFO:  eta: 5:55:40  iter: 5799  total_loss: 0.132  loss_cls: 0.048  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 1.9788  data_time: 1.3754  lr: 0.001000  max_mem: 9421M
[03/28 14:28:51] d2.utils.events INFO:  eta: 5:55:05  iter: 5819  total_loss: 0.133  loss_cls: 0.052  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.022  time: 1.9785  data_time: 1.2947  lr: 0.001000  max_mem: 9421M
[03/28 14:29:25] d2.utils.events INFO:  eta: 5:53:53  iter: 5839  total_loss: 0.120  loss_cls: 0.041  loss_box_reg: 0.059  loss_rpn_cls: 0.004  loss_rpn_loc: 0.016  time: 1.9775  data_time: 1.1346  lr: 0.001000  max_mem: 9421M
[03/28 14:30:16] d2.utils.events INFO:  eta: 5:52:51  iter: 5859  total_loss: 0.151  loss_cls: 0.055  loss_box_reg: 0.064  loss_rpn_cls: 0.005  loss_rpn_loc: 0.024  time: 1.9790  data_time: 1.8320  lr: 0.001000  max_mem: 9421M
[03/28 14:30:52] d2.utils.events INFO:  eta: 5:52:43  iter: 5879  total_loss: 0.133  loss_cls: 0.052  loss_box_reg: 0.058  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9784  data_time: 1.2322  lr: 0.001000  max_mem: 9421M
[03/28 14:31:32] d2.utils.events INFO:  eta: 5:49:52  iter: 5899  total_loss: 0.158  loss_cls: 0.058  loss_box_reg: 0.062  loss_rpn_cls: 0.008  loss_rpn_loc: 0.020  time: 1.9784  data_time: 1.4298  lr: 0.001000  max_mem: 9421M
[03/28 14:32:16] d2.utils.events INFO:  eta: 5:48:03  iter: 5919  total_loss: 0.141  loss_cls: 0.055  loss_box_reg: 0.054  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9792  data_time: 1.6289  lr: 0.001000  max_mem: 9421M
[03/28 14:33:06] d2.utils.events INFO:  eta: 5:51:33  iter: 5939  total_loss: 0.142  loss_cls: 0.048  loss_box_reg: 0.063  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 1.9809  data_time: 1.9359  lr: 0.001000  max_mem: 9421M
[03/28 14:34:05] d2.utils.events INFO:  eta: 5:53:36  iter: 5959  total_loss: 0.144  loss_cls: 0.052  loss_box_reg: 0.064  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9842  data_time: 2.3772  lr: 0.001000  max_mem: 9421M
[03/28 14:34:51] d2.utils.events INFO:  eta: 5:53:38  iter: 5979  total_loss: 0.154  loss_cls: 0.054  loss_box_reg: 0.062  loss_rpn_cls: 0.005  loss_rpn_loc: 0.027  time: 1.9853  data_time: 1.7321  lr: 0.001000  max_mem: 9421M
[03/28 14:35:33] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/28 14:35:33] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/28 14:35:33] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/28 14:35:33] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/28 14:35:35] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0502 s / img. ETA=0:03:22
[03/28 14:35:40] d2.evaluation.evaluator INFO: Inference done 18/1210. 0.0485 s / img. ETA=0:09:19
[03/28 14:35:46] d2.evaluation.evaluator INFO: Inference done 38/1210. 0.0467 s / img. ETA=0:06:44
[03/28 14:35:51] d2.evaluation.evaluator INFO: Inference done 60/1210. 0.0461 s / img. ETA=0:05:46
[03/28 14:35:59] d2.evaluation.evaluator INFO: Inference done 76/1210. 0.0459 s / img. ETA=0:06:31
[03/28 14:36:04] d2.evaluation.evaluator INFO: Inference done 95/1210. 0.0463 s / img. ETA=0:06:07
[03/28 14:36:09] d2.evaluation.evaluator INFO: Inference done 115/1210. 0.0466 s / img. ETA=0:05:45
[03/28 14:36:14] d2.evaluation.evaluator INFO: Inference done 139/1210. 0.0470 s / img. ETA=0:05:21
[03/28 14:36:20] d2.evaluation.evaluator INFO: Inference done 159/1210. 0.0471 s / img. ETA=0:05:09
[03/28 14:36:25] d2.evaluation.evaluator INFO: Inference done 173/1210. 0.0470 s / img. ETA=0:05:10
[03/28 14:36:30] d2.evaluation.evaluator INFO: Inference done 189/1210. 0.0471 s / img. ETA=0:05:07
[03/28 14:36:35] d2.evaluation.evaluator INFO: Inference done 210/1210. 0.0473 s / img. ETA=0:04:55
[03/28 14:36:40] d2.evaluation.evaluator INFO: Inference done 231/1210. 0.0476 s / img. ETA=0:04:43
[03/28 14:36:45] d2.evaluation.evaluator INFO: Inference done 250/1210. 0.0477 s / img. ETA=0:04:36
[03/28 14:36:50] d2.evaluation.evaluator INFO: Inference done 271/1210. 0.0478 s / img. ETA=0:04:28
[03/28 14:36:55] d2.evaluation.evaluator INFO: Inference done 295/1210. 0.0482 s / img. ETA=0:04:15
[03/28 14:37:00] d2.evaluation.evaluator INFO: Inference done 313/1210. 0.0484 s / img. ETA=0:04:11
[03/28 14:37:06] d2.evaluation.evaluator INFO: Inference done 334/1210. 0.0484 s / img. ETA=0:04:03
[03/28 14:37:11] d2.evaluation.evaluator INFO: Inference done 353/1210. 0.0485 s / img. ETA=0:03:57
[03/28 14:37:16] d2.evaluation.evaluator INFO: Inference done 375/1210. 0.0487 s / img. ETA=0:03:49
[03/28 14:37:21] d2.evaluation.evaluator INFO: Inference done 387/1210. 0.0486 s / img. ETA=0:03:49
[03/28 14:37:26] d2.evaluation.evaluator INFO: Inference done 404/1210. 0.0486 s / img. ETA=0:03:45
[03/28 14:37:31] d2.evaluation.evaluator INFO: Inference done 423/1210. 0.0486 s / img. ETA=0:03:40
[03/28 14:37:38] d2.evaluation.evaluator INFO: Inference done 434/1210. 0.0486 s / img. ETA=0:03:44
[03/28 14:37:44] d2.evaluation.evaluator INFO: Inference done 455/1210. 0.0485 s / img. ETA=0:03:37
[03/28 14:37:49] d2.evaluation.evaluator INFO: Inference done 473/1210. 0.0485 s / img. ETA=0:03:32
[03/28 14:37:54] d2.evaluation.evaluator INFO: Inference done 493/1210. 0.0484 s / img. ETA=0:03:25
[03/28 14:37:59] d2.evaluation.evaluator INFO: Inference done 515/1210. 0.0483 s / img. ETA=0:03:17
[03/28 14:38:04] d2.evaluation.evaluator INFO: Inference done 530/1210. 0.0482 s / img. ETA=0:03:14
[03/28 14:38:09] d2.evaluation.evaluator INFO: Inference done 551/1210. 0.0482 s / img. ETA=0:03:07
[03/28 14:38:15] d2.evaluation.evaluator INFO: Inference done 559/1210. 0.0482 s / img. ETA=0:03:09
[03/28 14:38:23] d2.evaluation.evaluator INFO: Inference done 571/1210. 0.0481 s / img. ETA=0:03:10
[03/28 14:38:29] d2.evaluation.evaluator INFO: Inference done 585/1210. 0.0481 s / img. ETA=0:03:07
[03/28 14:38:34] d2.evaluation.evaluator INFO: Inference done 608/1210. 0.0480 s / img. ETA=0:02:59
[03/28 14:38:42] d2.evaluation.evaluator INFO: Inference done 633/1210. 0.0481 s / img. ETA=0:02:52
[03/28 14:38:47] d2.evaluation.evaluator INFO: Inference done 657/1210. 0.0481 s / img. ETA=0:02:43
[03/28 14:38:52] d2.evaluation.evaluator INFO: Inference done 676/1210. 0.0481 s / img. ETA=0:02:37
[03/28 14:38:57] d2.evaluation.evaluator INFO: Inference done 695/1210. 0.0481 s / img. ETA=0:02:31
[03/28 14:39:03] d2.evaluation.evaluator INFO: Inference done 710/1210. 0.0480 s / img. ETA=0:02:27
[03/28 14:39:08] d2.evaluation.evaluator INFO: Inference done 735/1210. 0.0480 s / img. ETA=0:02:19
[03/28 14:39:13] d2.evaluation.evaluator INFO: Inference done 761/1210. 0.0480 s / img. ETA=0:02:10
[03/28 14:39:18] d2.evaluation.evaluator INFO: Inference done 786/1210. 0.0479 s / img. ETA=0:02:01
[03/28 14:39:24] d2.evaluation.evaluator INFO: Inference done 792/1210. 0.0479 s / img. ETA=0:02:02
[03/28 14:39:29] d2.evaluation.evaluator INFO: Inference done 811/1210. 0.0478 s / img. ETA=0:01:56
[03/28 14:39:38] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0478 s / img. ETA=0:01:55
[03/28 14:39:43] d2.evaluation.evaluator INFO: Inference done 843/1210. 0.0478 s / img. ETA=0:01:49
[03/28 14:39:48] d2.evaluation.evaluator INFO: Inference done 864/1210. 0.0479 s / img. ETA=0:01:42
[03/28 14:39:53] d2.evaluation.evaluator INFO: Inference done 886/1210. 0.0478 s / img. ETA=0:01:35
[03/28 14:39:59] d2.evaluation.evaluator INFO: Inference done 911/1210. 0.0478 s / img. ETA=0:01:27
[03/28 14:40:04] d2.evaluation.evaluator INFO: Inference done 933/1210. 0.0477 s / img. ETA=0:01:20
[03/28 14:40:10] d2.evaluation.evaluator INFO: Inference done 960/1210. 0.0477 s / img. ETA=0:01:12
[03/28 14:40:15] d2.evaluation.evaluator INFO: Inference done 981/1210. 0.0477 s / img. ETA=0:01:05
[03/28 14:40:20] d2.evaluation.evaluator INFO: Inference done 998/1210. 0.0476 s / img. ETA=0:01:01
[03/28 14:40:25] d2.evaluation.evaluator INFO: Inference done 1017/1210. 0.0476 s / img. ETA=0:00:55
[03/28 14:40:30] d2.evaluation.evaluator INFO: Inference done 1037/1210. 0.0475 s / img. ETA=0:00:49
[03/28 14:40:35] d2.evaluation.evaluator INFO: Inference done 1061/1210. 0.0475 s / img. ETA=0:00:42
[03/28 14:40:40] d2.evaluation.evaluator INFO: Inference done 1086/1210. 0.0475 s / img. ETA=0:00:35
[03/28 14:40:45] d2.evaluation.evaluator INFO: Inference done 1106/1210. 0.0474 s / img. ETA=0:00:29
[03/28 14:40:50] d2.evaluation.evaluator INFO: Inference done 1130/1210. 0.0474 s / img. ETA=0:00:22
[03/28 14:40:56] d2.evaluation.evaluator INFO: Inference done 1149/1210. 0.0475 s / img. ETA=0:00:17
[03/28 14:41:01] d2.evaluation.evaluator INFO: Inference done 1168/1210. 0.0475 s / img. ETA=0:00:11
[03/28 14:41:06] d2.evaluation.evaluator INFO: Inference done 1184/1210. 0.0475 s / img. ETA=0:00:07
[03/28 14:41:11] d2.evaluation.evaluator INFO: Inference done 1204/1210. 0.0475 s / img. ETA=0:00:01
[03/28 14:41:14] d2.evaluation.evaluator INFO: Total inference time: 0:05:39.826647 (0.282014 s / img per device, on 1 devices)
[03/28 14:41:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:57 (0.047474 s / img per device, on 1 devices)
[03/28 14:41:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/28 14:41:14] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/28 14:41:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/28 14:41:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.635 | 62.829 | 53.859 | 31.390 | 18.711 | 41.561 |
[03/28 14:41:16] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/28 14:41:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/28 14:41:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/28 14:41:16] d2.evaluation.testing INFO: copypaste: 43.6346,62.8292,53.8594,31.3903,18.7106,41.5609
[03/28 14:41:16] d2.utils.events INFO:  eta: 5:54:16  iter: 5999  total_loss: 0.159  loss_cls: 0.057  loss_box_reg: 0.065  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9856  data_time: 1.5025  lr: 0.001000  max_mem: 9421M
[03/28 14:41:57] d2.utils.events INFO:  eta: 5:53:18  iter: 6019  total_loss: 0.149  loss_cls: 0.056  loss_box_reg: 0.067  loss_rpn_cls: 0.006  loss_rpn_loc: 0.017  time: 1.9857  data_time: 1.4843  lr: 0.001000  max_mem: 9421M
[03/28 14:42:42] d2.utils.events INFO:  eta: 5:53:34  iter: 6039  total_loss: 0.159  loss_cls: 0.060  loss_box_reg: 0.065  loss_rpn_cls: 0.006  loss_rpn_loc: 0.023  time: 1.9866  data_time: 1.6782  lr: 0.001000  max_mem: 9421M
[03/28 14:43:27] d2.utils.events INFO:  eta: 5:52:59  iter: 6059  total_loss: 0.141  loss_cls: 0.053  loss_box_reg: 0.054  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 1.9874  data_time: 1.6971  lr: 0.001000  max_mem: 9421M
[03/28 14:44:06] d2.utils.events INFO:  eta: 5:51:11  iter: 6079  total_loss: 0.150  loss_cls: 0.055  loss_box_reg: 0.069  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 1.9872  data_time: 1.3563  lr: 0.001000  max_mem: 9421M
[03/28 14:44:44] d2.utils.events INFO:  eta: 5:51:38  iter: 6099  total_loss: 0.142  loss_cls: 0.049  loss_box_reg: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 1.9868  data_time: 1.2929  lr: 0.001000  max_mem: 9421M
[03/28 14:45:21] d2.utils.events INFO:  eta: 5:51:03  iter: 6119  total_loss: 0.149  loss_cls: 0.053  loss_box_reg: 0.066  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9865  data_time: 1.2689  lr: 0.001000  max_mem: 9421M
[03/28 14:46:11] d2.utils.events INFO:  eta: 5:52:24  iter: 6139  total_loss: 0.151  loss_cls: 0.051  loss_box_reg: 0.063  loss_rpn_cls: 0.006  loss_rpn_loc: 0.024  time: 1.9882  data_time: 1.9552  lr: 0.001000  max_mem: 9421M
[03/28 14:46:50] d2.utils.events INFO:  eta: 5:51:20  iter: 6159  total_loss: 0.158  loss_cls: 0.056  loss_box_reg: 0.066  loss_rpn_cls: 0.007  loss_rpn_loc: 0.026  time: 1.9879  data_time: 1.3521  lr: 0.001000  max_mem: 9421M
[03/28 14:47:24] d2.utils.events INFO:  eta: 5:50:45  iter: 6179  total_loss: 0.137  loss_cls: 0.048  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 1.9871  data_time: 1.1670  lr: 0.001000  max_mem: 9421M
[03/28 14:48:07] d2.utils.events INFO:  eta: 5:47:44  iter: 6199  total_loss: 0.147  loss_cls: 0.054  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9875  data_time: 1.5640  lr: 0.001000  max_mem: 9421M
[03/28 14:48:50] d2.utils.events INFO:  eta: 5:47:35  iter: 6219  total_loss: 0.136  loss_cls: 0.050  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9881  data_time: 1.5914  lr: 0.001000  max_mem: 9421M
[03/28 14:49:42] d2.utils.events INFO:  eta: 5:48:32  iter: 6239  total_loss: 0.143  loss_cls: 0.051  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 1.9900  data_time: 2.0183  lr: 0.001000  max_mem: 9421M
[03/28 14:50:30] d2.utils.events INFO:  eta: 5:46:24  iter: 6259  total_loss: 0.143  loss_cls: 0.057  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 1.9914  data_time: 1.8630  lr: 0.001000  max_mem: 9421M
[03/28 14:51:07] d2.utils.events INFO:  eta: 5:47:21  iter: 6279  total_loss: 0.140  loss_cls: 0.053  loss_box_reg: 0.055  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 1.9909  data_time: 1.2797  lr: 0.001000  max_mem: 9421M
[03/28 14:51:50] d2.utils.events INFO:  eta: 5:48:03  iter: 6299  total_loss: 0.137  loss_cls: 0.050  loss_box_reg: 0.060  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 1.9914  data_time: 1.5982  lr: 0.001000  max_mem: 9421M
[03/28 14:52:23] d2.utils.events INFO:  eta: 5:45:44  iter: 6319  total_loss: 0.144  loss_cls: 0.050  loss_box_reg: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 1.9904  data_time: 1.1145  lr: 0.001000  max_mem: 9421M
[03/28 14:52:58] d2.utils.events INFO:  eta: 5:42:50  iter: 6339  total_loss: 0.140  loss_cls: 0.046  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9895  data_time: 1.1607  lr: 0.001000  max_mem: 9421M
[03/28 14:53:39] d2.utils.events INFO:  eta: 5:41:50  iter: 6359  total_loss: 0.141  loss_cls: 0.047  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 1.9898  data_time: 1.5172  lr: 0.001000  max_mem: 9421M
[03/28 14:54:24] d2.utils.events INFO:  eta: 5:40:09  iter: 6379  total_loss: 0.120  loss_cls: 0.045  loss_box_reg: 0.053  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9905  data_time: 1.6449  lr: 0.001000  max_mem: 9421M
[03/28 14:55:08] d2.utils.events INFO:  eta: 5:40:39  iter: 6399  total_loss: 0.147  loss_cls: 0.054  loss_box_reg: 0.064  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9913  data_time: 1.6321  lr: 0.001000  max_mem: 9421M
[03/28 14:55:45] d2.utils.events INFO:  eta: 5:40:29  iter: 6419  total_loss: 0.143  loss_cls: 0.053  loss_box_reg: 0.059  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9907  data_time: 1.2730  lr: 0.001000  max_mem: 9421M
[03/28 14:56:28] d2.utils.events INFO:  eta: 5:40:46  iter: 6439  total_loss: 0.135  loss_cls: 0.048  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9913  data_time: 1.5837  lr: 0.001000  max_mem: 9421M
[03/28 14:57:13] d2.utils.events INFO:  eta: 5:39:59  iter: 6459  total_loss: 0.148  loss_cls: 0.052  loss_box_reg: 0.057  loss_rpn_cls: 0.006  loss_rpn_loc: 0.025  time: 1.9921  data_time: 1.6924  lr: 0.001000  max_mem: 9421M
[03/28 14:57:57] d2.utils.events INFO:  eta: 5:41:22  iter: 6479  total_loss: 0.155  loss_cls: 0.057  loss_box_reg: 0.069  loss_rpn_cls: 0.007  loss_rpn_loc: 0.020  time: 1.9927  data_time: 1.6036  lr: 0.001000  max_mem: 9421M
[03/28 14:58:43] d2.utils.events INFO:  eta: 5:39:49  iter: 6499  total_loss: 0.145  loss_cls: 0.051  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 1.9936  data_time: 1.7315  lr: 0.001000  max_mem: 9421M
[03/28 14:59:22] d2.utils.events INFO:  eta: 5:38:22  iter: 6519  total_loss: 0.145  loss_cls: 0.053  loss_box_reg: 0.064  loss_rpn_cls: 0.007  loss_rpn_loc: 0.015  time: 1.9935  data_time: 1.4146  lr: 0.001000  max_mem: 9421M
[03/28 14:59:59] d2.utils.events INFO:  eta: 5:37:19  iter: 6539  total_loss: 0.121  loss_cls: 0.043  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.015  time: 1.9931  data_time: 1.2634  lr: 0.001000  max_mem: 9421M
[03/28 15:00:40] d2.utils.events INFO:  eta: 5:35:33  iter: 6559  total_loss: 0.152  loss_cls: 0.048  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9932  data_time: 1.4620  lr: 0.001000  max_mem: 9421M
[03/28 15:01:25] d2.utils.events INFO:  eta: 5:36:08  iter: 6579  total_loss: 0.146  loss_cls: 0.058  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9940  data_time: 1.6932  lr: 0.001000  max_mem: 9421M
[03/28 15:02:00] d2.utils.events INFO:  eta: 5:35:33  iter: 6599  total_loss: 0.142  loss_cls: 0.051  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9932  data_time: 1.1244  lr: 0.001000  max_mem: 9421M
[03/28 15:02:37] d2.utils.events INFO:  eta: 5:36:51  iter: 6619  total_loss: 0.129  loss_cls: 0.050  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.014  time: 1.9928  data_time: 1.2881  lr: 0.001000  max_mem: 9421M
[03/28 15:03:14] d2.utils.events INFO:  eta: 5:35:38  iter: 6639  total_loss: 0.148  loss_cls: 0.050  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9924  data_time: 1.3164  lr: 0.001000  max_mem: 9421M
[03/28 15:03:54] d2.utils.events INFO:  eta: 5:34:14  iter: 6659  total_loss: 0.121  loss_cls: 0.048  loss_box_reg: 0.055  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 1.9925  data_time: 1.4355  lr: 0.001000  max_mem: 9421M
[03/28 15:04:37] d2.utils.events INFO:  eta: 5:33:39  iter: 6679  total_loss: 0.136  loss_cls: 0.049  loss_box_reg: 0.056  loss_rpn_cls: 0.007  loss_rpn_loc: 0.024  time: 1.9928  data_time: 1.5547  lr: 0.001000  max_mem: 9421M
[03/28 15:05:17] d2.utils.events INFO:  eta: 5:33:38  iter: 6699  total_loss: 0.149  loss_cls: 0.050  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 1.9929  data_time: 1.4756  lr: 0.001000  max_mem: 9421M
[03/28 15:06:08] d2.utils.events INFO:  eta: 5:34:15  iter: 6719  total_loss: 0.143  loss_cls: 0.052  loss_box_reg: 0.067  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 1.9940  data_time: 1.7879  lr: 0.001000  max_mem: 9421M
[03/28 15:06:58] d2.utils.events INFO:  eta: 5:34:27  iter: 6739  total_loss: 0.149  loss_cls: 0.053  loss_box_reg: 0.060  loss_rpn_cls: 0.007  loss_rpn_loc: 0.017  time: 1.9955  data_time: 1.9616  lr: 0.001000  max_mem: 9421M
[03/28 15:07:49] d2.utils.events INFO:  eta: 5:33:52  iter: 6759  total_loss: 0.137  loss_cls: 0.044  loss_box_reg: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 1.9971  data_time: 1.9708  lr: 0.001000  max_mem: 9421M
[03/28 15:08:27] d2.utils.events INFO:  eta: 5:30:58  iter: 6779  total_loss: 0.149  loss_cls: 0.051  loss_box_reg: 0.062  loss_rpn_cls: 0.006  loss_rpn_loc: 0.017  time: 1.9969  data_time: 1.3443  lr: 0.001000  max_mem: 9421M
[03/28 15:09:07] d2.utils.events INFO:  eta: 5:30:22  iter: 6799  total_loss: 0.129  loss_cls: 0.042  loss_box_reg: 0.054  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9968  data_time: 1.4271  lr: 0.001000  max_mem: 9421M
[03/28 15:09:49] d2.utils.events INFO:  eta: 5:29:47  iter: 6819  total_loss: 0.127  loss_cls: 0.046  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9970  data_time: 1.4993  lr: 0.001000  max_mem: 9421M
[03/28 15:10:35] d2.utils.events INFO:  eta: 5:30:42  iter: 6839  total_loss: 0.135  loss_cls: 0.044  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 1.9980  data_time: 1.7654  lr: 0.001000  max_mem: 9421M
[03/28 15:11:14] d2.utils.events INFO:  eta: 5:29:32  iter: 6859  total_loss: 0.123  loss_cls: 0.043  loss_box_reg: 0.053  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 1.9972  data_time: 1.1693  lr: 0.001000  max_mem: 9421M
[03/28 15:11:53] d2.utils.events INFO:  eta: 5:28:56  iter: 6879  total_loss: 0.135  loss_cls: 0.042  loss_box_reg: 0.058  loss_rpn_cls: 0.003  loss_rpn_loc: 0.027  time: 1.9970  data_time: 1.4001  lr: 0.001000  max_mem: 9421M
[03/28 15:12:35] d2.utils.events INFO:  eta: 5:27:08  iter: 6899  total_loss: 0.132  loss_cls: 0.048  loss_box_reg: 0.064  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 1.9972  data_time: 1.5213  lr: 0.001000  max_mem: 9421M
[03/28 15:13:12] d2.utils.events INFO:  eta: 5:24:45  iter: 6919  total_loss: 0.140  loss_cls: 0.053  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.024  time: 1.9968  data_time: 1.2843  lr: 0.001000  max_mem: 9421M
[03/28 15:13:46] d2.utils.events INFO:  eta: 5:19:05  iter: 6939  total_loss: 0.138  loss_cls: 0.049  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 1.9959  data_time: 1.1262  lr: 0.001000  max_mem: 9421M
[03/28 15:14:31] d2.utils.events INFO:  eta: 5:17:19  iter: 6959  total_loss: 0.151  loss_cls: 0.058  loss_box_reg: 0.062  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  time: 1.9968  data_time: 1.7311  lr: 0.001000  max_mem: 9421M
[03/28 15:15:09] d2.utils.events INFO:  eta: 5:16:22  iter: 6979  total_loss: 0.142  loss_cls: 0.049  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9964  data_time: 1.2773  lr: 0.001000  max_mem: 9421M
[03/28 15:15:50] d2.utils.events INFO:  eta: 5:14:24  iter: 6999  total_loss: 0.148  loss_cls: 0.052  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.025  time: 1.9966  data_time: 1.5384  lr: 0.001000  max_mem: 9421M
[03/28 15:16:36] d2.utils.events INFO:  eta: 5:14:26  iter: 7019  total_loss: 0.148  loss_cls: 0.051  loss_box_reg: 0.062  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.9974  data_time: 1.7142  lr: 0.001000  max_mem: 9421M
[03/28 15:17:18] d2.utils.events INFO:  eta: 5:14:08  iter: 7039  total_loss: 0.142  loss_cls: 0.050  loss_box_reg: 0.062  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9977  data_time: 1.5208  lr: 0.001000  max_mem: 9421M
[03/28 15:17:55] d2.utils.events INFO:  eta: 5:13:05  iter: 7059  total_loss: 0.137  loss_cls: 0.051  loss_box_reg: 0.058  loss_rpn_cls: 0.006  loss_rpn_loc: 0.023  time: 1.9973  data_time: 1.3070  lr: 0.001000  max_mem: 9421M
[03/28 15:18:31] d2.utils.events INFO:  eta: 5:12:43  iter: 7079  total_loss: 0.136  loss_cls: 0.045  loss_box_reg: 0.055  loss_rpn_cls: 0.007  loss_rpn_loc: 0.025  time: 1.9967  data_time: 1.1967  lr: 0.001000  max_mem: 9421M
[03/28 15:19:11] d2.utils.events INFO:  eta: 5:12:45  iter: 7099  total_loss: 0.142  loss_cls: 0.052  loss_box_reg: 0.058  loss_rpn_cls: 0.007  loss_rpn_loc: 0.020  time: 1.9967  data_time: 1.4454  lr: 0.001000  max_mem: 9421M
[03/28 15:19:55] d2.utils.events INFO:  eta: 5:12:21  iter: 7119  total_loss: 0.138  loss_cls: 0.044  loss_box_reg: 0.060  loss_rpn_cls: 0.006  loss_rpn_loc: 0.023  time: 1.9973  data_time: 1.5790  lr: 0.001000  max_mem: 9421M
[03/28 15:20:33] d2.utils.events INFO:  eta: 5:11:37  iter: 7139  total_loss: 0.142  loss_cls: 0.047  loss_box_reg: 0.064  loss_rpn_cls: 0.006  loss_rpn_loc: 0.021  time: 1.9970  data_time: 1.3559  lr: 0.001000  max_mem: 9421M
[03/28 15:21:08] d2.utils.events INFO:  eta: 5:10:43  iter: 7159  total_loss: 0.143  loss_cls: 0.058  loss_box_reg: 0.062  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 1.9963  data_time: 1.1746  lr: 0.001000  max_mem: 9421M
[03/28 15:21:56] d2.utils.events INFO:  eta: 5:10:28  iter: 7179  total_loss: 0.139  loss_cls: 0.049  loss_box_reg: 0.060  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.9975  data_time: 1.8343  lr: 0.001000  max_mem: 9421M
[03/28 15:22:36] d2.utils.events INFO:  eta: 5:09:53  iter: 7199  total_loss: 0.128  loss_cls: 0.045  loss_box_reg: 0.057  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 1.9975  data_time: 1.4198  lr: 0.001000  max_mem: 9421M
[03/28 15:23:11] d2.utils.events INFO:  eta: 5:08:42  iter: 7219  total_loss: 0.136  loss_cls: 0.044  loss_box_reg: 0.059  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  time: 1.9968  data_time: 1.1783  lr: 0.001000  max_mem: 9421M
[03/28 15:24:01] d2.utils.events INFO:  eta: 5:07:33  iter: 7239  total_loss: 0.142  loss_cls: 0.056  loss_box_reg: 0.063  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 1.9981  data_time: 1.9096  lr: 0.001000  max_mem: 9421M
[03/28 15:24:36] d2.utils.events INFO:  eta: 5:07:30  iter: 7259  total_loss: 0.164  loss_cls: 0.055  loss_box_reg: 0.064  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9975  data_time: 1.2085  lr: 0.001000  max_mem: 9421M
[03/28 15:25:15] d2.utils.events INFO:  eta: 5:06:59  iter: 7279  total_loss: 0.134  loss_cls: 0.048  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9974  data_time: 1.3788  lr: 0.001000  max_mem: 9421M
[03/28 15:25:53] d2.utils.events INFO:  eta: 5:06:45  iter: 7299  total_loss: 0.143  loss_cls: 0.049  loss_box_reg: 0.061  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 1.9971  data_time: 1.2977  lr: 0.001000  max_mem: 9421M
[03/28 15:26:31] d2.utils.events INFO:  eta: 5:05:51  iter: 7319  total_loss: 0.140  loss_cls: 0.051  loss_box_reg: 0.065  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 1.9968  data_time: 1.3333  lr: 0.001000  max_mem: 9421M
[03/28 15:27:08] d2.utils.events INFO:  eta: 5:05:36  iter: 7339  total_loss: 0.130  loss_cls: 0.043  loss_box_reg: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.9964  data_time: 1.3126  lr: 0.001000  max_mem: 9421M
[03/28 15:27:45] d2.utils.events INFO:  eta: 5:04:27  iter: 7359  total_loss: 0.155  loss_cls: 0.051  loss_box_reg: 0.067  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9961  data_time: 1.2952  lr: 0.001000  max_mem: 9421M
[03/28 15:28:31] d2.utils.events INFO:  eta: 5:04:08  iter: 7379  total_loss: 0.132  loss_cls: 0.043  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9969  data_time: 1.7532  lr: 0.001000  max_mem: 9421M
[03/28 15:29:07] d2.utils.events INFO:  eta: 5:02:19  iter: 7399  total_loss: 0.137  loss_cls: 0.050  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9963  data_time: 1.1763  lr: 0.001000  max_mem: 9421M
[03/28 15:29:44] d2.utils.events INFO:  eta: 5:02:44  iter: 7419  total_loss: 0.134  loss_cls: 0.048  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.016  time: 1.9959  data_time: 1.2876  lr: 0.001000  max_mem: 9421M
[03/28 15:30:30] d2.utils.events INFO:  eta: 5:02:10  iter: 7439  total_loss: 0.126  loss_cls: 0.043  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 1.9968  data_time: 1.7572  lr: 0.001000  max_mem: 9421M
[03/28 15:31:09] d2.utils.events INFO:  eta: 5:00:11  iter: 7459  total_loss: 0.117  loss_cls: 0.041  loss_box_reg: 0.053  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 1.9966  data_time: 1.3712  lr: 0.001000  max_mem: 9421M
[03/28 15:31:43] d2.utils.events INFO:  eta: 4:57:22  iter: 7479  total_loss: 0.141  loss_cls: 0.054  loss_box_reg: 0.057  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 1.9958  data_time: 1.1300  lr: 0.001000  max_mem: 9421M
[03/28 15:32:19] d2.utils.events INFO:  eta: 4:56:05  iter: 7499  total_loss: 0.135  loss_cls: 0.049  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 1.9953  data_time: 1.2825  lr: 0.001000  max_mem: 9421M
[03/28 15:33:02] d2.utils.events INFO:  eta: 4:55:24  iter: 7519  total_loss: 0.138  loss_cls: 0.046  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9957  data_time: 1.5763  lr: 0.001000  max_mem: 9421M
[03/28 15:33:44] d2.utils.events INFO:  eta: 4:54:58  iter: 7539  total_loss: 0.126  loss_cls: 0.045  loss_box_reg: 0.055  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9959  data_time: 1.5039  lr: 0.001000  max_mem: 9421M
[03/28 15:34:17] d2.utils.events INFO:  eta: 4:54:24  iter: 7559  total_loss: 0.133  loss_cls: 0.048  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 1.9950  data_time: 1.0842  lr: 0.001000  max_mem: 9421M
[03/28 15:35:01] d2.utils.events INFO:  eta: 4:53:52  iter: 7579  total_loss: 0.151  loss_cls: 0.052  loss_box_reg: 0.063  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9955  data_time: 1.6105  lr: 0.001000  max_mem: 9421M
[03/28 15:35:40] d2.utils.events INFO:  eta: 4:53:58  iter: 7599  total_loss: 0.159  loss_cls: 0.056  loss_box_reg: 0.069  loss_rpn_cls: 0.007  loss_rpn_loc: 0.027  time: 1.9954  data_time: 1.3891  lr: 0.001000  max_mem: 9421M
[03/28 15:36:27] d2.utils.events INFO:  eta: 4:53:42  iter: 7619  total_loss: 0.159  loss_cls: 0.049  loss_box_reg: 0.069  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9963  data_time: 1.7412  lr: 0.001000  max_mem: 9421M
[03/28 15:37:03] d2.utils.events INFO:  eta: 4:53:40  iter: 7639  total_loss: 0.142  loss_cls: 0.050  loss_box_reg: 0.061  loss_rpn_cls: 0.007  loss_rpn_loc: 0.018  time: 1.9958  data_time: 1.2422  lr: 0.001000  max_mem: 9421M
[03/28 15:37:55] d2.utils.events INFO:  eta: 4:54:00  iter: 7659  total_loss: 0.141  loss_cls: 0.054  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.024  time: 1.9974  data_time: 2.0487  lr: 0.001000  max_mem: 9421M
[03/28 15:38:40] d2.utils.events INFO:  eta: 4:52:01  iter: 7679  total_loss: 0.142  loss_cls: 0.044  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9980  data_time: 1.6850  lr: 0.001000  max_mem: 9421M
[03/28 15:39:20] d2.utils.events INFO:  eta: 4:51:27  iter: 7699  total_loss: 0.141  loss_cls: 0.053  loss_box_reg: 0.068  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  time: 1.9980  data_time: 1.4364  lr: 0.001000  max_mem: 9421M
[03/28 15:40:16] d2.utils.events INFO:  eta: 4:51:46  iter: 7719  total_loss: 0.138  loss_cls: 0.045  loss_box_reg: 0.063  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 2.0002  data_time: 2.2816  lr: 0.001000  max_mem: 9421M
[03/28 15:40:49] d2.utils.events INFO:  eta: 4:49:56  iter: 7739  total_loss: 0.158  loss_cls: 0.061  loss_box_reg: 0.066  loss_rpn_cls: 0.006  loss_rpn_loc: 0.022  time: 1.9993  data_time: 1.0750  lr: 0.001000  max_mem: 9421M
[03/28 15:41:26] d2.utils.events INFO:  eta: 4:48:47  iter: 7759  total_loss: 0.129  loss_cls: 0.053  loss_box_reg: 0.058  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9989  data_time: 1.2988  lr: 0.001000  max_mem: 9421M
[03/28 15:42:05] d2.utils.events INFO:  eta: 4:48:17  iter: 7779  total_loss: 0.146  loss_cls: 0.047  loss_box_reg: 0.060  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9987  data_time: 1.3483  lr: 0.001000  max_mem: 9421M
[03/28 15:42:50] d2.utils.events INFO:  eta: 4:48:55  iter: 7799  total_loss: 0.123  loss_cls: 0.043  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9993  data_time: 1.6482  lr: 0.001000  max_mem: 9421M
[03/28 15:43:28] d2.utils.events INFO:  eta: 4:47:40  iter: 7819  total_loss: 0.118  loss_cls: 0.040  loss_box_reg: 0.053  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 1.9991  data_time: 1.3494  lr: 0.001000  max_mem: 9421M
[03/28 15:44:15] d2.utils.events INFO:  eta: 4:47:26  iter: 7839  total_loss: 0.141  loss_cls: 0.051  loss_box_reg: 0.065  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 2.0000  data_time: 1.7911  lr: 0.001000  max_mem: 9421M
[03/28 15:45:10] d2.utils.events INFO:  eta: 4:48:30  iter: 7859  total_loss: 0.115  loss_cls: 0.042  loss_box_reg: 0.054  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 2.0019  data_time: 2.1368  lr: 0.001000  max_mem: 9421M
[03/28 15:46:03] d2.utils.events INFO:  eta: 4:48:14  iter: 7879  total_loss: 0.124  loss_cls: 0.044  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0036  data_time: 2.1039  lr: 0.001000  max_mem: 9421M
[03/28 15:46:50] d2.utils.events INFO:  eta: 4:51:27  iter: 7899  total_loss: 0.138  loss_cls: 0.042  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0045  data_time: 1.7747  lr: 0.001000  max_mem: 9421M
[03/28 15:47:33] d2.utils.events INFO:  eta: 4:51:55  iter: 7919  total_loss: 0.133  loss_cls: 0.048  loss_box_reg: 0.060  loss_rpn_cls: 0.005  loss_rpn_loc: 0.020  time: 2.0048  data_time: 1.5677  lr: 0.001000  max_mem: 9421M
[03/28 15:48:18] d2.utils.events INFO:  eta: 4:54:09  iter: 7939  total_loss: 0.133  loss_cls: 0.043  loss_box_reg: 0.059  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 2.0054  data_time: 1.6621  lr: 0.001000  max_mem: 9421M
[03/28 15:49:02] d2.utils.events INFO:  eta: 4:55:18  iter: 7959  total_loss: 0.131  loss_cls: 0.044  loss_box_reg: 0.056  loss_rpn_cls: 0.004  loss_rpn_loc: 0.025  time: 2.0059  data_time: 1.6520  lr: 0.001000  max_mem: 9421M
[03/28 15:49:39] d2.utils.events INFO:  eta: 4:54:18  iter: 7979  total_loss: 0.150  loss_cls: 0.046  loss_box_reg: 0.075  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 2.0055  data_time: 1.2805  lr: 0.001000  max_mem: 9421M
[03/28 15:50:12] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/lr0.001_finetune/model_0007999.pth
[03/28 15:50:15] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/28 15:50:15] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/28 15:50:15] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/28 15:50:15] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/28 15:50:17] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0535 s / img. ETA=0:03:17
[03/28 15:50:23] d2.evaluation.evaluator INFO: Inference done 32/1210. 0.0478 s / img. ETA=0:04:25
[03/28 15:50:28] d2.evaluation.evaluator INFO: Inference done 55/1210. 0.0470 s / img. ETA=0:04:16
[03/28 15:50:33] d2.evaluation.evaluator INFO: Inference done 74/1210. 0.0469 s / img. ETA=0:04:27
[03/28 15:50:38] d2.evaluation.evaluator INFO: Inference done 97/1210. 0.0468 s / img. ETA=0:04:18
[03/28 15:50:43] d2.evaluation.evaluator INFO: Inference done 120/1210. 0.0468 s / img. ETA=0:04:10
[03/28 15:50:48] d2.evaluation.evaluator INFO: Inference done 144/1210. 0.0468 s / img. ETA=0:04:00
[03/28 15:50:53] d2.evaluation.evaluator INFO: Inference done 165/1210. 0.0467 s / img. ETA=0:03:58
[03/28 15:50:58] d2.evaluation.evaluator INFO: Inference done 184/1210. 0.0465 s / img. ETA=0:03:58
[03/28 15:51:06] d2.evaluation.evaluator INFO: Inference done 197/1210. 0.0468 s / img. ETA=0:04:20
[03/28 15:51:11] d2.evaluation.evaluator INFO: Inference done 219/1210. 0.0471 s / img. ETA=0:04:11
[03/28 15:51:16] d2.evaluation.evaluator INFO: Inference done 239/1210. 0.0470 s / img. ETA=0:04:08
[03/28 15:51:21] d2.evaluation.evaluator INFO: Inference done 261/1210. 0.0472 s / img. ETA=0:04:00
[03/28 15:51:26] d2.evaluation.evaluator INFO: Inference done 284/1210. 0.0473 s / img. ETA=0:03:52
[03/28 15:51:32] d2.evaluation.evaluator INFO: Inference done 304/1210. 0.0475 s / img. ETA=0:03:47
[03/28 15:51:37] d2.evaluation.evaluator INFO: Inference done 327/1210. 0.0475 s / img. ETA=0:03:40
[03/28 15:51:42] d2.evaluation.evaluator INFO: Inference done 337/1210. 0.0474 s / img. ETA=0:03:44
[03/28 15:51:47] d2.evaluation.evaluator INFO: Inference done 361/1210. 0.0474 s / img. ETA=0:03:35
[03/28 15:51:53] d2.evaluation.evaluator INFO: Inference done 379/1210. 0.0473 s / img. ETA=0:03:35
[03/28 15:51:58] d2.evaluation.evaluator INFO: Inference done 398/1210. 0.0472 s / img. ETA=0:03:30
[03/28 15:52:03] d2.evaluation.evaluator INFO: Inference done 419/1210. 0.0471 s / img. ETA=0:03:24
[03/28 15:52:09] d2.evaluation.evaluator INFO: Inference done 440/1210. 0.0470 s / img. ETA=0:03:18
[03/28 15:52:14] d2.evaluation.evaluator INFO: Inference done 460/1210. 0.0468 s / img. ETA=0:03:13
[03/28 15:52:19] d2.evaluation.evaluator INFO: Inference done 476/1210. 0.0467 s / img. ETA=0:03:10
[03/28 15:52:24] d2.evaluation.evaluator INFO: Inference done 501/1210. 0.0468 s / img. ETA=0:03:02
[03/28 15:52:29] d2.evaluation.evaluator INFO: Inference done 520/1210. 0.0467 s / img. ETA=0:02:57
[03/28 15:52:34] d2.evaluation.evaluator INFO: Inference done 536/1210. 0.0467 s / img. ETA=0:02:54
[03/28 15:52:43] d2.evaluation.evaluator INFO: Inference done 559/1210. 0.0468 s / img. ETA=0:02:52
[03/28 15:52:50] d2.evaluation.evaluator INFO: Inference done 578/1210. 0.0468 s / img. ETA=0:02:49
[03/28 15:52:55] d2.evaluation.evaluator INFO: Inference done 606/1210. 0.0469 s / img. ETA=0:02:39
[03/28 15:53:00] d2.evaluation.evaluator INFO: Inference done 629/1210. 0.0469 s / img. ETA=0:02:32
[03/28 15:53:05] d2.evaluation.evaluator INFO: Inference done 653/1210. 0.0468 s / img. ETA=0:02:24
[03/28 15:53:10] d2.evaluation.evaluator INFO: Inference done 676/1210. 0.0468 s / img. ETA=0:02:18
[03/28 15:53:18] d2.evaluation.evaluator INFO: Inference done 693/1210. 0.0467 s / img. ETA=0:02:16
[03/28 15:53:23] d2.evaluation.evaluator INFO: Inference done 707/1210. 0.0467 s / img. ETA=0:02:14
[03/28 15:53:29] d2.evaluation.evaluator INFO: Inference done 728/1210. 0.0467 s / img. ETA=0:02:08
[03/28 15:53:34] d2.evaluation.evaluator INFO: Inference done 735/1210. 0.0467 s / img. ETA=0:02:08
[03/28 15:53:39] d2.evaluation.evaluator INFO: Inference done 761/1210. 0.0468 s / img. ETA=0:02:00
[03/28 15:53:45] d2.evaluation.evaluator INFO: Inference done 775/1210. 0.0467 s / img. ETA=0:01:58
[03/28 15:53:51] d2.evaluation.evaluator INFO: Inference done 792/1210. 0.0466 s / img. ETA=0:01:53
[03/28 15:53:58] d2.evaluation.evaluator INFO: Inference done 803/1210. 0.0466 s / img. ETA=0:01:53
[03/28 15:54:03] d2.evaluation.evaluator INFO: Inference done 821/1210. 0.0465 s / img. ETA=0:01:48
[03/28 15:54:10] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0465 s / img. ETA=0:01:50
[03/28 15:54:17] d2.evaluation.evaluator INFO: Inference done 832/1210. 0.0466 s / img. ETA=0:01:50
[03/28 15:54:25] d2.evaluation.evaluator INFO: Inference done 854/1210. 0.0466 s / img. ETA=0:01:44
[03/28 15:54:30] d2.evaluation.evaluator INFO: Inference done 874/1210. 0.0466 s / img. ETA=0:01:38
[03/28 15:54:35] d2.evaluation.evaluator INFO: Inference done 894/1210. 0.0466 s / img. ETA=0:01:32
[03/28 15:54:41] d2.evaluation.evaluator INFO: Inference done 916/1210. 0.0467 s / img. ETA=0:01:25
[03/28 15:54:46] d2.evaluation.evaluator INFO: Inference done 940/1210. 0.0467 s / img. ETA=0:01:17
[03/28 15:54:53] d2.evaluation.evaluator INFO: Inference done 958/1210. 0.0467 s / img. ETA=0:01:13
[03/28 15:54:58] d2.evaluation.evaluator INFO: Inference done 976/1210. 0.0467 s / img. ETA=0:01:07
[03/28 15:55:03] d2.evaluation.evaluator INFO: Inference done 987/1210. 0.0468 s / img. ETA=0:01:05
[03/28 15:55:09] d2.evaluation.evaluator INFO: Inference done 1003/1210. 0.0468 s / img. ETA=0:01:00
[03/28 15:55:15] d2.evaluation.evaluator INFO: Inference done 1013/1210. 0.0468 s / img. ETA=0:00:58
[03/28 15:55:21] d2.evaluation.evaluator INFO: Inference done 1032/1210. 0.0467 s / img. ETA=0:00:52
[03/28 15:55:26] d2.evaluation.evaluator INFO: Inference done 1056/1210. 0.0467 s / img. ETA=0:00:45
[03/28 15:55:31] d2.evaluation.evaluator INFO: Inference done 1082/1210. 0.0467 s / img. ETA=0:00:37
[03/28 15:55:37] d2.evaluation.evaluator INFO: Inference done 1095/1210. 0.0467 s / img. ETA=0:00:33
[03/28 15:55:42] d2.evaluation.evaluator INFO: Inference done 1119/1210. 0.0468 s / img. ETA=0:00:26
[03/28 15:55:47] d2.evaluation.evaluator INFO: Inference done 1142/1210. 0.0468 s / img. ETA=0:00:19
[03/28 15:55:53] d2.evaluation.evaluator INFO: Inference done 1164/1210. 0.0468 s / img. ETA=0:00:13
[03/28 15:55:58] d2.evaluation.evaluator INFO: Inference done 1183/1210. 0.0468 s / img. ETA=0:00:07
[03/28 15:56:03] d2.evaluation.evaluator INFO: Inference done 1201/1210. 0.0468 s / img. ETA=0:00:02
[03/28 15:56:05] d2.evaluation.evaluator INFO: Total inference time: 0:05:48.962036 (0.289595 s / img per device, on 1 devices)
[03/28 15:56:05] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:56 (0.046738 s / img per device, on 1 devices)
[03/28 15:56:06] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/28 15:56:06] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/28 15:56:06] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/28 15:56:07] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.100 | 63.741 | 55.805 | 33.686 | 19.435 | 42.923 |
[03/28 15:56:07] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/28 15:56:07] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/28 15:56:07] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/28 15:56:07] d2.evaluation.testing INFO: copypaste: 45.0999,63.7411,55.8049,33.6856,19.4349,42.9234
[03/28 15:56:07] d2.utils.events INFO:  eta: 4:52:42  iter: 7999  total_loss: 0.147  loss_cls: 0.059  loss_box_reg: 0.066  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 2.0046  data_time: 1.1082  lr: 0.001000  max_mem: 9421M
[03/28 15:56:38] d2.utils.events INFO:  eta: 4:50:21  iter: 8019  total_loss: 0.126  loss_cls: 0.046  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0034  data_time: 0.9875  lr: 0.001000  max_mem: 9421M
[03/28 15:57:18] d2.utils.events INFO:  eta: 4:49:23  iter: 8039  total_loss: 0.130  loss_cls: 0.046  loss_box_reg: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.015  time: 2.0034  data_time: 1.4289  lr: 0.001000  max_mem: 9421M
[03/28 15:58:04] d2.utils.events INFO:  eta: 4:48:48  iter: 8059  total_loss: 0.143  loss_cls: 0.049  loss_box_reg: 0.063  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  time: 2.0041  data_time: 1.7282  lr: 0.001000  max_mem: 9421M
[03/28 15:58:43] d2.utils.events INFO:  eta: 4:47:17  iter: 8079  total_loss: 0.147  loss_cls: 0.048  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 2.0041  data_time: 1.4141  lr: 0.001000  max_mem: 9421M
[03/28 15:59:26] d2.utils.events INFO:  eta: 4:45:14  iter: 8099  total_loss: 0.169  loss_cls: 0.053  loss_box_reg: 0.071  loss_rpn_cls: 0.005  loss_rpn_loc: 0.023  time: 2.0044  data_time: 1.5483  lr: 0.001000  max_mem: 9421M
[03/28 16:00:04] d2.utils.events INFO:  eta: 4:43:53  iter: 8119  total_loss: 0.136  loss_cls: 0.046  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 2.0041  data_time: 1.3164  lr: 0.001000  max_mem: 9421M
[03/28 16:00:49] d2.utils.events INFO:  eta: 4:43:45  iter: 8139  total_loss: 0.149  loss_cls: 0.050  loss_box_reg: 0.066  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 2.0047  data_time: 1.6713  lr: 0.001000  max_mem: 9421M
[03/28 16:01:31] d2.utils.events INFO:  eta: 4:44:05  iter: 8159  total_loss: 0.124  loss_cls: 0.043  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0050  data_time: 1.5387  lr: 0.001000  max_mem: 9421M
[03/28 16:02:11] d2.utils.events INFO:  eta: 4:44:05  iter: 8179  total_loss: 0.137  loss_cls: 0.044  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 2.0050  data_time: 1.4720  lr: 0.001000  max_mem: 9421M
[03/28 16:02:59] d2.utils.events INFO:  eta: 4:44:00  iter: 8199  total_loss: 0.134  loss_cls: 0.047  loss_box_reg: 0.056  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0059  data_time: 1.8293  lr: 0.001000  max_mem: 9421M
[03/28 16:03:40] d2.utils.events INFO:  eta: 4:44:11  iter: 8219  total_loss: 0.153  loss_cls: 0.045  loss_box_reg: 0.056  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 2.0061  data_time: 1.4812  lr: 0.001000  max_mem: 9421M
[03/28 16:04:14] d2.utils.events INFO:  eta: 4:43:31  iter: 8239  total_loss: 0.122  loss_cls: 0.043  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0052  data_time: 1.0981  lr: 0.001000  max_mem: 9421M
[03/28 16:04:54] d2.utils.events INFO:  eta: 4:42:16  iter: 8259  total_loss: 0.144  loss_cls: 0.055  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 2.0052  data_time: 1.4535  lr: 0.001000  max_mem: 9421M
[03/28 16:05:36] d2.utils.events INFO:  eta: 4:42:21  iter: 8279  total_loss: 0.140  loss_cls: 0.047  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 2.0055  data_time: 1.5768  lr: 0.001000  max_mem: 9421M
[03/28 16:06:14] d2.utils.events INFO:  eta: 4:41:30  iter: 8299  total_loss: 0.152  loss_cls: 0.052  loss_box_reg: 0.068  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 2.0052  data_time: 1.3186  lr: 0.001000  max_mem: 9421M
[03/28 16:06:51] d2.utils.events INFO:  eta: 4:40:36  iter: 8319  total_loss: 0.136  loss_cls: 0.047  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 2.0049  data_time: 1.3320  lr: 0.001000  max_mem: 9421M
[03/28 16:07:27] d2.utils.events INFO:  eta: 4:40:41  iter: 8339  total_loss: 0.145  loss_cls: 0.048  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 2.0043  data_time: 1.2140  lr: 0.001000  max_mem: 9421M
[03/28 16:08:04] d2.utils.events INFO:  eta: 4:41:05  iter: 8359  total_loss: 0.156  loss_cls: 0.049  loss_box_reg: 0.065  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 2.0040  data_time: 1.3135  lr: 0.001000  max_mem: 9421M
[03/28 16:08:42] d2.utils.events INFO:  eta: 4:40:30  iter: 8379  total_loss: 0.141  loss_cls: 0.049  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 2.0038  data_time: 1.3488  lr: 0.001000  max_mem: 9421M
[03/28 16:09:14] d2.utils.events INFO:  eta: 4:39:10  iter: 8399  total_loss: 0.145  loss_cls: 0.053  loss_box_reg: 0.065  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 2.0027  data_time: 1.0204  lr: 0.001000  max_mem: 9421M
[03/28 16:10:06] d2.utils.events INFO:  eta: 4:38:51  iter: 8419  total_loss: 0.130  loss_cls: 0.050  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 2.0036  data_time: 1.8100  lr: 0.001000  max_mem: 9421M
[03/28 16:10:49] d2.utils.events INFO:  eta: 4:37:48  iter: 8439  total_loss: 0.128  loss_cls: 0.044  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 2.0040  data_time: 1.5900  lr: 0.001000  max_mem: 9421M
[03/28 16:11:31] d2.utils.events INFO:  eta: 4:37:25  iter: 8459  total_loss: 0.139  loss_cls: 0.046  loss_box_reg: 0.068  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 2.0036  data_time: 1.2608  lr: 0.001000  max_mem: 9421M
[03/28 16:12:03] d2.utils.events INFO:  eta: 4:35:57  iter: 8479  total_loss: 0.147  loss_cls: 0.049  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 2.0027  data_time: 1.0673  lr: 0.001000  max_mem: 9421M
[03/28 16:12:45] d2.utils.events INFO:  eta: 4:35:43  iter: 8499  total_loss: 0.115  loss_cls: 0.037  loss_box_reg: 0.054  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0029  data_time: 1.5301  lr: 0.001000  max_mem: 9421M
[03/28 16:13:22] d2.utils.events INFO:  eta: 4:35:26  iter: 8519  total_loss: 0.130  loss_cls: 0.044  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 2.0025  data_time: 1.2601  lr: 0.001000  max_mem: 9421M
[03/28 16:13:59] d2.utils.events INFO:  eta: 4:34:51  iter: 8539  total_loss: 0.149  loss_cls: 0.050  loss_box_reg: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 2.0021  data_time: 1.2849  lr: 0.001000  max_mem: 9421M
[03/28 16:14:47] d2.utils.events INFO:  eta: 4:34:19  iter: 8559  total_loss: 0.128  loss_cls: 0.043  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 2.0030  data_time: 1.8234  lr: 0.001000  max_mem: 9421M
[03/28 16:15:25] d2.utils.events INFO:  eta: 4:33:20  iter: 8579  total_loss: 0.133  loss_cls: 0.051  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 2.0028  data_time: 1.3278  lr: 0.001000  max_mem: 9421M
[03/28 16:16:07] d2.utils.events INFO:  eta: 4:33:06  iter: 8599  total_loss: 0.125  loss_cls: 0.045  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 2.0030  data_time: 1.5348  lr: 0.001000  max_mem: 9421M
[03/28 16:16:48] d2.utils.events INFO:  eta: 4:30:48  iter: 8619  total_loss: 0.136  loss_cls: 0.048  loss_box_reg: 0.072  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 2.0030  data_time: 1.4596  lr: 0.001000  max_mem: 9421M
[03/28 16:17:29] d2.utils.events INFO:  eta: 4:30:37  iter: 8639  total_loss: 0.143  loss_cls: 0.046  loss_box_reg: 0.068  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0032  data_time: 1.5088  lr: 0.001000  max_mem: 9421M
[03/28 16:18:16] d2.utils.events INFO:  eta: 4:29:15  iter: 8659  total_loss: 0.126  loss_cls: 0.041  loss_box_reg: 0.053  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 2.0040  data_time: 1.7757  lr: 0.001000  max_mem: 9421M
[03/28 16:18:52] d2.utils.events INFO:  eta: 4:30:26  iter: 8679  total_loss: 0.149  loss_cls: 0.052  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0035  data_time: 1.2268  lr: 0.001000  max_mem: 9421M
[03/28 16:19:33] d2.utils.events INFO:  eta: 4:29:04  iter: 8699  total_loss: 0.131  loss_cls: 0.043  loss_box_reg: 0.053  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 2.0036  data_time: 1.4626  lr: 0.001000  max_mem: 9421M
[03/28 16:20:10] d2.utils.events INFO:  eta: 4:27:31  iter: 8719  total_loss: 0.150  loss_cls: 0.046  loss_box_reg: 0.066  loss_rpn_cls: 0.005  loss_rpn_loc: 0.029  time: 2.0032  data_time: 1.2905  lr: 0.001000  max_mem: 9421M
[03/28 16:20:44] d2.utils.events INFO:  eta: 4:26:57  iter: 8739  total_loss: 0.132  loss_cls: 0.049  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 2.0025  data_time: 1.1346  lr: 0.001000  max_mem: 9421M
[03/28 16:21:30] d2.utils.events INFO:  eta: 4:26:46  iter: 8759  total_loss: 0.138  loss_cls: 0.049  loss_box_reg: 0.064  loss_rpn_cls: 0.007  loss_rpn_loc: 0.024  time: 2.0032  data_time: 1.6969  lr: 0.001000  max_mem: 9421M
[03/28 16:22:02] d2.utils.events INFO:  eta: 4:25:47  iter: 8779  total_loss: 0.150  loss_cls: 0.052  loss_box_reg: 0.066  loss_rpn_cls: 0.005  loss_rpn_loc: 0.024  time: 2.0024  data_time: 1.0926  lr: 0.001000  max_mem: 9421M
[03/28 16:22:39] d2.utils.events INFO:  eta: 4:24:06  iter: 8799  total_loss: 0.123  loss_cls: 0.044  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 2.0019  data_time: 1.2649  lr: 0.001000  max_mem: 9421M
[03/28 16:23:18] d2.utils.events INFO:  eta: 4:24:36  iter: 8819  total_loss: 0.148  loss_cls: 0.054  loss_box_reg: 0.064  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 2.0018  data_time: 1.3825  lr: 0.001000  max_mem: 9421M
[03/28 16:23:59] d2.utils.events INFO:  eta: 4:23:00  iter: 8839  total_loss: 0.129  loss_cls: 0.044  loss_box_reg: 0.058  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0020  data_time: 1.5133  lr: 0.001000  max_mem: 9421M
[03/28 16:24:43] d2.utils.events INFO:  eta: 4:21:42  iter: 8859  total_loss: 0.117  loss_cls: 0.043  loss_box_reg: 0.055  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 2.0024  data_time: 1.5999  lr: 0.001000  max_mem: 9421M
[03/28 16:25:21] d2.utils.events INFO:  eta: 4:20:22  iter: 8879  total_loss: 0.144  loss_cls: 0.048  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 2.0022  data_time: 1.3639  lr: 0.001000  max_mem: 9421M
[03/28 16:26:17] d2.utils.events INFO:  eta: 4:19:10  iter: 8899  total_loss: 0.141  loss_cls: 0.049  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.025  time: 2.0040  data_time: 2.2485  lr: 0.001000  max_mem: 9421M
[03/28 16:26:56] d2.utils.events INFO:  eta: 4:18:07  iter: 8919  total_loss: 0.144  loss_cls: 0.047  loss_box_reg: 0.055  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 2.0038  data_time: 1.3376  lr: 0.001000  max_mem: 9421M
[03/28 16:27:37] d2.utils.events INFO:  eta: 4:18:02  iter: 8939  total_loss: 0.146  loss_cls: 0.051  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 2.0040  data_time: 1.5069  lr: 0.001000  max_mem: 9421M
[03/28 16:28:17] d2.utils.events INFO:  eta: 4:15:22  iter: 8959  total_loss: 0.131  loss_cls: 0.045  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 2.0039  data_time: 1.3872  lr: 0.001000  max_mem: 9421M
[03/28 16:28:53] d2.utils.events INFO:  eta: 4:14:48  iter: 8979  total_loss: 0.140  loss_cls: 0.051  loss_box_reg: 0.073  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 2.0035  data_time: 1.2755  lr: 0.001000  max_mem: 9421M
[03/28 16:29:31] d2.utils.events INFO:  eta: 4:15:30  iter: 8999  total_loss: 0.123  loss_cls: 0.044  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 2.0032  data_time: 1.3420  lr: 0.001000  max_mem: 9421M
[03/28 16:30:10] d2.utils.events INFO:  eta: 4:15:58  iter: 9019  total_loss: 0.152  loss_cls: 0.047  loss_box_reg: 0.069  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0031  data_time: 1.3964  lr: 0.001000  max_mem: 9421M
[03/28 16:30:59] d2.utils.events INFO:  eta: 4:15:34  iter: 9039  total_loss: 0.127  loss_cls: 0.040  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.024  time: 2.0041  data_time: 1.9181  lr: 0.001000  max_mem: 9421M
[03/28 16:31:33] d2.utils.events INFO:  eta: 4:14:23  iter: 9059  total_loss: 0.135  loss_cls: 0.047  loss_box_reg: 0.055  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 2.0034  data_time: 1.1028  lr: 0.001000  max_mem: 9421M
[03/28 16:32:11] d2.utils.events INFO:  eta: 4:13:53  iter: 9079  total_loss: 0.129  loss_cls: 0.046  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 2.0032  data_time: 1.3500  lr: 0.001000  max_mem: 9421M
[03/28 16:32:58] d2.utils.events INFO:  eta: 4:13:29  iter: 9099  total_loss: 0.121  loss_cls: 0.039  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 2.0036  data_time: 1.6107  lr: 0.001000  max_mem: 9421M
[03/28 16:33:31] d2.utils.events INFO:  eta: 4:13:17  iter: 9119  total_loss: 0.129  loss_cls: 0.045  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 2.0029  data_time: 1.1022  lr: 0.001000  max_mem: 9421M
[03/28 16:34:17] d2.utils.events INFO:  eta: 4:12:20  iter: 9139  total_loss: 0.152  loss_cls: 0.046  loss_box_reg: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 2.0035  data_time: 1.7226  lr: 0.001000  max_mem: 9421M
[03/28 16:34:58] d2.utils.events INFO:  eta: 4:11:59  iter: 9159  total_loss: 0.126  loss_cls: 0.045  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 2.0035  data_time: 1.4762  lr: 0.001000  max_mem: 9421M
[03/28 16:35:33] d2.utils.events INFO:  eta: 4:11:02  iter: 9179  total_loss: 0.123  loss_cls: 0.043  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 2.0030  data_time: 1.2279  lr: 0.001000  max_mem: 9421M
[03/28 16:36:13] d2.utils.events INFO:  eta: 4:10:24  iter: 9199  total_loss: 0.146  loss_cls: 0.049  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 2.0030  data_time: 1.4469  lr: 0.001000  max_mem: 9421M
[03/28 16:36:49] d2.utils.events INFO:  eta: 4:09:34  iter: 9219  total_loss: 0.129  loss_cls: 0.043  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0025  data_time: 1.2037  lr: 0.001000  max_mem: 9421M
[03/28 16:37:36] d2.utils.events INFO:  eta: 4:09:12  iter: 9239  total_loss: 0.143  loss_cls: 0.048  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.026  time: 2.0033  data_time: 1.8366  lr: 0.001000  max_mem: 9421M
[03/28 16:38:12] d2.utils.events INFO:  eta: 4:08:38  iter: 9259  total_loss: 0.135  loss_cls: 0.042  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 2.0029  data_time: 1.2455  lr: 0.001000  max_mem: 9421M
[03/28 16:38:48] d2.utils.events INFO:  eta: 4:07:52  iter: 9279  total_loss: 0.130  loss_cls: 0.045  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 2.0024  data_time: 1.1905  lr: 0.001000  max_mem: 9421M
[03/28 16:39:26] d2.utils.events INFO:  eta: 4:07:30  iter: 9299  total_loss: 0.135  loss_cls: 0.044  loss_box_reg: 0.058  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 2.0021  data_time: 1.3126  lr: 0.001000  max_mem: 9421M
[03/28 16:40:06] d2.utils.events INFO:  eta: 4:07:03  iter: 9319  total_loss: 0.125  loss_cls: 0.045  loss_box_reg: 0.051  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  time: 2.0021  data_time: 1.3984  lr: 0.001000  max_mem: 9421M
[03/28 16:40:45] d2.utils.events INFO:  eta: 4:06:09  iter: 9339  total_loss: 0.147  loss_cls: 0.047  loss_box_reg: 0.065  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 2.0020  data_time: 1.4019  lr: 0.001000  max_mem: 9421M
[03/28 16:41:29] d2.utils.events INFO:  eta: 4:05:19  iter: 9359  total_loss: 0.132  loss_cls: 0.041  loss_box_reg: 0.067  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 2.0024  data_time: 1.6667  lr: 0.001000  max_mem: 9421M
[03/28 16:42:23] d2.utils.events INFO:  eta: 4:04:44  iter: 9379  total_loss: 0.134  loss_cls: 0.041  loss_box_reg: 0.058  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 2.0039  data_time: 2.1541  lr: 0.001000  max_mem: 9421M
[03/28 16:42:58] d2.utils.events INFO:  eta: 4:04:47  iter: 9399  total_loss: 0.149  loss_cls: 0.050  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.025  time: 2.0034  data_time: 1.1944  lr: 0.001000  max_mem: 9421M
[03/28 16:43:35] d2.utils.events INFO:  eta: 4:04:08  iter: 9419  total_loss: 0.137  loss_cls: 0.050  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  time: 2.0030  data_time: 1.2325  lr: 0.001000  max_mem: 9421M
[03/28 16:44:08] d2.utils.events INFO:  eta: 4:03:31  iter: 9439  total_loss: 0.133  loss_cls: 0.043  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 2.0023  data_time: 1.0897  lr: 0.001000  max_mem: 9421M
[03/28 16:44:45] d2.utils.events INFO:  eta: 4:03:00  iter: 9459  total_loss: 0.118  loss_cls: 0.041  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 2.0019  data_time: 1.2582  lr: 0.001000  max_mem: 9421M
[03/28 16:45:20] d2.utils.events INFO:  eta: 4:02:45  iter: 9479  total_loss: 0.130  loss_cls: 0.044  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 2.0014  data_time: 1.2243  lr: 0.001000  max_mem: 9421M
[03/28 16:45:57] d2.utils.events INFO:  eta: 4:01:52  iter: 9499  total_loss: 0.134  loss_cls: 0.049  loss_box_reg: 0.058  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0011  data_time: 1.2794  lr: 0.001000  max_mem: 9421M
[03/28 16:46:39] d2.utils.events INFO:  eta: 4:01:31  iter: 9519  total_loss: 0.140  loss_cls: 0.048  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 2.0014  data_time: 1.5630  lr: 0.001000  max_mem: 9421M
[03/28 16:47:16] d2.utils.events INFO:  eta: 4:00:48  iter: 9539  total_loss: 0.145  loss_cls: 0.048  loss_box_reg: 0.065  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 2.0010  data_time: 1.2827  lr: 0.001000  max_mem: 9421M
[03/28 16:47:50] d2.utils.events INFO:  eta: 4:00:06  iter: 9559  total_loss: 0.113  loss_cls: 0.041  loss_box_reg: 0.056  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 2.0004  data_time: 1.1516  lr: 0.001000  max_mem: 9421M
[03/28 16:48:33] d2.utils.events INFO:  eta: 3:59:32  iter: 9579  total_loss: 0.148  loss_cls: 0.049  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 2.0007  data_time: 1.5928  lr: 0.001000  max_mem: 9421M
[03/28 16:49:06] d2.utils.events INFO:  eta: 3:58:30  iter: 9599  total_loss: 0.128  loss_cls: 0.045  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 1.9999  data_time: 1.0667  lr: 0.001000  max_mem: 9421M
[03/28 16:49:40] d2.utils.events INFO:  eta: 3:57:26  iter: 9619  total_loss: 0.123  loss_cls: 0.041  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9994  data_time: 1.1924  lr: 0.001000  max_mem: 9421M
[03/28 16:50:28] d2.utils.events INFO:  eta: 3:56:52  iter: 9639  total_loss: 0.139  loss_cls: 0.046  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 2.0001  data_time: 1.7934  lr: 0.001000  max_mem: 9421M
[03/28 16:51:12] d2.utils.events INFO:  eta: 3:57:02  iter: 9659  total_loss: 0.128  loss_cls: 0.040  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 2.0005  data_time: 1.6397  lr: 0.001000  max_mem: 9421M
[03/28 16:51:51] d2.utils.events INFO:  eta: 3:55:44  iter: 9679  total_loss: 0.143  loss_cls: 0.048  loss_box_reg: 0.070  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 2.0005  data_time: 1.4222  lr: 0.001000  max_mem: 9421M
[03/28 16:52:29] d2.utils.events INFO:  eta: 3:54:32  iter: 9699  total_loss: 0.117  loss_cls: 0.039  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 2.0003  data_time: 1.3133  lr: 0.001000  max_mem: 9421M
[03/28 16:53:17] d2.utils.events INFO:  eta: 3:53:59  iter: 9719  total_loss: 0.129  loss_cls: 0.043  loss_box_reg: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 2.0010  data_time: 1.8177  lr: 0.001000  max_mem: 9421M
[03/28 16:53:59] d2.utils.events INFO:  eta: 3:54:55  iter: 9739  total_loss: 0.152  loss_cls: 0.046  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.028  time: 2.0012  data_time: 1.4938  lr: 0.001000  max_mem: 9421M
[03/28 16:54:40] d2.utils.events INFO:  eta: 3:54:41  iter: 9759  total_loss: 0.137  loss_cls: 0.049  loss_box_reg: 0.066  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 2.0014  data_time: 1.5360  lr: 0.001000  max_mem: 9421M
[03/28 16:55:27] d2.utils.events INFO:  eta: 3:55:00  iter: 9779  total_loss: 0.142  loss_cls: 0.047  loss_box_reg: 0.073  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 2.0021  data_time: 1.7693  lr: 0.001000  max_mem: 9421M
[03/28 16:56:14] d2.utils.events INFO:  eta: 3:55:06  iter: 9799  total_loss: 0.143  loss_cls: 0.047  loss_box_reg: 0.068  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 2.0028  data_time: 1.7397  lr: 0.001000  max_mem: 9421M
[03/28 16:56:59] d2.utils.events INFO:  eta: 3:54:52  iter: 9819  total_loss: 0.151  loss_cls: 0.050  loss_box_reg: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 2.0033  data_time: 1.6533  lr: 0.001000  max_mem: 9421M
[03/28 16:57:45] d2.utils.events INFO:  eta: 3:54:36  iter: 9839  total_loss: 0.144  loss_cls: 0.049  loss_box_reg: 0.067  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 2.0039  data_time: 1.7077  lr: 0.001000  max_mem: 9421M
[03/28 16:58:32] d2.utils.events INFO:  eta: 3:54:49  iter: 9859  total_loss: 0.130  loss_cls: 0.044  loss_box_reg: 0.050  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 2.0046  data_time: 1.7969  lr: 0.001000  max_mem: 9421M
[03/28 16:59:12] d2.utils.events INFO:  eta: 3:54:47  iter: 9879  total_loss: 0.132  loss_cls: 0.047  loss_box_reg: 0.055  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0046  data_time: 1.4118  lr: 0.001000  max_mem: 9421M
[03/28 16:59:48] d2.utils.events INFO:  eta: 3:53:59  iter: 9899  total_loss: 0.127  loss_cls: 0.041  loss_box_reg: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 2.0042  data_time: 1.2399  lr: 0.001000  max_mem: 9421M
[03/28 17:00:22] d2.utils.events INFO:  eta: 3:53:05  iter: 9919  total_loss: 0.143  loss_cls: 0.048  loss_box_reg: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 2.0035  data_time: 1.1298  lr: 0.001000  max_mem: 9421M
[03/28 17:00:56] d2.utils.events INFO:  eta: 3:51:05  iter: 9939  total_loss: 0.123  loss_cls: 0.044  loss_box_reg: 0.058  loss_rpn_cls: 0.004  loss_rpn_loc: 0.016  time: 2.0029  data_time: 1.1321  lr: 0.001000  max_mem: 9421M
[03/28 17:01:30] d2.utils.events INFO:  eta: 3:50:31  iter: 9959  total_loss: 0.123  loss_cls: 0.039  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 2.0024  data_time: 1.1665  lr: 0.001000  max_mem: 9421M
[03/28 17:02:05] d2.utils.events INFO:  eta: 3:49:57  iter: 9979  total_loss: 0.136  loss_cls: 0.040  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.028  time: 2.0018  data_time: 1.1542  lr: 0.001000  max_mem: 9421M
[03/28 17:02:48] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/28 17:02:48] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/28 17:02:48] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/28 17:02:48] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/28 17:02:50] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0482 s / img. ETA=0:02:54
[03/28 17:02:55] d2.evaluation.evaluator INFO: Inference done 32/1210. 0.0465 s / img. ETA=0:04:23
[03/28 17:03:00] d2.evaluation.evaluator INFO: Inference done 56/1210. 0.0462 s / img. ETA=0:04:12
[03/28 17:03:06] d2.evaluation.evaluator INFO: Inference done 77/1210. 0.0457 s / img. ETA=0:04:18
[03/28 17:03:11] d2.evaluation.evaluator INFO: Inference done 98/1210. 0.0462 s / img. ETA=0:04:18
[03/28 17:03:16] d2.evaluation.evaluator INFO: Inference done 121/1210. 0.0469 s / img. ETA=0:04:10
[03/28 17:03:21] d2.evaluation.evaluator INFO: Inference done 145/1210. 0.0468 s / img. ETA=0:04:02
[03/28 17:03:27] d2.evaluation.evaluator INFO: Inference done 165/1210. 0.0470 s / img. ETA=0:04:04
[03/28 17:03:32] d2.evaluation.evaluator INFO: Inference done 183/1210. 0.0468 s / img. ETA=0:04:07
[03/28 17:03:38] d2.evaluation.evaluator INFO: Inference done 202/1210. 0.0470 s / img. ETA=0:04:07
[03/28 17:03:43] d2.evaluation.evaluator INFO: Inference done 227/1210. 0.0471 s / img. ETA=0:03:56
[03/28 17:03:48] d2.evaluation.evaluator INFO: Inference done 245/1210. 0.0469 s / img. ETA=0:03:54
[03/28 17:03:53] d2.evaluation.evaluator INFO: Inference done 269/1210. 0.0469 s / img. ETA=0:03:46
[03/28 17:03:58] d2.evaluation.evaluator INFO: Inference done 290/1210. 0.0472 s / img. ETA=0:03:41
[03/28 17:04:06] d2.evaluation.evaluator INFO: Inference done 304/1210. 0.0473 s / img. ETA=0:03:52
[03/28 17:04:11] d2.evaluation.evaluator INFO: Inference done 313/1210. 0.0473 s / img. ETA=0:03:57
[03/28 17:04:16] d2.evaluation.evaluator INFO: Inference done 336/1210. 0.0474 s / img. ETA=0:03:49
[03/28 17:04:21] d2.evaluation.evaluator INFO: Inference done 358/1210. 0.0474 s / img. ETA=0:03:41
[03/28 17:04:27] d2.evaluation.evaluator INFO: Inference done 372/1210. 0.0474 s / img. ETA=0:03:42
[03/28 17:04:32] d2.evaluation.evaluator INFO: Inference done 388/1210. 0.0473 s / img. ETA=0:03:41
[03/28 17:04:37] d2.evaluation.evaluator INFO: Inference done 406/1210. 0.0471 s / img. ETA=0:03:36
[03/28 17:04:43] d2.evaluation.evaluator INFO: Inference done 429/1210. 0.0471 s / img. ETA=0:03:28
[03/28 17:04:48] d2.evaluation.evaluator INFO: Inference done 450/1210. 0.0471 s / img. ETA=0:03:22
[03/28 17:04:53] d2.evaluation.evaluator INFO: Inference done 467/1210. 0.0471 s / img. ETA=0:03:19
[03/28 17:04:58] d2.evaluation.evaluator INFO: Inference done 486/1210. 0.0470 s / img. ETA=0:03:14
[03/28 17:05:03] d2.evaluation.evaluator INFO: Inference done 506/1210. 0.0470 s / img. ETA=0:03:08
[03/28 17:05:08] d2.evaluation.evaluator INFO: Inference done 523/1210. 0.0469 s / img. ETA=0:03:04
[03/28 17:05:13] d2.evaluation.evaluator INFO: Inference done 545/1210. 0.0469 s / img. ETA=0:02:57
[03/28 17:05:18] d2.evaluation.evaluator INFO: Inference done 563/1210. 0.0469 s / img. ETA=0:02:52
[03/28 17:05:24] d2.evaluation.evaluator INFO: Inference done 578/1210. 0.0468 s / img. ETA=0:02:50
[03/28 17:05:29] d2.evaluation.evaluator INFO: Inference done 605/1210. 0.0468 s / img. ETA=0:02:40
[03/28 17:05:35] d2.evaluation.evaluator INFO: Inference done 611/1210. 0.0468 s / img. ETA=0:02:44
[03/28 17:05:40] d2.evaluation.evaluator INFO: Inference done 637/1210. 0.0469 s / img. ETA=0:02:35
[03/28 17:05:45] d2.evaluation.evaluator INFO: Inference done 663/1210. 0.0468 s / img. ETA=0:02:26
[03/28 17:05:51] d2.evaluation.evaluator INFO: Inference done 684/1210. 0.0468 s / img. ETA=0:02:20
[03/28 17:05:57] d2.evaluation.evaluator INFO: Inference done 698/1210. 0.0468 s / img. ETA=0:02:19
[03/28 17:06:03] d2.evaluation.evaluator INFO: Inference done 713/1210. 0.0467 s / img. ETA=0:02:15
[03/28 17:06:08] d2.evaluation.evaluator INFO: Inference done 737/1210. 0.0467 s / img. ETA=0:02:08
[03/28 17:06:13] d2.evaluation.evaluator INFO: Inference done 760/1210. 0.0467 s / img. ETA=0:02:01
[03/28 17:06:18] d2.evaluation.evaluator INFO: Inference done 785/1210. 0.0466 s / img. ETA=0:01:53
[03/28 17:06:23] d2.evaluation.evaluator INFO: Inference done 803/1210. 0.0466 s / img. ETA=0:01:49
[03/28 17:06:34] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0465 s / img. ETA=0:01:46
[03/28 17:06:39] d2.evaluation.evaluator INFO: Inference done 844/1210. 0.0465 s / img. ETA=0:01:40
[03/28 17:06:45] d2.evaluation.evaluator INFO: Inference done 866/1210. 0.0465 s / img. ETA=0:01:34
[03/28 17:06:50] d2.evaluation.evaluator INFO: Inference done 888/1210. 0.0464 s / img. ETA=0:01:27
[03/28 17:06:55] d2.evaluation.evaluator INFO: Inference done 912/1210. 0.0464 s / img. ETA=0:01:20
[03/28 17:07:00] d2.evaluation.evaluator INFO: Inference done 935/1210. 0.0464 s / img. ETA=0:01:14
[03/28 17:07:05] d2.evaluation.evaluator INFO: Inference done 960/1210. 0.0464 s / img. ETA=0:01:06
[03/28 17:07:10] d2.evaluation.evaluator INFO: Inference done 980/1210. 0.0464 s / img. ETA=0:01:01
[03/28 17:07:15] d2.evaluation.evaluator INFO: Inference done 996/1210. 0.0464 s / img. ETA=0:00:57
[03/28 17:07:20] d2.evaluation.evaluator INFO: Inference done 1014/1210. 0.0464 s / img. ETA=0:00:52
[03/28 17:07:25] d2.evaluation.evaluator INFO: Inference done 1034/1210. 0.0463 s / img. ETA=0:00:47
[03/28 17:07:30] d2.evaluation.evaluator INFO: Inference done 1057/1210. 0.0463 s / img. ETA=0:00:40
[03/28 17:07:36] d2.evaluation.evaluator INFO: Inference done 1083/1210. 0.0463 s / img. ETA=0:00:33
[03/28 17:07:41] d2.evaluation.evaluator INFO: Inference done 1106/1210. 0.0463 s / img. ETA=0:00:27
[03/28 17:07:46] d2.evaluation.evaluator INFO: Inference done 1132/1210. 0.0464 s / img. ETA=0:00:20
[03/28 17:07:51] d2.evaluation.evaluator INFO: Inference done 1155/1210. 0.0464 s / img. ETA=0:00:14
[03/28 17:07:56] d2.evaluation.evaluator INFO: Inference done 1173/1210. 0.0464 s / img. ETA=0:00:09
[03/28 17:08:01] d2.evaluation.evaluator INFO: Inference done 1191/1210. 0.0464 s / img. ETA=0:00:04
[03/28 17:08:06] d2.evaluation.evaluator INFO: Inference done 1208/1210. 0.0464 s / img. ETA=0:00:00
[03/28 17:08:07] d2.evaluation.evaluator INFO: Total inference time: 0:05:17.338419 (0.263351 s / img per device, on 1 devices)
[03/28 17:08:07] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:55 (0.046386 s / img per device, on 1 devices)
[03/28 17:08:07] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/28 17:08:07] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/28 17:08:07] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/28 17:08:08] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.901 | 63.669 | 55.559 | 33.180 | 21.188 | 43.079 |
[03/28 17:08:08] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/28 17:08:08] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/28 17:08:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/28 17:08:08] d2.evaluation.testing INFO: copypaste: 44.9007,63.6692,55.5589,33.1795,21.1885,43.0795
[03/28 17:08:08] d2.utils.events INFO:  eta: 3:49:00  iter: 9999  total_loss: 0.128  loss_cls: 0.050  loss_box_reg: 0.061  loss_rpn_cls: 0.006  loss_rpn_loc: 0.017  time: 2.0021  data_time: 1.5826  lr: 0.001000  max_mem: 9421M
[03/28 17:08:47] d2.utils.events INFO:  eta: 3:48:09  iter: 10019  total_loss: 0.129  loss_cls: 0.042  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 2.0020  data_time: 1.3435  lr: 0.001000  max_mem: 9421M
[03/28 17:09:29] d2.utils.events INFO:  eta: 3:46:39  iter: 10039  total_loss: 0.122  loss_cls: 0.044  loss_box_reg: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 2.0021  data_time: 1.5014  lr: 0.001000  max_mem: 9421M
[03/28 17:10:00] d2.utils.events INFO:  eta: 3:46:24  iter: 10059  total_loss: 0.136  loss_cls: 0.047  loss_box_reg: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 2.0013  data_time: 1.0023  lr: 0.001000  max_mem: 9421M
[03/28 17:10:37] d2.utils.events INFO:  eta: 3:46:23  iter: 10079  total_loss: 0.143  loss_cls: 0.046  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 2.0009  data_time: 1.2839  lr: 0.001000  max_mem: 9421M
[03/28 17:11:11] d2.utils.events INFO:  eta: 3:45:49  iter: 10099  total_loss: 0.131  loss_cls: 0.045  loss_box_reg: 0.059  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0004  data_time: 1.1296  lr: 0.001000  max_mem: 9421M
[03/28 17:11:48] d2.utils.events INFO:  eta: 3:45:17  iter: 10119  total_loss: 0.143  loss_cls: 0.045  loss_box_reg: 0.071  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 2.0000  data_time: 1.2586  lr: 0.001000  max_mem: 9421M
[03/28 17:12:28] d2.utils.events INFO:  eta: 3:44:40  iter: 10139  total_loss: 0.147  loss_cls: 0.044  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 2.0001  data_time: 1.4362  lr: 0.001000  max_mem: 9421M
[03/28 17:13:03] d2.utils.events INFO:  eta: 3:43:42  iter: 10159  total_loss: 0.134  loss_cls: 0.041  loss_box_reg: 0.067  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9996  data_time: 1.1734  lr: 0.001000  max_mem: 9421M
[03/28 17:13:48] d2.utils.events INFO:  eta: 3:43:44  iter: 10179  total_loss: 0.133  loss_cls: 0.041  loss_box_reg: 0.065  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 2.0000  data_time: 1.6442  lr: 0.001000  max_mem: 9421M
[03/28 17:14:26] d2.utils.events INFO:  eta: 3:42:34  iter: 10199  total_loss: 0.134  loss_cls: 0.043  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9999  data_time: 1.3879  lr: 0.001000  max_mem: 9421M
[03/28 17:14:59] d2.utils.events INFO:  eta: 3:40:04  iter: 10219  total_loss: 0.139  loss_cls: 0.043  loss_box_reg: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.016  time: 1.9992  data_time: 1.0601  lr: 0.001000  max_mem: 9421M
[03/28 17:15:34] d2.utils.events INFO:  eta: 3:38:49  iter: 10239  total_loss: 0.140  loss_cls: 0.052  loss_box_reg: 0.066  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9986  data_time: 1.1727  lr: 0.001000  max_mem: 9421M
[03/28 17:16:11] d2.utils.events INFO:  eta: 3:38:41  iter: 10259  total_loss: 0.143  loss_cls: 0.051  loss_box_reg: 0.070  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9984  data_time: 1.2875  lr: 0.001000  max_mem: 9421M
[03/28 17:16:55] d2.utils.events INFO:  eta: 3:37:53  iter: 10279  total_loss: 0.135  loss_cls: 0.042  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.9987  data_time: 1.6142  lr: 0.001000  max_mem: 9421M
[03/28 17:17:34] d2.utils.events INFO:  eta: 3:36:50  iter: 10299  total_loss: 0.121  loss_cls: 0.040  loss_box_reg: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9986  data_time: 1.3746  lr: 0.001000  max_mem: 9421M
[03/28 17:18:14] d2.utils.events INFO:  eta: 3:36:11  iter: 10319  total_loss: 0.130  loss_cls: 0.039  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 1.9987  data_time: 1.4737  lr: 0.001000  max_mem: 9421M
[03/28 17:19:01] d2.utils.events INFO:  eta: 3:35:15  iter: 10339  total_loss: 0.128  loss_cls: 0.045  loss_box_reg: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 1.9990  data_time: 1.6006  lr: 0.001000  max_mem: 9421M
[03/28 17:19:38] d2.utils.events INFO:  eta: 3:34:52  iter: 10359  total_loss: 0.134  loss_cls: 0.044  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 1.9988  data_time: 1.3012  lr: 0.001000  max_mem: 9421M
[03/28 17:20:16] d2.utils.events INFO:  eta: 3:34:00  iter: 10379  total_loss: 0.140  loss_cls: 0.046  loss_box_reg: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 1.9986  data_time: 1.3117  lr: 0.001000  max_mem: 9421M
[03/28 17:21:00] d2.utils.events INFO:  eta: 3:32:52  iter: 10399  total_loss: 0.134  loss_cls: 0.045  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 1.9989  data_time: 1.6184  lr: 0.001000  max_mem: 9421M
[03/28 17:21:35] d2.utils.events INFO:  eta: 3:31:47  iter: 10419  total_loss: 0.140  loss_cls: 0.047  loss_box_reg: 0.061  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.9985  data_time: 1.2107  lr: 0.001000  max_mem: 9421M
[03/28 17:22:13] d2.utils.events INFO:  eta: 3:30:50  iter: 10439  total_loss: 0.127  loss_cls: 0.041  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9983  data_time: 1.3119  lr: 0.001000  max_mem: 9421M
[03/28 17:22:58] d2.utils.events INFO:  eta: 3:30:17  iter: 10459  total_loss: 0.144  loss_cls: 0.045  loss_box_reg: 0.066  loss_rpn_cls: 0.003  loss_rpn_loc: 0.023  time: 1.9988  data_time: 1.6697  lr: 0.001000  max_mem: 9421M
[03/28 17:23:33] d2.utils.events INFO:  eta: 3:29:47  iter: 10479  total_loss: 0.129  loss_cls: 0.042  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 1.9983  data_time: 1.1612  lr: 0.001000  max_mem: 9421M
[03/28 17:24:10] d2.utils.events INFO:  eta: 3:29:07  iter: 10499  total_loss: 0.123  loss_cls: 0.043  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 1.9979  data_time: 1.2479  lr: 0.001000  max_mem: 9421M
[03/28 17:24:46] d2.utils.events INFO:  eta: 3:28:32  iter: 10519  total_loss: 0.120  loss_cls: 0.044  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9976  data_time: 1.2288  lr: 0.001000  max_mem: 9421M
[03/28 17:25:26] d2.utils.events INFO:  eta: 3:27:48  iter: 10539  total_loss: 0.126  loss_cls: 0.041  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9976  data_time: 1.4458  lr: 0.001000  max_mem: 9421M
[03/28 17:26:01] d2.utils.events INFO:  eta: 3:27:29  iter: 10559  total_loss: 0.125  loss_cls: 0.037  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9971  data_time: 1.1778  lr: 0.001000  max_mem: 9421M
[03/28 17:26:34] d2.utils.events INFO:  eta: 3:26:35  iter: 10579  total_loss: 0.138  loss_cls: 0.043  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9964  data_time: 1.0667  lr: 0.001000  max_mem: 9421M
[03/28 17:27:09] d2.utils.events INFO:  eta: 3:26:18  iter: 10599  total_loss: 0.136  loss_cls: 0.045  loss_box_reg: 0.057  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 1.9960  data_time: 1.1970  lr: 0.001000  max_mem: 9421M
[03/28 17:27:54] d2.utils.events INFO:  eta: 3:25:53  iter: 10619  total_loss: 0.127  loss_cls: 0.044  loss_box_reg: 0.058  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9964  data_time: 1.6595  lr: 0.001000  max_mem: 9421M
[03/28 17:28:29] d2.utils.events INFO:  eta: 3:25:09  iter: 10639  total_loss: 0.144  loss_cls: 0.049  loss_box_reg: 0.069  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 1.9960  data_time: 1.1718  lr: 0.001000  max_mem: 9421M
[03/28 17:29:04] d2.utils.events INFO:  eta: 3:24:16  iter: 10659  total_loss: 0.125  loss_cls: 0.039  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9956  data_time: 1.1946  lr: 0.001000  max_mem: 9421M
[03/28 17:29:50] d2.utils.events INFO:  eta: 3:23:48  iter: 10679  total_loss: 0.129  loss_cls: 0.041  loss_box_reg: 0.058  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9961  data_time: 1.7318  lr: 0.001000  max_mem: 9421M
[03/28 17:30:31] d2.utils.events INFO:  eta: 3:23:21  iter: 10699  total_loss: 0.129  loss_cls: 0.043  loss_box_reg: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9960  data_time: 1.3801  lr: 0.001000  max_mem: 9421M
[03/28 17:31:03] d2.utils.events INFO:  eta: 3:21:57  iter: 10719  total_loss: 0.137  loss_cls: 0.046  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9953  data_time: 1.0233  lr: 0.001000  max_mem: 9421M
[03/28 17:31:40] d2.utils.events INFO:  eta: 3:20:19  iter: 10739  total_loss: 0.126  loss_cls: 0.044  loss_box_reg: 0.054  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9950  data_time: 1.2733  lr: 0.001000  max_mem: 9421M
[03/28 17:32:14] d2.utils.events INFO:  eta: 3:18:09  iter: 10759  total_loss: 0.122  loss_cls: 0.043  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.016  time: 1.9945  data_time: 1.1536  lr: 0.001000  max_mem: 9421M
[03/28 17:32:48] d2.utils.events INFO:  eta: 3:17:02  iter: 10779  total_loss: 0.139  loss_cls: 0.045  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9939  data_time: 1.1134  lr: 0.001000  max_mem: 9421M
[03/28 17:33:24] d2.utils.events INFO:  eta: 3:16:17  iter: 10799  total_loss: 0.142  loss_cls: 0.047  loss_box_reg: 0.068  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 1.9935  data_time: 1.2299  lr: 0.001000  max_mem: 9421M
[03/28 17:33:58] d2.utils.events INFO:  eta: 3:14:52  iter: 10819  total_loss: 0.123  loss_cls: 0.040  loss_box_reg: 0.054  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9930  data_time: 1.1636  lr: 0.001000  max_mem: 9421M
[03/28 17:34:42] d2.utils.events INFO:  eta: 3:14:19  iter: 10839  total_loss: 0.138  loss_cls: 0.044  loss_box_reg: 0.066  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 1.9934  data_time: 1.6353  lr: 0.001000  max_mem: 9421M
[03/28 17:35:27] d2.utils.events INFO:  eta: 3:13:27  iter: 10859  total_loss: 0.119  loss_cls: 0.038  loss_box_reg: 0.057  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 1.9939  data_time: 1.6480  lr: 0.001000  max_mem: 9421M
[03/28 17:36:09] d2.utils.events INFO:  eta: 3:12:21  iter: 10879  total_loss: 0.131  loss_cls: 0.043  loss_box_reg: 0.065  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 1.9940  data_time: 1.5220  lr: 0.001000  max_mem: 9421M
[03/28 17:36:44] d2.utils.events INFO:  eta: 3:11:51  iter: 10899  total_loss: 0.121  loss_cls: 0.039  loss_box_reg: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 1.9935  data_time: 1.1564  lr: 0.001000  max_mem: 9421M
[03/28 17:37:16] d2.utils.events INFO:  eta: 3:11:49  iter: 10919  total_loss: 0.115  loss_cls: 0.039  loss_box_reg: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9928  data_time: 1.0424  lr: 0.001000  max_mem: 9421M
[03/28 17:37:56] d2.utils.events INFO:  eta: 3:11:32  iter: 10939  total_loss: 0.127  loss_cls: 0.042  loss_box_reg: 0.066  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 1.9928  data_time: 1.3766  lr: 0.001000  max_mem: 9421M
[03/28 17:38:37] d2.utils.events INFO:  eta: 3:11:16  iter: 10959  total_loss: 0.141  loss_cls: 0.043  loss_box_reg: 0.061  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 1.9929  data_time: 1.5076  lr: 0.001000  max_mem: 9421M
[03/28 17:39:13] d2.utils.events INFO:  eta: 3:11:11  iter: 10979  total_loss: 0.135  loss_cls: 0.045  loss_box_reg: 0.061  loss_rpn_cls: 0.006  loss_rpn_loc: 0.024  time: 1.9926  data_time: 1.2187  lr: 0.001000  max_mem: 9421M
[03/28 17:39:48] d2.utils.events INFO:  eta: 3:10:58  iter: 10999  total_loss: 0.122  loss_cls: 0.041  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9921  data_time: 1.1515  lr: 0.001000  max_mem: 9421M
[03/28 17:40:20] d2.utils.events INFO:  eta: 3:09:38  iter: 11019  total_loss: 0.118  loss_cls: 0.036  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9915  data_time: 1.0671  lr: 0.001000  max_mem: 9421M
[03/28 17:41:03] d2.utils.events INFO:  eta: 3:08:44  iter: 11039  total_loss: 0.125  loss_cls: 0.042  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9917  data_time: 1.5249  lr: 0.001000  max_mem: 9421M
[03/28 17:41:43] d2.utils.events INFO:  eta: 3:08:48  iter: 11059  total_loss: 0.128  loss_cls: 0.040  loss_box_reg: 0.055  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9917  data_time: 1.4209  lr: 0.001000  max_mem: 9421M
[03/28 17:42:22] d2.utils.events INFO:  eta: 3:08:00  iter: 11079  total_loss: 0.126  loss_cls: 0.042  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9916  data_time: 1.3479  lr: 0.001000  max_mem: 9421M
[03/28 17:43:00] d2.utils.events INFO:  eta: 3:07:43  iter: 11099  total_loss: 0.120  loss_cls: 0.039  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9915  data_time: 1.3357  lr: 0.001000  max_mem: 9421M
[03/28 17:43:38] d2.utils.events INFO:  eta: 3:06:24  iter: 11119  total_loss: 0.149  loss_cls: 0.047  loss_box_reg: 0.067  loss_rpn_cls: 0.003  loss_rpn_loc: 0.026  time: 1.9913  data_time: 1.3079  lr: 0.001000  max_mem: 9421M
[03/28 17:44:20] d2.utils.events INFO:  eta: 3:05:37  iter: 11139  total_loss: 0.129  loss_cls: 0.038  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9915  data_time: 1.5299  lr: 0.001000  max_mem: 9421M
[03/28 17:45:01] d2.utils.events INFO:  eta: 3:05:34  iter: 11159  total_loss: 0.152  loss_cls: 0.045  loss_box_reg: 0.066  loss_rpn_cls: 0.005  loss_rpn_loc: 0.022  time: 1.9916  data_time: 1.4671  lr: 0.001000  max_mem: 9421M
[03/28 17:45:43] d2.utils.events INFO:  eta: 3:04:07  iter: 11179  total_loss: 0.132  loss_cls: 0.042  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9918  data_time: 1.5735  lr: 0.001000  max_mem: 9421M
[03/28 17:46:22] d2.utils.events INFO:  eta: 3:03:35  iter: 11199  total_loss: 0.134  loss_cls: 0.042  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9918  data_time: 1.3762  lr: 0.001000  max_mem: 9421M
[03/28 17:47:01] d2.utils.events INFO:  eta: 3:03:22  iter: 11219  total_loss: 0.149  loss_cls: 0.050  loss_box_reg: 0.071  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9916  data_time: 1.3280  lr: 0.001000  max_mem: 9421M
[03/28 17:47:34] d2.utils.events INFO:  eta: 3:03:24  iter: 11239  total_loss: 0.127  loss_cls: 0.042  loss_box_reg: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 1.9911  data_time: 1.1386  lr: 0.001000  max_mem: 9421M
[03/28 17:48:09] d2.utils.events INFO:  eta: 3:02:26  iter: 11259  total_loss: 0.121  loss_cls: 0.038  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9906  data_time: 1.1666  lr: 0.001000  max_mem: 9421M
[03/28 17:48:48] d2.utils.events INFO:  eta: 3:01:35  iter: 11279  total_loss: 0.143  loss_cls: 0.046  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9906  data_time: 1.3912  lr: 0.001000  max_mem: 9421M
[03/28 17:49:21] d2.utils.events INFO:  eta: 3:00:53  iter: 11299  total_loss: 0.121  loss_cls: 0.041  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 1.9899  data_time: 1.0427  lr: 0.001000  max_mem: 9421M
[03/28 17:49:54] d2.utils.events INFO:  eta: 3:00:09  iter: 11319  total_loss: 0.124  loss_cls: 0.041  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9894  data_time: 1.0919  lr: 0.001000  max_mem: 9421M
[03/28 17:50:38] d2.utils.events INFO:  eta: 2:59:40  iter: 11339  total_loss: 0.136  loss_cls: 0.035  loss_box_reg: 0.069  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 1.9897  data_time: 1.6005  lr: 0.001000  max_mem: 9421M
[03/28 17:51:15] d2.utils.events INFO:  eta: 2:59:10  iter: 11359  total_loss: 0.126  loss_cls: 0.042  loss_box_reg: 0.068  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 1.9894  data_time: 1.2612  lr: 0.001000  max_mem: 9421M
[03/28 17:51:49] d2.utils.events INFO:  eta: 2:58:43  iter: 11379  total_loss: 0.136  loss_cls: 0.038  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9889  data_time: 1.1393  lr: 0.001000  max_mem: 9421M
[03/28 17:52:35] d2.utils.events INFO:  eta: 2:58:13  iter: 11399  total_loss: 0.134  loss_cls: 0.043  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 1.9895  data_time: 1.7385  lr: 0.001000  max_mem: 9421M
[03/28 17:53:26] d2.utils.events INFO:  eta: 2:57:40  iter: 11419  total_loss: 0.127  loss_cls: 0.041  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9904  data_time: 1.9746  lr: 0.001000  max_mem: 9421M
[03/28 17:54:01] d2.utils.events INFO:  eta: 2:57:15  iter: 11439  total_loss: 0.119  loss_cls: 0.040  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9901  data_time: 1.2052  lr: 0.001000  max_mem: 9421M
[03/28 17:54:48] d2.utils.events INFO:  eta: 2:56:43  iter: 11459  total_loss: 0.132  loss_cls: 0.045  loss_box_reg: 0.056  loss_rpn_cls: 0.004  loss_rpn_loc: 0.016  time: 1.9907  data_time: 1.7804  lr: 0.001000  max_mem: 9421M
[03/28 17:55:26] d2.utils.events INFO:  eta: 2:56:25  iter: 11479  total_loss: 0.133  loss_cls: 0.045  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 1.9905  data_time: 1.2934  lr: 0.001000  max_mem: 9421M
[03/28 17:55:58] d2.utils.events INFO:  eta: 2:55:29  iter: 11499  total_loss: 0.135  loss_cls: 0.042  loss_box_reg: 0.067  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 1.9898  data_time: 1.0516  lr: 0.001000  max_mem: 9421M
[03/28 17:56:33] d2.utils.events INFO:  eta: 2:54:45  iter: 11519  total_loss: 0.124  loss_cls: 0.037  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9894  data_time: 1.2024  lr: 0.001000  max_mem: 9421M
[03/28 17:57:16] d2.utils.events INFO:  eta: 2:54:13  iter: 11539  total_loss: 0.132  loss_cls: 0.043  loss_box_reg: 0.062  loss_rpn_cls: 0.004  loss_rpn_loc: 0.012  time: 1.9897  data_time: 1.5461  lr: 0.001000  max_mem: 9421M
[03/28 17:57:50] d2.utils.events INFO:  eta: 2:53:41  iter: 11559  total_loss: 0.124  loss_cls: 0.039  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9892  data_time: 1.1592  lr: 0.001000  max_mem: 9421M
[03/28 17:58:24] d2.utils.events INFO:  eta: 2:53:19  iter: 11579  total_loss: 0.133  loss_cls: 0.044  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9886  data_time: 1.1214  lr: 0.001000  max_mem: 9421M
[03/28 17:58:57] d2.utils.events INFO:  eta: 2:52:39  iter: 11599  total_loss: 0.119  loss_cls: 0.041  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9881  data_time: 1.1053  lr: 0.001000  max_mem: 9421M
[03/28 17:59:31] d2.utils.events INFO:  eta: 2:52:03  iter: 11619  total_loss: 0.129  loss_cls: 0.040  loss_box_reg: 0.058  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9876  data_time: 1.1272  lr: 0.001000  max_mem: 9421M
[03/28 18:00:10] d2.utils.events INFO:  eta: 2:51:37  iter: 11639  total_loss: 0.120  loss_cls: 0.042  loss_box_reg: 0.052  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9875  data_time: 1.3962  lr: 0.001000  max_mem: 9421M
[03/28 18:00:54] d2.utils.events INFO:  eta: 2:51:04  iter: 11659  total_loss: 0.126  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.004  loss_rpn_loc: 0.023  time: 1.9879  data_time: 1.6219  lr: 0.001000  max_mem: 9421M
[03/28 18:01:39] d2.utils.events INFO:  eta: 2:50:20  iter: 11679  total_loss: 0.141  loss_cls: 0.048  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 1.9883  data_time: 1.6348  lr: 0.001000  max_mem: 9421M
[03/28 18:02:20] d2.utils.events INFO:  eta: 2:49:40  iter: 11699  total_loss: 0.120  loss_cls: 0.037  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9884  data_time: 1.4740  lr: 0.001000  max_mem: 9421M
[03/28 18:02:55] d2.utils.events INFO:  eta: 2:49:30  iter: 11719  total_loss: 0.122  loss_cls: 0.038  loss_box_reg: 0.054  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9881  data_time: 1.2353  lr: 0.001000  max_mem: 9421M
[03/28 18:03:33] d2.utils.events INFO:  eta: 2:49:00  iter: 11739  total_loss: 0.108  loss_cls: 0.037  loss_box_reg: 0.053  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9879  data_time: 1.3204  lr: 0.001000  max_mem: 9421M
[03/28 18:04:11] d2.utils.events INFO:  eta: 2:48:45  iter: 11759  total_loss: 0.135  loss_cls: 0.044  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 1.9877  data_time: 1.3028  lr: 0.001000  max_mem: 9421M
[03/28 18:04:45] d2.utils.events INFO:  eta: 2:48:54  iter: 11779  total_loss: 0.140  loss_cls: 0.044  loss_box_reg: 0.068  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9873  data_time: 1.1397  lr: 0.001000  max_mem: 9421M
[03/28 18:05:25] d2.utils.events INFO:  eta: 2:48:50  iter: 11799  total_loss: 0.138  loss_cls: 0.048  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9872  data_time: 1.3994  lr: 0.001000  max_mem: 9421M
[03/28 18:06:13] d2.utils.events INFO:  eta: 2:49:36  iter: 11819  total_loss: 0.121  loss_cls: 0.038  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9880  data_time: 1.8706  lr: 0.001000  max_mem: 9421M
[03/28 18:07:04] d2.utils.events INFO:  eta: 2:49:19  iter: 11839  total_loss: 0.115  loss_cls: 0.038  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.016  time: 1.9886  data_time: 1.8027  lr: 0.001000  max_mem: 9421M
[03/28 18:07:50] d2.utils.events INFO:  eta: 2:49:49  iter: 11859  total_loss: 0.122  loss_cls: 0.038  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9892  data_time: 1.7425  lr: 0.001000  max_mem: 9421M
[03/28 18:08:45] d2.utils.events INFO:  eta: 2:49:44  iter: 11879  total_loss: 0.149  loss_cls: 0.046  loss_box_reg: 0.065  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 1.9904  data_time: 2.1163  lr: 0.001000  max_mem: 9421M
[03/28 18:09:26] d2.utils.events INFO:  eta: 2:49:13  iter: 11899  total_loss: 0.115  loss_cls: 0.043  loss_box_reg: 0.055  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9906  data_time: 1.4754  lr: 0.001000  max_mem: 9421M
[03/28 18:10:15] d2.utils.events INFO:  eta: 2:49:58  iter: 11919  total_loss: 0.132  loss_cls: 0.046  loss_box_reg: 0.066  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9913  data_time: 1.8734  lr: 0.001000  max_mem: 9421M
[03/28 18:10:57] d2.utils.events INFO:  eta: 2:49:24  iter: 11939  total_loss: 0.132  loss_cls: 0.042  loss_box_reg: 0.068  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 1.9912  data_time: 1.3191  lr: 0.001000  max_mem: 9421M
[03/28 18:11:32] d2.utils.events INFO:  eta: 2:48:50  iter: 11959  total_loss: 0.141  loss_cls: 0.045  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9908  data_time: 1.1475  lr: 0.001000  max_mem: 9421M
[03/28 18:12:07] d2.utils.events INFO:  eta: 2:47:28  iter: 11979  total_loss: 0.153  loss_cls: 0.056  loss_box_reg: 0.069  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9904  data_time: 1.2096  lr: 0.001000  max_mem: 9421M
[03/28 18:12:44] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/lr0.001_finetune/model_0011999.pth
[03/28 18:12:47] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/28 18:12:47] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/28 18:12:47] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/28 18:12:47] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/28 18:12:49] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0484 s / img. ETA=0:02:54
[03/28 18:12:55] d2.evaluation.evaluator INFO: Inference done 17/1210. 0.0481 s / img. ETA=0:11:31
[03/28 18:13:00] d2.evaluation.evaluator INFO: Inference done 38/1210. 0.0457 s / img. ETA=0:07:05
[03/28 18:13:05] d2.evaluation.evaluator INFO: Inference done 60/1210. 0.0454 s / img. ETA=0:05:59
[03/28 18:13:11] d2.evaluation.evaluator INFO: Inference done 65/1210. 0.0454 s / img. ETA=0:07:22
[03/28 18:13:16] d2.evaluation.evaluator INFO: Inference done 87/1210. 0.0456 s / img. ETA=0:06:30
[03/28 18:13:21] d2.evaluation.evaluator INFO: Inference done 109/1210. 0.0462 s / img. ETA=0:05:55
[03/28 18:13:26] d2.evaluation.evaluator INFO: Inference done 135/1210. 0.0465 s / img. ETA=0:05:18
[03/28 18:13:32] d2.evaluation.evaluator INFO: Inference done 155/1210. 0.0464 s / img. ETA=0:05:08
[03/28 18:13:37] d2.evaluation.evaluator INFO: Inference done 163/1210. 0.0465 s / img. ETA=0:05:24
[03/28 18:13:42] d2.evaluation.evaluator INFO: Inference done 180/1210. 0.0469 s / img. ETA=0:05:18
[03/28 18:13:47] d2.evaluation.evaluator INFO: Inference done 198/1210. 0.0470 s / img. ETA=0:05:10
[03/28 18:13:52] d2.evaluation.evaluator INFO: Inference done 221/1210. 0.0470 s / img. ETA=0:04:54
[03/28 18:13:57] d2.evaluation.evaluator INFO: Inference done 239/1210. 0.0468 s / img. ETA=0:04:48
[03/28 18:14:02] d2.evaluation.evaluator INFO: Inference done 263/1210. 0.0467 s / img. ETA=0:04:33
[03/28 18:14:08] d2.evaluation.evaluator INFO: Inference done 285/1210. 0.0469 s / img. ETA=0:04:23
[03/28 18:14:13] d2.evaluation.evaluator INFO: Inference done 308/1210. 0.0471 s / img. ETA=0:04:12
[03/28 18:14:18] d2.evaluation.evaluator INFO: Inference done 332/1210. 0.0470 s / img. ETA=0:04:01
[03/28 18:14:23] d2.evaluation.evaluator INFO: Inference done 355/1210. 0.0469 s / img. ETA=0:03:52
[03/28 18:14:28] d2.evaluation.evaluator INFO: Inference done 378/1210. 0.0469 s / img. ETA=0:03:43
[03/28 18:14:33] d2.evaluation.evaluator INFO: Inference done 390/1210. 0.0468 s / img. ETA=0:03:44
[03/28 18:14:38] d2.evaluation.evaluator INFO: Inference done 409/1210. 0.0468 s / img. ETA=0:03:39
[03/28 18:14:44] d2.evaluation.evaluator INFO: Inference done 433/1210. 0.0467 s / img. ETA=0:03:30
[03/28 18:14:49] d2.evaluation.evaluator INFO: Inference done 455/1210. 0.0466 s / img. ETA=0:03:24
[03/28 18:14:55] d2.evaluation.evaluator INFO: Inference done 474/1210. 0.0466 s / img. ETA=0:03:20
[03/28 18:15:00] d2.evaluation.evaluator INFO: Inference done 498/1210. 0.0467 s / img. ETA=0:03:11
[03/28 18:15:05] d2.evaluation.evaluator INFO: Inference done 517/1210. 0.0466 s / img. ETA=0:03:06
[03/28 18:15:12] d2.evaluation.evaluator INFO: Inference done 529/1210. 0.0466 s / img. ETA=0:03:07
[03/28 18:15:17] d2.evaluation.evaluator INFO: Inference done 551/1210. 0.0465 s / img. ETA=0:03:00
[03/28 18:15:22] d2.evaluation.evaluator INFO: Inference done 570/1210. 0.0465 s / img. ETA=0:02:54
[03/28 18:15:27] d2.evaluation.evaluator INFO: Inference done 586/1210. 0.0465 s / img. ETA=0:02:51
[03/28 18:15:32] d2.evaluation.evaluator INFO: Inference done 608/1210. 0.0465 s / img. ETA=0:02:44
[03/28 18:15:37] d2.evaluation.evaluator INFO: Inference done 637/1210. 0.0464 s / img. ETA=0:02:33
[03/28 18:15:45] d2.evaluation.evaluator INFO: Inference done 657/1210. 0.0464 s / img. ETA=0:02:30
[03/28 18:15:51] d2.evaluation.evaluator INFO: Inference done 666/1210. 0.0465 s / img. ETA=0:02:30
[03/28 18:15:56] d2.evaluation.evaluator INFO: Inference done 681/1210. 0.0465 s / img. ETA=0:02:27
[03/28 18:16:01] d2.evaluation.evaluator INFO: Inference done 697/1210. 0.0465 s / img. ETA=0:02:23
[03/28 18:16:06] d2.evaluation.evaluator INFO: Inference done 713/1210. 0.0465 s / img. ETA=0:02:19
[03/28 18:16:11] d2.evaluation.evaluator INFO: Inference done 737/1210. 0.0465 s / img. ETA=0:02:11
[03/28 18:16:17] d2.evaluation.evaluator INFO: Inference done 754/1210. 0.0464 s / img. ETA=0:02:07
[03/28 18:16:22] d2.evaluation.evaluator INFO: Inference done 780/1210. 0.0464 s / img. ETA=0:01:59
[03/28 18:16:27] d2.evaluation.evaluator INFO: Inference done 796/1210. 0.0463 s / img. ETA=0:01:55
[03/28 18:16:32] d2.evaluation.evaluator INFO: Inference done 812/1210. 0.0463 s / img. ETA=0:01:50
[03/28 18:16:41] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0463 s / img. ETA=0:01:50
[03/28 18:16:46] d2.evaluation.evaluator INFO: Inference done 842/1210. 0.0463 s / img. ETA=0:01:44
[03/28 18:16:51] d2.evaluation.evaluator INFO: Inference done 864/1210. 0.0464 s / img. ETA=0:01:38
[03/28 18:16:56] d2.evaluation.evaluator INFO: Inference done 885/1210. 0.0464 s / img. ETA=0:01:31
[03/28 18:17:02] d2.evaluation.evaluator INFO: Inference done 909/1210. 0.0465 s / img. ETA=0:01:24
[03/28 18:17:07] d2.evaluation.evaluator INFO: Inference done 933/1210. 0.0466 s / img. ETA=0:01:17
[03/28 18:17:12] d2.evaluation.evaluator INFO: Inference done 957/1210. 0.0466 s / img. ETA=0:01:10
[03/28 18:17:17] d2.evaluation.evaluator INFO: Inference done 965/1210. 0.0466 s / img. ETA=0:01:08
[03/28 18:17:22] d2.evaluation.evaluator INFO: Inference done 984/1210. 0.0467 s / img. ETA=0:01:03
[03/28 18:17:27] d2.evaluation.evaluator INFO: Inference done 1000/1210. 0.0467 s / img. ETA=0:00:59
[03/28 18:17:34] d2.evaluation.evaluator INFO: Inference done 1010/1210. 0.0467 s / img. ETA=0:00:57
[03/28 18:17:39] d2.evaluation.evaluator INFO: Inference done 1026/1210. 0.0467 s / img. ETA=0:00:52
[03/28 18:17:44] d2.evaluation.evaluator INFO: Inference done 1052/1210. 0.0467 s / img. ETA=0:00:44
[03/28 18:17:53] d2.evaluation.evaluator INFO: Inference done 1077/1210. 0.0468 s / img. ETA=0:00:37
[03/28 18:17:58] d2.evaluation.evaluator INFO: Inference done 1098/1210. 0.0468 s / img. ETA=0:00:31
[03/28 18:18:03] d2.evaluation.evaluator INFO: Inference done 1123/1210. 0.0468 s / img. ETA=0:00:24
[03/28 18:18:13] d2.evaluation.evaluator INFO: Inference done 1145/1210. 0.0468 s / img. ETA=0:00:18
[03/28 18:18:18] d2.evaluation.evaluator INFO: Inference done 1167/1210. 0.0468 s / img. ETA=0:00:12
[03/28 18:18:24] d2.evaluation.evaluator INFO: Inference done 1184/1210. 0.0468 s / img. ETA=0:00:07
[03/28 18:18:30] d2.evaluation.evaluator INFO: Inference done 1205/1210. 0.0468 s / img. ETA=0:00:01
[03/28 18:18:31] d2.evaluation.evaluator INFO: Total inference time: 0:05:43.116548 (0.284744 s / img per device, on 1 devices)
[03/28 18:18:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:56 (0.046793 s / img per device, on 1 devices)
[03/28 18:18:31] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/28 18:18:31] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/28 18:18:31] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/28 18:18:32] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.544 | 63.780 | 55.568 | 32.593 | 19.427 | 42.603 |
[03/28 18:18:32] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/28 18:18:32] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/28 18:18:32] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/28 18:18:32] d2.evaluation.testing INFO: copypaste: 44.5445,63.7805,55.5684,32.5934,19.4275,42.6030
[03/28 18:18:32] d2.utils.events INFO:  eta: 2:46:20  iter: 11999  total_loss: 0.139  loss_cls: 0.048  loss_box_reg: 0.070  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 1.9901  data_time: 1.2728  lr: 0.001000  max_mem: 9421M
[03/28 18:19:06] d2.utils.events INFO:  eta: 2:45:54  iter: 12019  total_loss: 0.133  loss_cls: 0.039  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9897  data_time: 1.1493  lr: 0.000100  max_mem: 9421M
[03/28 18:19:45] d2.utils.events INFO:  eta: 2:45:47  iter: 12039  total_loss: 0.132  loss_cls: 0.045  loss_box_reg: 0.065  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9896  data_time: 1.3658  lr: 0.000100  max_mem: 9421M
[03/28 18:20:23] d2.utils.events INFO:  eta: 2:45:02  iter: 12059  total_loss: 0.122  loss_cls: 0.038  loss_box_reg: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9894  data_time: 1.3449  lr: 0.000100  max_mem: 9421M
[03/28 18:20:59] d2.utils.events INFO:  eta: 2:44:28  iter: 12079  total_loss: 0.125  loss_cls: 0.036  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9891  data_time: 1.2479  lr: 0.000100  max_mem: 9421M
[03/28 18:21:38] d2.utils.events INFO:  eta: 2:43:38  iter: 12099  total_loss: 0.118  loss_cls: 0.040  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9890  data_time: 1.3616  lr: 0.000100  max_mem: 9421M
[03/28 18:22:10] d2.utils.events INFO:  eta: 2:43:00  iter: 12119  total_loss: 0.116  loss_cls: 0.035  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9884  data_time: 1.0461  lr: 0.000100  max_mem: 9421M
[03/28 18:23:02] d2.utils.events INFO:  eta: 2:43:02  iter: 12139  total_loss: 0.118  loss_cls: 0.034  loss_box_reg: 0.056  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9893  data_time: 2.0113  lr: 0.000100  max_mem: 9421M
[03/28 18:23:39] d2.utils.events INFO:  eta: 2:42:01  iter: 12159  total_loss: 0.114  loss_cls: 0.034  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 1.9891  data_time: 1.3093  lr: 0.000100  max_mem: 9421M
[03/28 18:24:14] d2.utils.events INFO:  eta: 2:41:42  iter: 12179  total_loss: 0.117  loss_cls: 0.037  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9887  data_time: 1.1801  lr: 0.000100  max_mem: 9421M
[03/28 18:24:54] d2.utils.events INFO:  eta: 2:41:20  iter: 12199  total_loss: 0.127  loss_cls: 0.038  loss_box_reg: 0.068  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9887  data_time: 1.4361  lr: 0.000100  max_mem: 9421M
[03/28 18:25:34] d2.utils.events INFO:  eta: 2:40:35  iter: 12219  total_loss: 0.113  loss_cls: 0.034  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9888  data_time: 1.4484  lr: 0.000100  max_mem: 9421M
[03/28 18:26:17] d2.utils.events INFO:  eta: 2:40:02  iter: 12239  total_loss: 0.120  loss_cls: 0.036  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9890  data_time: 1.5612  lr: 0.000100  max_mem: 9421M
[03/28 18:26:53] d2.utils.events INFO:  eta: 2:39:07  iter: 12259  total_loss: 0.126  loss_cls: 0.038  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.022  time: 1.9887  data_time: 1.2178  lr: 0.000100  max_mem: 9421M
[03/28 18:27:30] d2.utils.events INFO:  eta: 2:38:34  iter: 12279  total_loss: 0.121  loss_cls: 0.038  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 1.9884  data_time: 1.2877  lr: 0.000100  max_mem: 9421M
[03/28 18:28:02] d2.utils.events INFO:  eta: 2:37:53  iter: 12299  total_loss: 0.126  loss_cls: 0.042  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9878  data_time: 1.0582  lr: 0.000100  max_mem: 9421M
[03/28 18:28:35] d2.utils.events INFO:  eta: 2:37:27  iter: 12319  total_loss: 0.116  loss_cls: 0.032  loss_box_reg: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 1.9873  data_time: 1.0995  lr: 0.000100  max_mem: 9421M
[03/28 18:29:18] d2.utils.events INFO:  eta: 2:36:54  iter: 12339  total_loss: 0.141  loss_cls: 0.040  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.023  time: 1.9876  data_time: 1.5300  lr: 0.000100  max_mem: 9421M
[03/28 18:29:51] d2.utils.events INFO:  eta: 2:35:57  iter: 12359  total_loss: 0.113  loss_cls: 0.034  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9870  data_time: 1.1174  lr: 0.000100  max_mem: 9421M
[03/28 18:30:26] d2.utils.events INFO:  eta: 2:35:24  iter: 12379  total_loss: 0.118  loss_cls: 0.038  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9866  data_time: 1.1553  lr: 0.000100  max_mem: 9421M
[03/28 18:31:00] d2.utils.events INFO:  eta: 2:34:38  iter: 12399  total_loss: 0.107  loss_cls: 0.035  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9861  data_time: 1.1330  lr: 0.000100  max_mem: 9421M
[03/28 18:31:33] d2.utils.events INFO:  eta: 2:33:53  iter: 12419  total_loss: 0.115  loss_cls: 0.035  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9856  data_time: 1.0927  lr: 0.000100  max_mem: 9421M
[03/28 18:32:15] d2.utils.events INFO:  eta: 2:33:20  iter: 12439  total_loss: 0.105  loss_cls: 0.032  loss_box_reg: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9858  data_time: 1.5399  lr: 0.000100  max_mem: 9421M
[03/28 18:32:49] d2.utils.events INFO:  eta: 2:32:42  iter: 12459  total_loss: 0.114  loss_cls: 0.038  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9853  data_time: 1.1203  lr: 0.000100  max_mem: 9421M
[03/28 18:33:29] d2.utils.events INFO:  eta: 2:32:08  iter: 12479  total_loss: 0.128  loss_cls: 0.038  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9853  data_time: 1.4209  lr: 0.000100  max_mem: 9421M
[03/28 18:34:07] d2.utils.events INFO:  eta: 2:32:21  iter: 12499  total_loss: 0.129  loss_cls: 0.040  loss_box_reg: 0.069  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9852  data_time: 1.3165  lr: 0.000100  max_mem: 9421M
[03/28 18:34:48] d2.utils.events INFO:  eta: 2:32:02  iter: 12519  total_loss: 0.119  loss_cls: 0.035  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9853  data_time: 1.4944  lr: 0.000100  max_mem: 9421M
[03/28 18:35:23] d2.utils.events INFO:  eta: 2:31:42  iter: 12539  total_loss: 0.123  loss_cls: 0.038  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9849  data_time: 1.1844  lr: 0.000100  max_mem: 9421M
[03/28 18:35:58] d2.utils.events INFO:  eta: 2:30:55  iter: 12559  total_loss: 0.126  loss_cls: 0.038  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9846  data_time: 1.1833  lr: 0.000100  max_mem: 9421M
[03/28 18:36:33] d2.utils.events INFO:  eta: 2:30:36  iter: 12579  total_loss: 0.123  loss_cls: 0.037  loss_box_reg: 0.066  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9842  data_time: 1.1690  lr: 0.000100  max_mem: 9421M
[03/28 18:37:05] d2.utils.events INFO:  eta: 2:30:02  iter: 12599  total_loss: 0.115  loss_cls: 0.039  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9836  data_time: 1.0596  lr: 0.000100  max_mem: 9421M
[03/28 18:37:39] d2.utils.events INFO:  eta: 2:29:41  iter: 12619  total_loss: 0.107  loss_cls: 0.034  loss_box_reg: 0.057  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  time: 1.9831  data_time: 1.1142  lr: 0.000100  max_mem: 9421M
[03/28 18:38:10] d2.utils.events INFO:  eta: 2:28:32  iter: 12639  total_loss: 0.129  loss_cls: 0.037  loss_box_reg: 0.060  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 1.9825  data_time: 0.9874  lr: 0.000100  max_mem: 9421M
[03/28 18:38:53] d2.utils.events INFO:  eta: 2:28:34  iter: 12659  total_loss: 0.110  loss_cls: 0.034  loss_box_reg: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9827  data_time: 1.6017  lr: 0.000100  max_mem: 9421M
[03/28 18:39:30] d2.utils.events INFO:  eta: 2:27:49  iter: 12679  total_loss: 0.124  loss_cls: 0.036  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9825  data_time: 1.2738  lr: 0.000100  max_mem: 9421M
[03/28 18:40:03] d2.utils.events INFO:  eta: 2:27:11  iter: 12699  total_loss: 0.124  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9820  data_time: 1.0453  lr: 0.000100  max_mem: 9421M
[03/28 18:40:49] d2.utils.events INFO:  eta: 2:26:15  iter: 12719  total_loss: 0.126  loss_cls: 0.039  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9825  data_time: 1.7380  lr: 0.000100  max_mem: 9421M
[03/28 18:41:23] d2.utils.events INFO:  eta: 2:25:42  iter: 12739  total_loss: 0.126  loss_cls: 0.037  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9820  data_time: 1.1404  lr: 0.000100  max_mem: 9421M
[03/28 18:42:00] d2.utils.events INFO:  eta: 2:25:12  iter: 12759  total_loss: 0.120  loss_cls: 0.038  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9818  data_time: 1.2735  lr: 0.000100  max_mem: 9421M
[03/28 18:42:37] d2.utils.events INFO:  eta: 2:24:37  iter: 12779  total_loss: 0.118  loss_cls: 0.033  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9816  data_time: 1.2800  lr: 0.000100  max_mem: 9421M
[03/28 18:43:11] d2.utils.events INFO:  eta: 2:23:55  iter: 12799  total_loss: 0.120  loss_cls: 0.039  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9812  data_time: 1.1087  lr: 0.000100  max_mem: 9421M
[03/28 18:43:46] d2.utils.events INFO:  eta: 2:22:43  iter: 12819  total_loss: 0.117  loss_cls: 0.036  loss_box_reg: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9808  data_time: 1.1350  lr: 0.000100  max_mem: 9421M
[03/28 18:44:21] d2.utils.events INFO:  eta: 2:21:46  iter: 12839  total_loss: 0.120  loss_cls: 0.039  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9805  data_time: 1.2340  lr: 0.000100  max_mem: 9421M
[03/28 18:45:03] d2.utils.events INFO:  eta: 2:21:11  iter: 12859  total_loss: 0.120  loss_cls: 0.034  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9807  data_time: 1.5204  lr: 0.000100  max_mem: 9421M
[03/28 18:45:42] d2.utils.events INFO:  eta: 2:20:06  iter: 12879  total_loss: 0.117  loss_cls: 0.036  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9806  data_time: 1.3756  lr: 0.000100  max_mem: 9421M
[03/28 18:46:20] d2.utils.events INFO:  eta: 2:18:54  iter: 12899  total_loss: 0.123  loss_cls: 0.036  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9805  data_time: 1.3471  lr: 0.000100  max_mem: 9421M
[03/28 18:46:57] d2.utils.events INFO:  eta: 2:17:37  iter: 12919  total_loss: 0.119  loss_cls: 0.034  loss_box_reg: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 1.9803  data_time: 1.2445  lr: 0.000100  max_mem: 9421M
[03/28 18:47:30] d2.utils.events INFO:  eta: 2:16:38  iter: 12939  total_loss: 0.131  loss_cls: 0.037  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9798  data_time: 1.0739  lr: 0.000100  max_mem: 9421M
[03/28 18:48:08] d2.utils.events INFO:  eta: 2:15:56  iter: 12959  total_loss: 0.119  loss_cls: 0.037  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9796  data_time: 1.2939  lr: 0.000100  max_mem: 9421M
[03/28 18:48:48] d2.utils.events INFO:  eta: 2:15:31  iter: 12979  total_loss: 0.111  loss_cls: 0.033  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9796  data_time: 1.4257  lr: 0.000100  max_mem: 9421M
[03/28 18:49:28] d2.utils.events INFO:  eta: 2:15:06  iter: 12999  total_loss: 0.107  loss_cls: 0.032  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9796  data_time: 1.3877  lr: 0.000100  max_mem: 9421M
[03/28 18:50:16] d2.utils.events INFO:  eta: 2:15:55  iter: 13019  total_loss: 0.111  loss_cls: 0.033  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9803  data_time: 1.8377  lr: 0.000100  max_mem: 9421M
[03/28 18:50:50] d2.utils.events INFO:  eta: 2:15:22  iter: 13039  total_loss: 0.115  loss_cls: 0.033  loss_box_reg: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9798  data_time: 1.1451  lr: 0.000100  max_mem: 9421M
[03/28 18:51:30] d2.utils.events INFO:  eta: 2:15:20  iter: 13059  total_loss: 0.108  loss_cls: 0.032  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9799  data_time: 1.4642  lr: 0.000100  max_mem: 9421M
[03/28 18:52:07] d2.utils.events INFO:  eta: 2:14:51  iter: 13079  total_loss: 0.123  loss_cls: 0.035  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9797  data_time: 1.2920  lr: 0.000100  max_mem: 9421M
[03/28 18:52:40] d2.utils.events INFO:  eta: 2:14:19  iter: 13099  total_loss: 0.124  loss_cls: 0.038  loss_box_reg: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9792  data_time: 1.0993  lr: 0.000100  max_mem: 9421M
[03/28 18:53:14] d2.utils.events INFO:  eta: 2:13:54  iter: 13119  total_loss: 0.119  loss_cls: 0.036  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9788  data_time: 1.1001  lr: 0.000100  max_mem: 9421M
[03/28 18:53:53] d2.utils.events INFO:  eta: 2:13:07  iter: 13139  total_loss: 0.120  loss_cls: 0.038  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9787  data_time: 1.3741  lr: 0.000100  max_mem: 9421M
[03/28 18:54:33] d2.utils.events INFO:  eta: 2:12:48  iter: 13159  total_loss: 0.123  loss_cls: 0.035  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9787  data_time: 1.4067  lr: 0.000100  max_mem: 9421M
[03/28 18:55:11] d2.utils.events INFO:  eta: 2:12:15  iter: 13179  total_loss: 0.118  loss_cls: 0.039  loss_box_reg: 0.058  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9786  data_time: 1.3232  lr: 0.000100  max_mem: 9421M
[03/28 18:55:48] d2.utils.events INFO:  eta: 2:11:32  iter: 13199  total_loss: 0.121  loss_cls: 0.038  loss_box_reg: 0.069  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9784  data_time: 1.2823  lr: 0.000100  max_mem: 9421M
[03/28 18:56:27] d2.utils.events INFO:  eta: 2:10:56  iter: 13219  total_loss: 0.115  loss_cls: 0.033  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9781  data_time: 1.2326  lr: 0.000100  max_mem: 9421M
[03/28 18:57:02] d2.utils.events INFO:  eta: 2:10:11  iter: 13239  total_loss: 0.130  loss_cls: 0.039  loss_box_reg: 0.067  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9778  data_time: 1.1593  lr: 0.000100  max_mem: 9421M
[03/28 18:57:36] d2.utils.events INFO:  eta: 2:09:54  iter: 13259  total_loss: 0.112  loss_cls: 0.032  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9773  data_time: 1.1110  lr: 0.000100  max_mem: 9421M
[03/28 18:58:14] d2.utils.events INFO:  eta: 2:09:05  iter: 13279  total_loss: 0.126  loss_cls: 0.034  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9772  data_time: 1.3391  lr: 0.000100  max_mem: 9421M
[03/28 18:58:48] d2.utils.events INFO:  eta: 2:08:33  iter: 13299  total_loss: 0.122  loss_cls: 0.035  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9767  data_time: 1.0290  lr: 0.000100  max_mem: 9421M
[03/28 18:59:22] d2.utils.events INFO:  eta: 2:08:11  iter: 13319  total_loss: 0.125  loss_cls: 0.037  loss_box_reg: 0.069  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 1.9762  data_time: 1.0924  lr: 0.000100  max_mem: 9421M
[03/28 18:59:54] d2.utils.events INFO:  eta: 2:06:59  iter: 13339  total_loss: 0.117  loss_cls: 0.033  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9756  data_time: 1.0403  lr: 0.000100  max_mem: 9421M
[03/28 19:00:29] d2.utils.events INFO:  eta: 2:07:09  iter: 13359  total_loss: 0.114  loss_cls: 0.033  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9753  data_time: 1.1867  lr: 0.000100  max_mem: 9421M
[03/28 19:01:13] d2.utils.events INFO:  eta: 2:06:37  iter: 13379  total_loss: 0.119  loss_cls: 0.037  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9756  data_time: 1.5866  lr: 0.000100  max_mem: 9421M
[03/28 19:01:49] d2.utils.events INFO:  eta: 2:06:13  iter: 13399  total_loss: 0.120  loss_cls: 0.037  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9754  data_time: 1.2145  lr: 0.000100  max_mem: 9421M
[03/28 19:02:24] d2.utils.events INFO:  eta: 2:06:03  iter: 13419  total_loss: 0.110  loss_cls: 0.036  loss_box_reg: 0.054  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9751  data_time: 1.1975  lr: 0.000100  max_mem: 9421M
[03/28 19:02:59] d2.utils.events INFO:  eta: 2:05:48  iter: 13439  total_loss: 0.125  loss_cls: 0.037  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9747  data_time: 1.1657  lr: 0.000100  max_mem: 9421M
[03/28 19:03:37] d2.utils.events INFO:  eta: 2:05:25  iter: 13459  total_loss: 0.109  loss_cls: 0.032  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9746  data_time: 1.3312  lr: 0.000100  max_mem: 9421M
[03/28 19:04:18] d2.utils.events INFO:  eta: 2:04:52  iter: 13479  total_loss: 0.105  loss_cls: 0.030  loss_box_reg: 0.053  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9747  data_time: 1.4964  lr: 0.000100  max_mem: 9421M
[03/28 19:04:56] d2.utils.events INFO:  eta: 2:04:09  iter: 13499  total_loss: 0.113  loss_cls: 0.036  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9746  data_time: 1.3564  lr: 0.000100  max_mem: 9421M
[03/28 19:05:32] d2.utils.events INFO:  eta: 2:03:18  iter: 13519  total_loss: 0.104  loss_cls: 0.032  loss_box_reg: 0.057  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.9743  data_time: 1.2124  lr: 0.000100  max_mem: 9421M
[03/28 19:06:18] d2.utils.events INFO:  eta: 2:02:23  iter: 13539  total_loss: 0.125  loss_cls: 0.041  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9745  data_time: 1.4845  lr: 0.000100  max_mem: 9421M
[03/28 19:06:53] d2.utils.events INFO:  eta: 2:01:56  iter: 13559  total_loss: 0.123  loss_cls: 0.038  loss_box_reg: 0.066  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 1.9741  data_time: 1.1815  lr: 0.000100  max_mem: 9421M
[03/28 19:07:35] d2.utils.events INFO:  eta: 2:01:04  iter: 13579  total_loss: 0.127  loss_cls: 0.040  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9743  data_time: 1.5372  lr: 0.000100  max_mem: 9421M
[03/28 19:08:17] d2.utils.events INFO:  eta: 2:00:55  iter: 13599  total_loss: 0.106  loss_cls: 0.034  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9745  data_time: 1.5375  lr: 0.000100  max_mem: 9421M
[03/28 19:08:53] d2.utils.events INFO:  eta: 2:00:50  iter: 13619  total_loss: 0.119  loss_cls: 0.035  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9742  data_time: 1.2586  lr: 0.000100  max_mem: 9421M
[03/28 19:09:25] d2.utils.events INFO:  eta: 2:00:01  iter: 13639  total_loss: 0.124  loss_cls: 0.038  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9737  data_time: 1.0455  lr: 0.000100  max_mem: 9421M
[03/28 19:09:59] d2.utils.events INFO:  eta: 1:58:44  iter: 13659  total_loss: 0.135  loss_cls: 0.041  loss_box_reg: 0.072  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9733  data_time: 1.1118  lr: 0.000100  max_mem: 9421M
[03/28 19:10:36] d2.utils.events INFO:  eta: 1:58:09  iter: 13679  total_loss: 0.134  loss_cls: 0.039  loss_box_reg: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 1.9731  data_time: 1.2838  lr: 0.000100  max_mem: 9421M
[03/28 19:11:15] d2.utils.events INFO:  eta: 1:57:36  iter: 13699  total_loss: 0.122  loss_cls: 0.039  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9731  data_time: 1.3857  lr: 0.000100  max_mem: 9421M
[03/28 19:12:02] d2.utils.events INFO:  eta: 1:57:09  iter: 13719  total_loss: 0.119  loss_cls: 0.038  loss_box_reg: 0.066  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 1.9736  data_time: 1.7598  lr: 0.000100  max_mem: 9421M
[03/28 19:12:37] d2.utils.events INFO:  eta: 1:56:36  iter: 13739  total_loss: 0.126  loss_cls: 0.038  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9733  data_time: 1.1851  lr: 0.000100  max_mem: 9421M
[03/28 19:13:12] d2.utils.events INFO:  eta: 1:56:00  iter: 13759  total_loss: 0.102  loss_cls: 0.034  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 1.9729  data_time: 1.1354  lr: 0.000100  max_mem: 9421M
[03/28 19:13:50] d2.utils.events INFO:  eta: 1:55:16  iter: 13779  total_loss: 0.100  loss_cls: 0.031  loss_box_reg: 0.048  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9729  data_time: 1.3578  lr: 0.000100  max_mem: 9421M
[03/28 19:14:29] d2.utils.events INFO:  eta: 1:54:43  iter: 13799  total_loss: 0.126  loss_cls: 0.041  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9728  data_time: 1.3718  lr: 0.000100  max_mem: 9421M
[03/28 19:15:03] d2.utils.events INFO:  eta: 1:54:07  iter: 13819  total_loss: 0.126  loss_cls: 0.037  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9725  data_time: 1.1444  lr: 0.000100  max_mem: 9421M
[03/28 19:15:40] d2.utils.events INFO:  eta: 1:53:41  iter: 13839  total_loss: 0.126  loss_cls: 0.035  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9722  data_time: 1.2437  lr: 0.000100  max_mem: 9421M
[03/28 19:16:16] d2.utils.events INFO:  eta: 1:53:05  iter: 13859  total_loss: 0.131  loss_cls: 0.044  loss_box_reg: 0.074  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9720  data_time: 1.2327  lr: 0.000100  max_mem: 9421M
[03/28 19:17:01] d2.utils.events INFO:  eta: 1:52:41  iter: 13879  total_loss: 0.123  loss_cls: 0.038  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9724  data_time: 1.6630  lr: 0.000100  max_mem: 9421M
[03/28 19:17:42] d2.utils.events INFO:  eta: 1:52:10  iter: 13899  total_loss: 0.132  loss_cls: 0.038  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 1.9725  data_time: 1.4951  lr: 0.000100  max_mem: 9421M
[03/28 19:18:18] d2.utils.events INFO:  eta: 1:51:50  iter: 13919  total_loss: 0.103  loss_cls: 0.032  loss_box_reg: 0.052  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9722  data_time: 1.2094  lr: 0.000100  max_mem: 9421M
[03/28 19:18:59] d2.utils.events INFO:  eta: 1:51:48  iter: 13939  total_loss: 0.120  loss_cls: 0.034  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9723  data_time: 1.4575  lr: 0.000100  max_mem: 9421M
[03/28 19:19:41] d2.utils.events INFO:  eta: 1:51:40  iter: 13959  total_loss: 0.110  loss_cls: 0.033  loss_box_reg: 0.055  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9725  data_time: 1.5140  lr: 0.000100  max_mem: 9421M
[03/28 19:20:31] d2.utils.events INFO:  eta: 1:51:20  iter: 13979  total_loss: 0.127  loss_cls: 0.034  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9733  data_time: 1.9412  lr: 0.000100  max_mem: 9421M
[03/28 19:21:12] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/28 19:21:12] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/28 19:21:12] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/28 19:21:12] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/28 19:21:19] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0504 s / img. ETA=0:17:11
[03/28 19:21:24] d2.evaluation.evaluator INFO: Inference done 30/1210. 0.0466 s / img. ETA=0:08:04
[03/28 19:21:29] d2.evaluation.evaluator INFO: Inference done 54/1210. 0.0459 s / img. ETA=0:06:06
[03/28 19:21:38] d2.evaluation.evaluator INFO: Inference done 74/1210. 0.0457 s / img. ETA=0:06:37
[03/28 19:21:43] d2.evaluation.evaluator INFO: Inference done 96/1210. 0.0457 s / img. ETA=0:05:57
[03/28 19:21:48] d2.evaluation.evaluator INFO: Inference done 117/1210. 0.0461 s / img. ETA=0:05:34
[03/28 19:21:53] d2.evaluation.evaluator INFO: Inference done 125/1210. 0.0461 s / img. ETA=0:06:00
[03/28 19:21:58] d2.evaluation.evaluator INFO: Inference done 147/1210. 0.0463 s / img. ETA=0:05:35
[03/28 19:22:03] d2.evaluation.evaluator INFO: Inference done 166/1210. 0.0465 s / img. ETA=0:05:23
[03/28 19:22:12] d2.evaluation.evaluator INFO: Inference done 182/1210. 0.0465 s / img. ETA=0:05:42
[03/28 19:22:17] d2.evaluation.evaluator INFO: Inference done 199/1210. 0.0466 s / img. ETA=0:05:33
[03/28 19:22:23] d2.evaluation.evaluator INFO: Inference done 221/1210. 0.0466 s / img. ETA=0:05:16
[03/28 19:22:28] d2.evaluation.evaluator INFO: Inference done 241/1210. 0.0465 s / img. ETA=0:05:05
[03/28 19:22:33] d2.evaluation.evaluator INFO: Inference done 265/1210. 0.0465 s / img. ETA=0:04:48
[03/28 19:22:38] d2.evaluation.evaluator INFO: Inference done 289/1210. 0.0466 s / img. ETA=0:04:33
[03/28 19:22:43] d2.evaluation.evaluator INFO: Inference done 311/1210. 0.0466 s / img. ETA=0:04:22
[03/28 19:22:48] d2.evaluation.evaluator INFO: Inference done 334/1210. 0.0466 s / img. ETA=0:04:11
[03/28 19:22:53] d2.evaluation.evaluator INFO: Inference done 358/1210. 0.0468 s / img. ETA=0:04:00
[03/28 19:23:00] d2.evaluation.evaluator INFO: Inference done 379/1210. 0.0468 s / img. ETA=0:03:56
[03/28 19:23:05] d2.evaluation.evaluator INFO: Inference done 398/1210. 0.0468 s / img. ETA=0:03:50
[03/28 19:23:10] d2.evaluation.evaluator INFO: Inference done 419/1210. 0.0468 s / img. ETA=0:03:42
[03/28 19:23:15] d2.evaluation.evaluator INFO: Inference done 439/1210. 0.0467 s / img. ETA=0:03:36
[03/28 19:23:20] d2.evaluation.evaluator INFO: Inference done 459/1210. 0.0466 s / img. ETA=0:03:29
[03/28 19:23:25] d2.evaluation.evaluator INFO: Inference done 474/1210. 0.0465 s / img. ETA=0:03:26
[03/28 19:23:30] d2.evaluation.evaluator INFO: Inference done 495/1210. 0.0465 s / img. ETA=0:03:19
[03/28 19:23:36] d2.evaluation.evaluator INFO: Inference done 516/1210. 0.0465 s / img. ETA=0:03:13
[03/28 19:23:41] d2.evaluation.evaluator INFO: Inference done 532/1210. 0.0465 s / img. ETA=0:03:09
[03/28 19:23:47] d2.evaluation.evaluator INFO: Inference done 558/1210. 0.0465 s / img. ETA=0:03:00
[03/28 19:23:52] d2.evaluation.evaluator INFO: Inference done 577/1210. 0.0464 s / img. ETA=0:02:55
[03/28 19:23:57] d2.evaluation.evaluator INFO: Inference done 597/1210. 0.0464 s / img. ETA=0:02:49
[03/28 19:24:02] d2.evaluation.evaluator INFO: Inference done 620/1210. 0.0465 s / img. ETA=0:02:41
[03/28 19:24:07] d2.evaluation.evaluator INFO: Inference done 644/1210. 0.0464 s / img. ETA=0:02:34
[03/28 19:24:12] d2.evaluation.evaluator INFO: Inference done 670/1210. 0.0464 s / img. ETA=0:02:25
[03/28 19:24:17] d2.evaluation.evaluator INFO: Inference done 691/1210. 0.0464 s / img. ETA=0:02:19
[03/28 19:24:23] d2.evaluation.evaluator INFO: Inference done 703/1210. 0.0463 s / img. ETA=0:02:17
[03/28 19:24:28] d2.evaluation.evaluator INFO: Inference done 723/1210. 0.0463 s / img. ETA=0:02:11
[03/28 19:24:33] d2.evaluation.evaluator INFO: Inference done 749/1210. 0.0464 s / img. ETA=0:02:03
[03/28 19:24:38] d2.evaluation.evaluator INFO: Inference done 772/1210. 0.0465 s / img. ETA=0:01:57
[03/28 19:24:44] d2.evaluation.evaluator INFO: Inference done 792/1210. 0.0464 s / img. ETA=0:01:51
[03/28 19:24:49] d2.evaluation.evaluator INFO: Inference done 810/1210. 0.0463 s / img. ETA=0:01:47
[03/28 19:24:58] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0463 s / img. ETA=0:01:46
[03/28 19:25:03] d2.evaluation.evaluator INFO: Inference done 844/1210. 0.0463 s / img. ETA=0:01:40
[03/28 19:25:08] d2.evaluation.evaluator INFO: Inference done 866/1210. 0.0463 s / img. ETA=0:01:33
[03/28 19:25:13] d2.evaluation.evaluator INFO: Inference done 887/1210. 0.0463 s / img. ETA=0:01:27
[03/28 19:25:19] d2.evaluation.evaluator INFO: Inference done 911/1210. 0.0464 s / img. ETA=0:01:20
[03/28 19:25:24] d2.evaluation.evaluator INFO: Inference done 935/1210. 0.0465 s / img. ETA=0:01:14
[03/28 19:25:29] d2.evaluation.evaluator INFO: Inference done 960/1210. 0.0465 s / img. ETA=0:01:06
[03/28 19:25:34] d2.evaluation.evaluator INFO: Inference done 980/1210. 0.0465 s / img. ETA=0:01:01
[03/28 19:25:39] d2.evaluation.evaluator INFO: Inference done 994/1210. 0.0465 s / img. ETA=0:00:58
[03/28 19:25:44] d2.evaluation.evaluator INFO: Inference done 1015/1210. 0.0465 s / img. ETA=0:00:52
[03/28 19:25:49] d2.evaluation.evaluator INFO: Inference done 1035/1210. 0.0464 s / img. ETA=0:00:46
[03/28 19:25:55] d2.evaluation.evaluator INFO: Inference done 1059/1210. 0.0464 s / img. ETA=0:00:40
[03/28 19:26:00] d2.evaluation.evaluator INFO: Inference done 1085/1210. 0.0465 s / img. ETA=0:00:33
[03/28 19:26:05] d2.evaluation.evaluator INFO: Inference done 1107/1210. 0.0465 s / img. ETA=0:00:27
[03/28 19:26:10] d2.evaluation.evaluator INFO: Inference done 1133/1210. 0.0466 s / img. ETA=0:00:20
[03/28 19:26:15] d2.evaluation.evaluator INFO: Inference done 1158/1210. 0.0466 s / img. ETA=0:00:13
[03/28 19:26:22] d2.evaluation.evaluator INFO: Inference done 1164/1210. 0.0466 s / img. ETA=0:00:12
[03/28 19:26:28] d2.evaluation.evaluator INFO: Inference done 1183/1210. 0.0466 s / img. ETA=0:00:07
[03/28 19:26:33] d2.evaluation.evaluator INFO: Inference done 1202/1210. 0.0466 s / img. ETA=0:00:02
[03/28 19:26:35] d2.evaluation.evaluator INFO: Total inference time: 0:05:21.984334 (0.267207 s / img per device, on 1 devices)
[03/28 19:26:35] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:56 (0.046560 s / img per device, on 1 devices)
[03/28 19:26:35] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/28 19:26:35] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/28 19:26:36] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/28 19:26:37] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.488 | 63.253 | 55.215 | 33.032 | 19.627 | 42.399 |
[03/28 19:26:37] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/28 19:26:37] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/28 19:26:37] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/28 19:26:37] d2.evaluation.testing INFO: copypaste: 44.4876,63.2529,55.2147,33.0316,19.6274,42.3994
[03/28 19:26:37] d2.utils.events INFO:  eta: 1:51:10  iter: 13999  total_loss: 0.108  loss_cls: 0.032  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9734  data_time: 1.4660  lr: 0.000100  max_mem: 9421M
[03/28 19:27:29] d2.utils.events INFO:  eta: 1:50:30  iter: 14019  total_loss: 0.119  loss_cls: 0.034  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9739  data_time: 1.7679  lr: 0.000100  max_mem: 9421M
[03/28 19:28:01] d2.utils.events INFO:  eta: 1:49:53  iter: 14039  total_loss: 0.125  loss_cls: 0.040  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9734  data_time: 1.0227  lr: 0.000100  max_mem: 9421M
[03/28 19:28:32] d2.utils.events INFO:  eta: 1:48:39  iter: 14059  total_loss: 0.138  loss_cls: 0.041  loss_box_reg: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.024  time: 1.9728  data_time: 1.0165  lr: 0.000100  max_mem: 9421M
[03/28 19:29:05] d2.utils.events INFO:  eta: 1:47:57  iter: 14079  total_loss: 0.116  loss_cls: 0.033  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 1.9724  data_time: 1.0824  lr: 0.000100  max_mem: 9421M
[03/28 19:29:40] d2.utils.events INFO:  eta: 1:47:05  iter: 14099  total_loss: 0.120  loss_cls: 0.037  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.9720  data_time: 1.1802  lr: 0.000100  max_mem: 9421M
[03/28 19:30:18] d2.utils.events INFO:  eta: 1:46:51  iter: 14119  total_loss: 0.126  loss_cls: 0.037  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9720  data_time: 1.3286  lr: 0.000100  max_mem: 9421M
[03/28 19:30:57] d2.utils.events INFO:  eta: 1:46:04  iter: 14139  total_loss: 0.123  loss_cls: 0.039  loss_box_reg: 0.066  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9719  data_time: 1.3597  lr: 0.000100  max_mem: 9421M
[03/28 19:31:31] d2.utils.events INFO:  eta: 1:45:22  iter: 14159  total_loss: 0.119  loss_cls: 0.034  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9716  data_time: 1.1462  lr: 0.000100  max_mem: 9421M
[03/28 19:32:16] d2.utils.events INFO:  eta: 1:44:38  iter: 14179  total_loss: 0.130  loss_cls: 0.035  loss_box_reg: 0.065  loss_rpn_cls: 0.004  loss_rpn_loc: 0.015  time: 1.9719  data_time: 1.6494  lr: 0.000100  max_mem: 9421M
[03/28 19:32:50] d2.utils.events INFO:  eta: 1:44:05  iter: 14199  total_loss: 0.125  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9715  data_time: 1.1198  lr: 0.000100  max_mem: 9421M
[03/28 19:33:32] d2.utils.events INFO:  eta: 1:43:44  iter: 14219  total_loss: 0.123  loss_cls: 0.038  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9717  data_time: 1.5274  lr: 0.000100  max_mem: 9421M
[03/28 19:34:13] d2.utils.events INFO:  eta: 1:43:15  iter: 14239  total_loss: 0.118  loss_cls: 0.037  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 1.9718  data_time: 1.4877  lr: 0.000100  max_mem: 9421M
[03/28 19:34:51] d2.utils.events INFO:  eta: 1:42:38  iter: 14259  total_loss: 0.131  loss_cls: 0.037  loss_box_reg: 0.070  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 1.9717  data_time: 1.3568  lr: 0.000100  max_mem: 9421M
[03/28 19:35:27] d2.utils.events INFO:  eta: 1:42:13  iter: 14279  total_loss: 0.112  loss_cls: 0.032  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9714  data_time: 1.1738  lr: 0.000100  max_mem: 9421M
[03/28 19:36:05] d2.utils.events INFO:  eta: 1:41:54  iter: 14299  total_loss: 0.110  loss_cls: 0.032  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9714  data_time: 1.3540  lr: 0.000100  max_mem: 9421M
[03/28 19:36:52] d2.utils.events INFO:  eta: 1:41:35  iter: 14319  total_loss: 0.109  loss_cls: 0.032  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9718  data_time: 1.7272  lr: 0.000100  max_mem: 9421M
[03/28 19:37:29] d2.utils.events INFO:  eta: 1:40:56  iter: 14339  total_loss: 0.112  loss_cls: 0.037  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9716  data_time: 1.2546  lr: 0.000100  max_mem: 9421M
[03/28 19:38:13] d2.utils.events INFO:  eta: 1:40:05  iter: 14359  total_loss: 0.124  loss_cls: 0.037  loss_box_reg: 0.070  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9719  data_time: 1.5965  lr: 0.000100  max_mem: 9421M
[03/28 19:38:48] d2.utils.events INFO:  eta: 1:39:25  iter: 14379  total_loss: 0.120  loss_cls: 0.037  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9716  data_time: 1.1410  lr: 0.000100  max_mem: 9421M
[03/28 19:39:23] d2.utils.events INFO:  eta: 1:38:59  iter: 14399  total_loss: 0.117  loss_cls: 0.035  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9713  data_time: 1.2005  lr: 0.000100  max_mem: 9421M
[03/28 19:39:55] d2.utils.events INFO:  eta: 1:37:57  iter: 14419  total_loss: 0.116  loss_cls: 0.038  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9708  data_time: 1.0220  lr: 0.000100  max_mem: 9421M
[03/28 19:40:31] d2.utils.events INFO:  eta: 1:37:35  iter: 14439  total_loss: 0.115  loss_cls: 0.033  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 1.9705  data_time: 1.1760  lr: 0.000100  max_mem: 9421M
[03/28 19:41:04] d2.utils.events INFO:  eta: 1:36:45  iter: 14459  total_loss: 0.111  loss_cls: 0.036  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9700  data_time: 1.0731  lr: 0.000100  max_mem: 9421M
[03/28 19:41:37] d2.utils.events INFO:  eta: 1:36:08  iter: 14479  total_loss: 0.115  loss_cls: 0.034  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9696  data_time: 1.0781  lr: 0.000100  max_mem: 9421M
[03/28 19:42:19] d2.utils.events INFO:  eta: 1:35:36  iter: 14499  total_loss: 0.120  loss_cls: 0.037  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9698  data_time: 1.5632  lr: 0.000100  max_mem: 9421M
[03/28 19:42:55] d2.utils.events INFO:  eta: 1:35:03  iter: 14519  total_loss: 0.130  loss_cls: 0.037  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9696  data_time: 1.2291  lr: 0.000100  max_mem: 9421M
[03/28 19:43:31] d2.utils.events INFO:  eta: 1:34:50  iter: 14539  total_loss: 0.109  loss_cls: 0.030  loss_box_reg: 0.056  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9693  data_time: 1.2220  lr: 0.000100  max_mem: 9421M
[03/28 19:44:06] d2.utils.events INFO:  eta: 1:34:01  iter: 14559  total_loss: 0.110  loss_cls: 0.032  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9690  data_time: 1.1375  lr: 0.000100  max_mem: 9421M
[03/28 19:44:42] d2.utils.events INFO:  eta: 1:34:02  iter: 14579  total_loss: 0.117  loss_cls: 0.035  loss_box_reg: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9688  data_time: 1.2372  lr: 0.000100  max_mem: 9421M
[03/28 19:45:20] d2.utils.events INFO:  eta: 1:33:38  iter: 14599  total_loss: 0.122  loss_cls: 0.033  loss_box_reg: 0.067  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9687  data_time: 1.2714  lr: 0.000100  max_mem: 9421M
[03/28 19:45:58] d2.utils.events INFO:  eta: 1:33:13  iter: 14619  total_loss: 0.126  loss_cls: 0.034  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.9686  data_time: 1.3418  lr: 0.000100  max_mem: 9421M
[03/28 19:46:38] d2.utils.events INFO:  eta: 1:32:57  iter: 14639  total_loss: 0.118  loss_cls: 0.036  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 1.9686  data_time: 1.4312  lr: 0.000100  max_mem: 9421M
[03/28 19:47:10] d2.utils.events INFO:  eta: 1:32:50  iter: 14659  total_loss: 0.130  loss_cls: 0.040  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 1.9681  data_time: 1.0627  lr: 0.000100  max_mem: 9421M
[03/28 19:47:49] d2.utils.events INFO:  eta: 1:32:20  iter: 14679  total_loss: 0.118  loss_cls: 0.037  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 1.9681  data_time: 1.3544  lr: 0.000100  max_mem: 9421M
[03/28 19:48:39] d2.utils.events INFO:  eta: 1:31:46  iter: 14699  total_loss: 0.125  loss_cls: 0.040  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9685  data_time: 1.6930  lr: 0.000100  max_mem: 9421M
[03/28 19:49:15] d2.utils.events INFO:  eta: 1:31:13  iter: 14719  total_loss: 0.123  loss_cls: 0.037  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9683  data_time: 1.1836  lr: 0.000100  max_mem: 9421M
[03/28 19:49:48] d2.utils.events INFO:  eta: 1:30:26  iter: 14739  total_loss: 0.131  loss_cls: 0.039  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9678  data_time: 1.0306  lr: 0.000100  max_mem: 9421M
[03/28 19:50:26] d2.utils.events INFO:  eta: 1:29:46  iter: 14759  total_loss: 0.108  loss_cls: 0.031  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.021  time: 1.9677  data_time: 1.3566  lr: 0.000100  max_mem: 9421M
[03/28 19:50:59] d2.utils.events INFO:  eta: 1:29:05  iter: 14779  total_loss: 0.113  loss_cls: 0.035  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9673  data_time: 1.0937  lr: 0.000100  max_mem: 9421M
[03/28 19:51:33] d2.utils.events INFO:  eta: 1:28:31  iter: 14799  total_loss: 0.111  loss_cls: 0.031  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 1.9669  data_time: 1.1104  lr: 0.000100  max_mem: 9421M
[03/28 19:52:12] d2.utils.events INFO:  eta: 1:28:20  iter: 14819  total_loss: 0.112  loss_cls: 0.035  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 1.9669  data_time: 1.3702  lr: 0.000100  max_mem: 9421M
[03/28 19:52:48] d2.utils.events INFO:  eta: 1:27:41  iter: 14839  total_loss: 0.116  loss_cls: 0.034  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9666  data_time: 1.1815  lr: 0.000100  max_mem: 9421M
[03/28 19:53:23] d2.utils.events INFO:  eta: 1:27:08  iter: 14859  total_loss: 0.128  loss_cls: 0.036  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9663  data_time: 1.1505  lr: 0.000100  max_mem: 9421M
[03/28 19:54:02] d2.utils.events INFO:  eta: 1:26:12  iter: 14879  total_loss: 0.109  loss_cls: 0.032  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9662  data_time: 1.3776  lr: 0.000100  max_mem: 9421M
[03/28 19:54:34] d2.utils.events INFO:  eta: 1:25:14  iter: 14899  total_loss: 0.126  loss_cls: 0.042  loss_box_reg: 0.067  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 1.9658  data_time: 1.0588  lr: 0.000100  max_mem: 9421M
[03/28 19:55:08] d2.utils.events INFO:  eta: 1:24:36  iter: 14919  total_loss: 0.140  loss_cls: 0.039  loss_box_reg: 0.068  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9654  data_time: 1.1363  lr: 0.000100  max_mem: 9421M
[03/28 19:55:46] d2.utils.events INFO:  eta: 1:24:02  iter: 14939  total_loss: 0.118  loss_cls: 0.035  loss_box_reg: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 1.9653  data_time: 1.3761  lr: 0.000100  max_mem: 9421M
[03/28 19:56:21] d2.utils.events INFO:  eta: 1:23:02  iter: 14959  total_loss: 0.120  loss_cls: 0.037  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9650  data_time: 1.1319  lr: 0.000100  max_mem: 9421M
[03/28 19:56:55] d2.utils.events INFO:  eta: 1:22:21  iter: 14979  total_loss: 0.125  loss_cls: 0.037  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9647  data_time: 1.1677  lr: 0.000100  max_mem: 9421M
[03/28 19:57:31] d2.utils.events INFO:  eta: 1:21:39  iter: 14999  total_loss: 0.119  loss_cls: 0.042  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9645  data_time: 1.2348  lr: 0.000100  max_mem: 9421M
[03/28 19:58:03] d2.utils.events INFO:  eta: 1:20:34  iter: 15019  total_loss: 0.121  loss_cls: 0.033  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9640  data_time: 1.0218  lr: 0.000100  max_mem: 9421M
[03/28 19:58:48] d2.utils.events INFO:  eta: 1:20:22  iter: 15039  total_loss: 0.127  loss_cls: 0.037  loss_box_reg: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9644  data_time: 1.6932  lr: 0.000100  max_mem: 9421M
[03/28 19:59:25] d2.utils.events INFO:  eta: 1:20:01  iter: 15059  total_loss: 0.126  loss_cls: 0.038  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9642  data_time: 1.2408  lr: 0.000100  max_mem: 9421M
[03/28 19:59:57] d2.utils.events INFO:  eta: 1:19:17  iter: 15079  total_loss: 0.114  loss_cls: 0.034  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9637  data_time: 1.0468  lr: 0.000100  max_mem: 9421M
[03/28 20:00:33] d2.utils.events INFO:  eta: 1:18:59  iter: 15099  total_loss: 0.118  loss_cls: 0.035  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9635  data_time: 1.2473  lr: 0.000100  max_mem: 9421M
[03/28 20:01:09] d2.utils.events INFO:  eta: 1:18:23  iter: 15119  total_loss: 0.114  loss_cls: 0.034  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9633  data_time: 1.2233  lr: 0.000100  max_mem: 9421M
[03/28 20:01:46] d2.utils.events INFO:  eta: 1:17:55  iter: 15139  total_loss: 0.138  loss_cls: 0.040  loss_box_reg: 0.072  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9631  data_time: 1.2688  lr: 0.000100  max_mem: 9421M
[03/28 20:02:23] d2.utils.events INFO:  eta: 1:17:21  iter: 15159  total_loss: 0.113  loss_cls: 0.035  loss_box_reg: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.9630  data_time: 1.3019  lr: 0.000100  max_mem: 9421M
[03/28 20:02:53] d2.utils.events INFO:  eta: 1:16:48  iter: 15179  total_loss: 0.111  loss_cls: 0.034  loss_box_reg: 0.058  loss_rpn_cls: 0.004  loss_rpn_loc: 0.015  time: 1.9624  data_time: 0.9733  lr: 0.000100  max_mem: 9421M
[03/28 20:03:31] d2.utils.events INFO:  eta: 1:16:16  iter: 15199  total_loss: 0.135  loss_cls: 0.043  loss_box_reg: 0.075  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9623  data_time: 1.3053  lr: 0.000100  max_mem: 9421M
[03/28 20:04:07] d2.utils.events INFO:  eta: 1:15:37  iter: 15219  total_loss: 0.120  loss_cls: 0.036  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9620  data_time: 1.2038  lr: 0.000100  max_mem: 9421M
[03/28 20:04:45] d2.utils.events INFO:  eta: 1:15:10  iter: 15239  total_loss: 0.130  loss_cls: 0.036  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9620  data_time: 1.3308  lr: 0.000100  max_mem: 9421M
[03/28 20:05:20] d2.utils.events INFO:  eta: 1:14:38  iter: 15259  total_loss: 0.121  loss_cls: 0.039  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9617  data_time: 1.1746  lr: 0.000100  max_mem: 9421M
[03/28 20:05:56] d2.utils.events INFO:  eta: 1:14:05  iter: 15279  total_loss: 0.104  loss_cls: 0.033  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9615  data_time: 1.2228  lr: 0.000100  max_mem: 9421M
[03/28 20:06:30] d2.utils.events INFO:  eta: 1:13:29  iter: 15299  total_loss: 0.132  loss_cls: 0.038  loss_box_reg: 0.067  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9611  data_time: 1.1309  lr: 0.000100  max_mem: 9421M
[03/28 20:07:08] d2.utils.events INFO:  eta: 1:12:54  iter: 15319  total_loss: 0.113  loss_cls: 0.034  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9610  data_time: 1.3355  lr: 0.000100  max_mem: 9421M
[03/28 20:07:45] d2.utils.events INFO:  eta: 1:12:24  iter: 15339  total_loss: 0.117  loss_cls: 0.035  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9609  data_time: 1.2678  lr: 0.000100  max_mem: 9421M
[03/28 20:08:25] d2.utils.events INFO:  eta: 1:11:36  iter: 15359  total_loss: 0.127  loss_cls: 0.039  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9610  data_time: 1.4167  lr: 0.000100  max_mem: 9421M
[03/28 20:09:04] d2.utils.events INFO:  eta: 1:11:04  iter: 15379  total_loss: 0.128  loss_cls: 0.038  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9609  data_time: 1.3823  lr: 0.000100  max_mem: 9421M
[03/28 20:09:48] d2.utils.events INFO:  eta: 1:10:27  iter: 15399  total_loss: 0.116  loss_cls: 0.032  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  time: 1.9612  data_time: 1.6199  lr: 0.000100  max_mem: 9421M
[03/28 20:10:37] d2.utils.events INFO:  eta: 1:10:16  iter: 15419  total_loss: 0.122  loss_cls: 0.036  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9618  data_time: 1.9071  lr: 0.000100  max_mem: 9421M
[03/28 20:11:15] d2.utils.events INFO:  eta: 1:09:38  iter: 15439  total_loss: 0.121  loss_cls: 0.035  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9617  data_time: 1.2937  lr: 0.000100  max_mem: 9421M
[03/28 20:11:49] d2.utils.events INFO:  eta: 1:09:00  iter: 15459  total_loss: 0.106  loss_cls: 0.036  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9614  data_time: 1.1103  lr: 0.000100  max_mem: 9421M
[03/28 20:12:31] d2.utils.events INFO:  eta: 1:08:38  iter: 15479  total_loss: 0.126  loss_cls: 0.038  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9616  data_time: 1.5372  lr: 0.000100  max_mem: 9421M
[03/28 20:13:05] d2.utils.events INFO:  eta: 1:07:48  iter: 15499  total_loss: 0.110  loss_cls: 0.035  loss_box_reg: 0.056  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9612  data_time: 1.0986  lr: 0.000100  max_mem: 9421M
[03/28 20:13:41] d2.utils.events INFO:  eta: 1:07:22  iter: 15519  total_loss: 0.129  loss_cls: 0.037  loss_box_reg: 0.067  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9610  data_time: 1.2050  lr: 0.000100  max_mem: 9421M
[03/28 20:14:21] d2.utils.events INFO:  eta: 1:06:40  iter: 15539  total_loss: 0.128  loss_cls: 0.036  loss_box_reg: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 1.9611  data_time: 1.4605  lr: 0.000100  max_mem: 9421M
[03/28 20:14:59] d2.utils.events INFO:  eta: 1:06:17  iter: 15559  total_loss: 0.118  loss_cls: 0.032  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9610  data_time: 1.2874  lr: 0.000100  max_mem: 9421M
[03/28 20:15:33] d2.utils.events INFO:  eta: 1:05:38  iter: 15579  total_loss: 0.119  loss_cls: 0.035  loss_box_reg: 0.055  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9607  data_time: 1.1457  lr: 0.000100  max_mem: 9421M
[03/28 20:16:08] d2.utils.events INFO:  eta: 1:05:06  iter: 15599  total_loss: 0.115  loss_cls: 0.033  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9604  data_time: 1.1270  lr: 0.000100  max_mem: 9421M
[03/28 20:16:44] d2.utils.events INFO:  eta: 1:04:28  iter: 15619  total_loss: 0.130  loss_cls: 0.037  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9602  data_time: 1.2241  lr: 0.000100  max_mem: 9421M
[03/28 20:17:17] d2.utils.events INFO:  eta: 1:03:53  iter: 15639  total_loss: 0.126  loss_cls: 0.040  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9598  data_time: 1.1047  lr: 0.000100  max_mem: 9421M
[03/28 20:17:59] d2.utils.events INFO:  eta: 1:03:23  iter: 15659  total_loss: 0.109  loss_cls: 0.033  loss_box_reg: 0.055  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9600  data_time: 1.5202  lr: 0.000100  max_mem: 9421M
[03/28 20:18:38] d2.utils.events INFO:  eta: 1:02:56  iter: 15679  total_loss: 0.107  loss_cls: 0.033  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9600  data_time: 1.4047  lr: 0.000100  max_mem: 9421M
[03/28 20:19:20] d2.utils.events INFO:  eta: 1:02:30  iter: 15699  total_loss: 0.130  loss_cls: 0.037  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9602  data_time: 1.5461  lr: 0.000100  max_mem: 9421M
[03/28 20:19:53] d2.utils.events INFO:  eta: 1:01:47  iter: 15719  total_loss: 0.124  loss_cls: 0.036  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9598  data_time: 1.0834  lr: 0.000100  max_mem: 9421M
[03/28 20:20:29] d2.utils.events INFO:  eta: 1:01:31  iter: 15739  total_loss: 0.107  loss_cls: 0.033  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9596  data_time: 1.2280  lr: 0.000100  max_mem: 9421M
[03/28 20:21:13] d2.utils.events INFO:  eta: 1:01:01  iter: 15759  total_loss: 0.120  loss_cls: 0.037  loss_box_reg: 0.058  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9599  data_time: 1.5807  lr: 0.000100  max_mem: 9421M
[03/28 20:21:46] d2.utils.events INFO:  eta: 1:00:28  iter: 15779  total_loss: 0.115  loss_cls: 0.033  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9594  data_time: 1.0626  lr: 0.000100  max_mem: 9421M
[03/28 20:22:27] d2.utils.events INFO:  eta: 0:59:55  iter: 15799  total_loss: 0.124  loss_cls: 0.035  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 1.9595  data_time: 1.4757  lr: 0.000100  max_mem: 9421M
[03/28 20:23:02] d2.utils.events INFO:  eta: 0:59:23  iter: 15819  total_loss: 0.130  loss_cls: 0.036  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9593  data_time: 1.1818  lr: 0.000100  max_mem: 9421M
[03/28 20:23:36] d2.utils.events INFO:  eta: 0:58:41  iter: 15839  total_loss: 0.119  loss_cls: 0.040  loss_box_reg: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  time: 1.9590  data_time: 1.1141  lr: 0.000100  max_mem: 9421M
[03/28 20:24:18] d2.utils.events INFO:  eta: 0:58:09  iter: 15859  total_loss: 0.126  loss_cls: 0.035  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9592  data_time: 1.5631  lr: 0.000100  max_mem: 9421M
[03/28 20:24:51] d2.utils.events INFO:  eta: 0:57:27  iter: 15879  total_loss: 0.126  loss_cls: 0.037  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 1.9588  data_time: 1.0767  lr: 0.000100  max_mem: 9421M
[03/28 20:25:35] d2.utils.events INFO:  eta: 0:57:12  iter: 15899  total_loss: 0.116  loss_cls: 0.034  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9589  data_time: 1.5085  lr: 0.000100  max_mem: 9421M
[03/28 20:26:32] d2.utils.events INFO:  eta: 0:56:43  iter: 15919  total_loss: 0.116  loss_cls: 0.038  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9598  data_time: 2.0388  lr: 0.000100  max_mem: 9421M
[03/28 20:27:13] d2.utils.events INFO:  eta: 0:56:13  iter: 15939  total_loss: 0.121  loss_cls: 0.036  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9599  data_time: 1.4609  lr: 0.000100  max_mem: 9421M
[03/28 20:27:56] d2.utils.events INFO:  eta: 0:55:56  iter: 15959  total_loss: 0.119  loss_cls: 0.036  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9601  data_time: 1.5710  lr: 0.000100  max_mem: 9421M
[03/28 20:28:41] d2.utils.events INFO:  eta: 0:55:32  iter: 15979  total_loss: 0.110  loss_cls: 0.032  loss_box_reg: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.9604  data_time: 1.6449  lr: 0.000100  max_mem: 9421M
[03/28 20:29:25] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/lr0.001_finetune/model_0015999.pth
[03/28 20:29:28] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/28 20:29:28] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/28 20:29:28] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/28 20:29:28] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/28 20:29:30] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0482 s / img. ETA=0:02:50
[03/28 20:29:37] d2.evaluation.evaluator INFO: Inference done 22/1210. 0.0447 s / img. ETA=0:09:05
[03/28 20:29:42] d2.evaluation.evaluator INFO: Inference done 46/1210. 0.0464 s / img. ETA=0:06:05
[03/28 20:29:47] d2.evaluation.evaluator INFO: Inference done 64/1210. 0.0456 s / img. ETA=0:05:51
[03/28 20:29:52] d2.evaluation.evaluator INFO: Inference done 84/1210. 0.0462 s / img. ETA=0:05:29
[03/28 20:29:58] d2.evaluation.evaluator INFO: Inference done 105/1210. 0.0464 s / img. ETA=0:05:12
[03/28 20:30:06] d2.evaluation.evaluator INFO: Inference done 127/1210. 0.0468 s / img. ETA=0:05:24
[03/28 20:30:13] d2.evaluation.evaluator INFO: Inference done 136/1210. 0.0471 s / img. ETA=0:05:58
[03/28 20:30:18] d2.evaluation.evaluator INFO: Inference done 155/1210. 0.0472 s / img. ETA=0:05:44
[03/28 20:30:24] d2.evaluation.evaluator INFO: Inference done 171/1210. 0.0471 s / img. ETA=0:05:42
[03/28 20:30:30] d2.evaluation.evaluator INFO: Inference done 178/1210. 0.0472 s / img. ETA=0:06:02
[03/28 20:30:35] d2.evaluation.evaluator INFO: Inference done 195/1210. 0.0473 s / img. ETA=0:05:51
[03/28 20:30:40] d2.evaluation.evaluator INFO: Inference done 216/1210. 0.0473 s / img. ETA=0:05:34
[03/28 20:30:46] d2.evaluation.evaluator INFO: Inference done 237/1210. 0.0471 s / img. ETA=0:05:19
[03/28 20:30:52] d2.evaluation.evaluator INFO: Inference done 240/1210. 0.0471 s / img. ETA=0:05:42
[03/28 20:30:57] d2.evaluation.evaluator INFO: Inference done 263/1210. 0.0473 s / img. ETA=0:05:23
[03/28 20:31:03] d2.evaluation.evaluator INFO: Inference done 290/1210. 0.0474 s / img. ETA=0:05:01
[03/28 20:31:08] d2.evaluation.evaluator INFO: Inference done 313/1210. 0.0474 s / img. ETA=0:04:46
[03/28 20:31:13] d2.evaluation.evaluator INFO: Inference done 337/1210. 0.0473 s / img. ETA=0:04:32
[03/28 20:31:20] d2.evaluation.evaluator INFO: Inference done 353/1210. 0.0472 s / img. ETA=0:04:31
[03/28 20:31:25] d2.evaluation.evaluator INFO: Inference done 377/1210. 0.0472 s / img. ETA=0:04:18
[03/28 20:31:30] d2.evaluation.evaluator INFO: Inference done 390/1210. 0.0471 s / img. ETA=0:04:17
[03/28 20:31:35] d2.evaluation.evaluator INFO: Inference done 409/1210. 0.0470 s / img. ETA=0:04:09
[03/28 20:31:41] d2.evaluation.evaluator INFO: Inference done 433/1210. 0.0469 s / img. ETA=0:03:58
[03/28 20:31:46] d2.evaluation.evaluator INFO: Inference done 455/1210. 0.0469 s / img. ETA=0:03:49
[03/28 20:31:52] d2.evaluation.evaluator INFO: Inference done 474/1210. 0.0469 s / img. ETA=0:03:43
[03/28 20:31:57] d2.evaluation.evaluator INFO: Inference done 498/1210. 0.0470 s / img. ETA=0:03:33
[03/28 20:32:02] d2.evaluation.evaluator INFO: Inference done 518/1210. 0.0469 s / img. ETA=0:03:26
[03/28 20:32:07] d2.evaluation.evaluator INFO: Inference done 537/1210. 0.0469 s / img. ETA=0:03:19
[03/28 20:32:13] d2.evaluation.evaluator INFO: Inference done 559/1210. 0.0468 s / img. ETA=0:03:11
[03/28 20:32:19] d2.evaluation.evaluator INFO: Inference done 578/1210. 0.0468 s / img. ETA=0:03:06
[03/28 20:32:24] d2.evaluation.evaluator INFO: Inference done 604/1210. 0.0469 s / img. ETA=0:02:56
[03/28 20:32:29] d2.evaluation.evaluator INFO: Inference done 625/1210. 0.0469 s / img. ETA=0:02:49
[03/28 20:32:34] d2.evaluation.evaluator INFO: Inference done 648/1210. 0.0469 s / img. ETA=0:02:41
[03/28 20:32:39] d2.evaluation.evaluator INFO: Inference done 672/1210. 0.0470 s / img. ETA=0:02:33
[03/28 20:32:45] d2.evaluation.evaluator INFO: Inference done 692/1210. 0.0469 s / img. ETA=0:02:27
[03/28 20:32:52] d2.evaluation.evaluator INFO: Inference done 704/1210. 0.0468 s / img. ETA=0:02:26
[03/28 20:32:57] d2.evaluation.evaluator INFO: Inference done 728/1210. 0.0467 s / img. ETA=0:02:18
[03/28 20:33:02] d2.evaluation.evaluator INFO: Inference done 754/1210. 0.0467 s / img. ETA=0:02:09
[03/28 20:33:07] d2.evaluation.evaluator INFO: Inference done 781/1210. 0.0466 s / img. ETA=0:02:00
[03/28 20:33:12] d2.evaluation.evaluator INFO: Inference done 797/1210. 0.0465 s / img. ETA=0:01:56
[03/28 20:33:17] d2.evaluation.evaluator INFO: Inference done 816/1210. 0.0465 s / img. ETA=0:01:50
[03/28 20:33:25] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0465 s / img. ETA=0:01:51
[03/28 20:33:30] d2.evaluation.evaluator INFO: Inference done 844/1210. 0.0466 s / img. ETA=0:01:44
[03/28 20:33:35] d2.evaluation.evaluator INFO: Inference done 865/1210. 0.0466 s / img. ETA=0:01:38
[03/28 20:33:40] d2.evaluation.evaluator INFO: Inference done 886/1210. 0.0466 s / img. ETA=0:01:32
[03/28 20:33:45] d2.evaluation.evaluator INFO: Inference done 911/1210. 0.0465 s / img. ETA=0:01:24
[03/28 20:33:52] d2.evaluation.evaluator INFO: Inference done 923/1210. 0.0465 s / img. ETA=0:01:22
[03/28 20:33:57] d2.evaluation.evaluator INFO: Inference done 948/1210. 0.0465 s / img. ETA=0:01:14
[03/28 20:34:02] d2.evaluation.evaluator INFO: Inference done 971/1210. 0.0465 s / img. ETA=0:01:07
[03/28 20:34:08] d2.evaluation.evaluator INFO: Inference done 989/1210. 0.0465 s / img. ETA=0:01:02
[03/28 20:34:17] d2.evaluation.evaluator INFO: Inference done 1007/1210. 0.0465 s / img. ETA=0:00:58
[03/28 20:34:22] d2.evaluation.evaluator INFO: Inference done 1024/1210. 0.0465 s / img. ETA=0:00:53
[03/28 20:34:27] d2.evaluation.evaluator INFO: Inference done 1037/1210. 0.0465 s / img. ETA=0:00:49
[03/28 20:34:32] d2.evaluation.evaluator INFO: Inference done 1062/1210. 0.0465 s / img. ETA=0:00:42
[03/28 20:34:38] d2.evaluation.evaluator INFO: Inference done 1088/1210. 0.0465 s / img. ETA=0:00:34
[03/28 20:34:43] d2.evaluation.evaluator INFO: Inference done 1112/1210. 0.0464 s / img. ETA=0:00:27
[03/28 20:34:48] d2.evaluation.evaluator INFO: Inference done 1138/1210. 0.0465 s / img. ETA=0:00:20
[03/28 20:34:54] d2.evaluation.evaluator INFO: Inference done 1147/1210. 0.0465 s / img. ETA=0:00:17
[03/28 20:35:00] d2.evaluation.evaluator INFO: Inference done 1169/1210. 0.0465 s / img. ETA=0:00:11
[03/28 20:35:05] d2.evaluation.evaluator INFO: Inference done 1188/1210. 0.0465 s / img. ETA=0:00:06
[03/28 20:35:11] d2.evaluation.evaluator INFO: Inference done 1197/1210. 0.0465 s / img. ETA=0:00:03
[03/28 20:35:15] d2.evaluation.evaluator INFO: Total inference time: 0:05:45.771053 (0.286947 s / img per device, on 1 devices)
[03/28 20:35:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:56 (0.046564 s / img per device, on 1 devices)
[03/28 20:35:15] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/28 20:35:15] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/28 20:35:15] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/28 20:35:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.468 | 62.804 | 55.409 | 33.229 | 19.739 | 42.407 |
[03/28 20:35:16] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/28 20:35:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/28 20:35:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/28 20:35:16] d2.evaluation.testing INFO: copypaste: 44.4680,62.8041,55.4093,33.2289,19.7389,42.4069
[03/28 20:35:16] d2.utils.events INFO:  eta: 0:55:02  iter: 15999  total_loss: 0.117  loss_cls: 0.035  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9607  data_time: 1.6366  lr: 0.000100  max_mem: 9421M
[03/28 20:35:49] d2.utils.events INFO:  eta: 0:54:37  iter: 16019  total_loss: 0.128  loss_cls: 0.038  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9603  data_time: 1.0739  lr: 0.000010  max_mem: 9421M
[03/28 20:36:26] d2.utils.events INFO:  eta: 0:54:00  iter: 16039  total_loss: 0.128  loss_cls: 0.035  loss_box_reg: 0.067  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9602  data_time: 1.2915  lr: 0.000010  max_mem: 9421M
[03/28 20:37:07] d2.utils.events INFO:  eta: 0:53:35  iter: 16059  total_loss: 0.121  loss_cls: 0.034  loss_box_reg: 0.068  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9603  data_time: 1.5032  lr: 0.000010  max_mem: 9421M
[03/28 20:37:42] d2.utils.events INFO:  eta: 0:53:03  iter: 16079  total_loss: 0.136  loss_cls: 0.039  loss_box_reg: 0.072  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9601  data_time: 1.1615  lr: 0.000010  max_mem: 9421M
[03/28 20:38:18] d2.utils.events INFO:  eta: 0:52:30  iter: 16099  total_loss: 0.118  loss_cls: 0.033  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9598  data_time: 1.2160  lr: 0.000010  max_mem: 9421M
[03/28 20:38:53] d2.utils.events INFO:  eta: 0:51:57  iter: 16119  total_loss: 0.120  loss_cls: 0.034  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 1.9596  data_time: 1.1811  lr: 0.000010  max_mem: 9421M
[03/28 20:39:30] d2.utils.events INFO:  eta: 0:51:23  iter: 16139  total_loss: 0.117  loss_cls: 0.035  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 1.9594  data_time: 1.2652  lr: 0.000010  max_mem: 9421M
[03/28 20:40:09] d2.utils.events INFO:  eta: 0:50:50  iter: 16159  total_loss: 0.116  loss_cls: 0.035  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9594  data_time: 1.3752  lr: 0.000010  max_mem: 9421M
[03/28 20:40:49] d2.utils.events INFO:  eta: 0:50:21  iter: 16179  total_loss: 0.118  loss_cls: 0.034  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9595  data_time: 1.4252  lr: 0.000010  max_mem: 9421M
[03/28 20:41:23] d2.utils.events INFO:  eta: 0:49:45  iter: 16199  total_loss: 0.115  loss_cls: 0.037  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9591  data_time: 1.1430  lr: 0.000010  max_mem: 9421M
[03/28 20:42:02] d2.utils.events INFO:  eta: 0:49:14  iter: 16219  total_loss: 0.134  loss_cls: 0.038  loss_box_reg: 0.067  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9591  data_time: 1.3800  lr: 0.000010  max_mem: 9421M
[03/28 20:42:44] d2.utils.events INFO:  eta: 0:48:38  iter: 16239  total_loss: 0.110  loss_cls: 0.036  loss_box_reg: 0.065  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9593  data_time: 1.5291  lr: 0.000010  max_mem: 9421M
[03/28 20:43:17] d2.utils.events INFO:  eta: 0:48:14  iter: 16259  total_loss: 0.136  loss_cls: 0.038  loss_box_reg: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9589  data_time: 1.1124  lr: 0.000010  max_mem: 9421M
[03/28 20:43:56] d2.utils.events INFO:  eta: 0:47:48  iter: 16279  total_loss: 0.115  loss_cls: 0.035  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9589  data_time: 1.3573  lr: 0.000010  max_mem: 9421M
[03/28 20:44:36] d2.utils.events INFO:  eta: 0:47:22  iter: 16299  total_loss: 0.130  loss_cls: 0.037  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9589  data_time: 1.4704  lr: 0.000010  max_mem: 9421M
[03/28 20:45:12] d2.utils.events INFO:  eta: 0:46:49  iter: 16319  total_loss: 0.122  loss_cls: 0.035  loss_box_reg: 0.067  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9587  data_time: 1.2313  lr: 0.000010  max_mem: 9421M
[03/28 20:46:12] d2.utils.events INFO:  eta: 0:46:19  iter: 16339  total_loss: 0.128  loss_cls: 0.034  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9600  data_time: 2.4043  lr: 0.000010  max_mem: 9421M
[03/28 20:46:59] d2.utils.events INFO:  eta: 0:45:53  iter: 16359  total_loss: 0.118  loss_cls: 0.033  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9605  data_time: 1.7941  lr: 0.000010  max_mem: 9421M
[03/28 20:47:33] d2.utils.events INFO:  eta: 0:45:27  iter: 16379  total_loss: 0.128  loss_cls: 0.035  loss_box_reg: 0.058  loss_rpn_cls: 0.003  loss_rpn_loc: 0.021  time: 1.9602  data_time: 1.1583  lr: 0.000010  max_mem: 9421M
[03/28 20:48:09] d2.utils.events INFO:  eta: 0:44:46  iter: 16399  total_loss: 0.122  loss_cls: 0.040  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 1.9600  data_time: 1.2102  lr: 0.000010  max_mem: 9421M
[03/28 20:48:45] d2.utils.events INFO:  eta: 0:44:12  iter: 16419  total_loss: 0.119  loss_cls: 0.035  loss_box_reg: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.9598  data_time: 1.2172  lr: 0.000010  max_mem: 9421M
[03/28 20:49:20] d2.utils.events INFO:  eta: 0:43:32  iter: 16439  total_loss: 0.121  loss_cls: 0.035  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9595  data_time: 1.1841  lr: 0.000010  max_mem: 9421M
[03/28 20:50:06] d2.utils.events INFO:  eta: 0:43:05  iter: 16459  total_loss: 0.128  loss_cls: 0.038  loss_box_reg: 0.068  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 1.9600  data_time: 1.7278  lr: 0.000010  max_mem: 9421M
[03/28 20:50:45] d2.utils.events INFO:  eta: 0:42:31  iter: 16479  total_loss: 0.119  loss_cls: 0.035  loss_box_reg: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.9599  data_time: 1.3230  lr: 0.000010  max_mem: 9421M
[03/28 20:51:33] d2.utils.events INFO:  eta: 0:42:17  iter: 16499  total_loss: 0.116  loss_cls: 0.031  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9604  data_time: 1.8402  lr: 0.000010  max_mem: 9421M
[03/28 20:52:10] d2.utils.events INFO:  eta: 0:41:41  iter: 16519  total_loss: 0.119  loss_cls: 0.033  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9603  data_time: 1.2978  lr: 0.000010  max_mem: 9421M
[03/28 20:52:44] d2.utils.events INFO:  eta: 0:40:59  iter: 16539  total_loss: 0.115  loss_cls: 0.031  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9600  data_time: 1.1085  lr: 0.000010  max_mem: 9421M
[03/28 20:53:16] d2.utils.events INFO:  eta: 0:40:11  iter: 16559  total_loss: 0.122  loss_cls: 0.040  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9596  data_time: 1.0618  lr: 0.000010  max_mem: 9421M
[03/28 20:53:50] d2.utils.events INFO:  eta: 0:39:38  iter: 16579  total_loss: 0.120  loss_cls: 0.036  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9592  data_time: 1.1219  lr: 0.000010  max_mem: 9421M
[03/28 20:54:30] d2.utils.events INFO:  eta: 0:38:56  iter: 16599  total_loss: 0.119  loss_cls: 0.035  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9593  data_time: 1.4328  lr: 0.000010  max_mem: 9421M
[03/28 20:55:05] d2.utils.events INFO:  eta: 0:38:17  iter: 16619  total_loss: 0.110  loss_cls: 0.034  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9590  data_time: 1.1738  lr: 0.000010  max_mem: 9421M
[03/28 20:55:39] d2.utils.events INFO:  eta: 0:37:43  iter: 16639  total_loss: 0.110  loss_cls: 0.035  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9587  data_time: 1.0990  lr: 0.000010  max_mem: 9421M
[03/28 20:56:24] d2.utils.events INFO:  eta: 0:37:02  iter: 16659  total_loss: 0.120  loss_cls: 0.035  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9591  data_time: 1.6792  lr: 0.000010  max_mem: 9421M
[03/28 20:56:59] d2.utils.events INFO:  eta: 0:36:15  iter: 16679  total_loss: 0.121  loss_cls: 0.041  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9588  data_time: 1.1624  lr: 0.000010  max_mem: 9421M
[03/28 20:57:41] d2.utils.events INFO:  eta: 0:35:37  iter: 16699  total_loss: 0.110  loss_cls: 0.034  loss_box_reg: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.017  time: 1.9590  data_time: 1.5323  lr: 0.000010  max_mem: 9421M
[03/28 20:58:21] d2.utils.events INFO:  eta: 0:35:03  iter: 16719  total_loss: 0.116  loss_cls: 0.034  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9590  data_time: 1.4136  lr: 0.000010  max_mem: 9421M
[03/28 20:58:54] d2.utils.events INFO:  eta: 0:34:28  iter: 16739  total_loss: 0.114  loss_cls: 0.034  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.9587  data_time: 1.1210  lr: 0.000010  max_mem: 9421M
[03/28 20:59:30] d2.utils.events INFO:  eta: 0:33:43  iter: 16759  total_loss: 0.127  loss_cls: 0.036  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9585  data_time: 1.2132  lr: 0.000010  max_mem: 9421M
[03/28 21:00:08] d2.utils.events INFO:  eta: 0:33:19  iter: 16779  total_loss: 0.122  loss_cls: 0.040  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9584  data_time: 1.3112  lr: 0.000010  max_mem: 9421M
[03/28 21:00:41] d2.utils.events INFO:  eta: 0:32:44  iter: 16799  total_loss: 0.108  loss_cls: 0.031  loss_box_reg: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  time: 1.9580  data_time: 1.0877  lr: 0.000010  max_mem: 9421M
[03/28 21:01:17] d2.utils.events INFO:  eta: 0:32:11  iter: 16819  total_loss: 0.119  loss_cls: 0.033  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9578  data_time: 1.2398  lr: 0.000010  max_mem: 9421M
[03/28 21:02:00] d2.utils.events INFO:  eta: 0:31:41  iter: 16839  total_loss: 0.121  loss_cls: 0.035  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9578  data_time: 1.4056  lr: 0.000010  max_mem: 9421M
[03/28 21:02:46] d2.utils.events INFO:  eta: 0:31:12  iter: 16859  total_loss: 0.121  loss_cls: 0.034  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9583  data_time: 1.7492  lr: 0.000010  max_mem: 9421M
[03/28 21:03:21] d2.utils.events INFO:  eta: 0:30:41  iter: 16879  total_loss: 0.123  loss_cls: 0.037  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 1.9580  data_time: 1.1508  lr: 0.000010  max_mem: 9421M
[03/28 21:04:01] d2.utils.events INFO:  eta: 0:30:08  iter: 16899  total_loss: 0.112  loss_cls: 0.031  loss_box_reg: 0.057  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 1.9580  data_time: 1.4342  lr: 0.000010  max_mem: 9421M
[03/28 21:04:34] d2.utils.events INFO:  eta: 0:29:30  iter: 16919  total_loss: 0.113  loss_cls: 0.032  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9577  data_time: 1.0910  lr: 0.000010  max_mem: 9421M
[03/28 21:05:09] d2.utils.events INFO:  eta: 0:28:50  iter: 16939  total_loss: 0.114  loss_cls: 0.030  loss_box_reg: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 1.9574  data_time: 1.2089  lr: 0.000010  max_mem: 9421M
[03/28 21:05:48] d2.utils.events INFO:  eta: 0:28:10  iter: 16959  total_loss: 0.113  loss_cls: 0.035  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9574  data_time: 1.3875  lr: 0.000010  max_mem: 9421M
[03/28 21:06:29] d2.utils.events INFO:  eta: 0:27:36  iter: 16979  total_loss: 0.107  loss_cls: 0.032  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9575  data_time: 1.4559  lr: 0.000010  max_mem: 9421M
[03/28 21:07:13] d2.utils.events INFO:  eta: 0:27:03  iter: 16999  total_loss: 0.115  loss_cls: 0.035  loss_box_reg: 0.063  loss_rpn_cls: 0.004  loss_rpn_loc: 0.015  time: 1.9578  data_time: 1.6315  lr: 0.000010  max_mem: 9421M
[03/28 21:07:46] d2.utils.events INFO:  eta: 0:26:31  iter: 17019  total_loss: 0.111  loss_cls: 0.036  loss_box_reg: 0.053  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9574  data_time: 1.0814  lr: 0.000010  max_mem: 9421M
[03/28 21:08:19] d2.utils.events INFO:  eta: 0:25:58  iter: 17039  total_loss: 0.120  loss_cls: 0.034  loss_box_reg: 0.061  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9571  data_time: 1.1200  lr: 0.000010  max_mem: 9421M
[03/28 21:08:53] d2.utils.events INFO:  eta: 0:25:23  iter: 17059  total_loss: 0.112  loss_cls: 0.036  loss_box_reg: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.018  time: 1.9568  data_time: 1.1380  lr: 0.000010  max_mem: 9421M
[03/28 21:09:27] d2.utils.events INFO:  eta: 0:24:50  iter: 17079  total_loss: 0.119  loss_cls: 0.032  loss_box_reg: 0.063  loss_rpn_cls: 0.003  loss_rpn_loc: 0.012  time: 1.9565  data_time: 1.1308  lr: 0.000010  max_mem: 9421M
[03/28 21:10:08] d2.utils.events INFO:  eta: 0:24:18  iter: 17099  total_loss: 0.119  loss_cls: 0.036  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9566  data_time: 1.4954  lr: 0.000010  max_mem: 9421M
[03/28 21:10:40] d2.utils.events INFO:  eta: 0:23:42  iter: 17119  total_loss: 0.125  loss_cls: 0.038  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 1.9562  data_time: 1.0246  lr: 0.000010  max_mem: 9421M
[03/28 21:11:21] d2.utils.events INFO:  eta: 0:23:09  iter: 17139  total_loss: 0.113  loss_cls: 0.034  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9562  data_time: 1.4690  lr: 0.000010  max_mem: 9421M
[03/28 21:12:01] d2.utils.events INFO:  eta: 0:22:39  iter: 17159  total_loss: 0.104  loss_cls: 0.033  loss_box_reg: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9563  data_time: 1.3686  lr: 0.000010  max_mem: 9421M
[03/28 21:12:41] d2.utils.events INFO:  eta: 0:22:10  iter: 17179  total_loss: 0.123  loss_cls: 0.032  loss_box_reg: 0.060  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9563  data_time: 1.4292  lr: 0.000010  max_mem: 9421M
[03/28 21:13:19] d2.utils.events INFO:  eta: 0:21:37  iter: 17199  total_loss: 0.120  loss_cls: 0.035  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9563  data_time: 1.3486  lr: 0.000010  max_mem: 9421M
[03/28 21:14:04] d2.utils.events INFO:  eta: 0:21:07  iter: 17219  total_loss: 0.114  loss_cls: 0.033  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9566  data_time: 1.6595  lr: 0.000010  max_mem: 9421M
[03/28 21:14:45] d2.utils.events INFO:  eta: 0:20:33  iter: 17239  total_loss: 0.130  loss_cls: 0.037  loss_box_reg: 0.072  loss_rpn_cls: 0.002  loss_rpn_loc: 0.025  time: 1.9567  data_time: 1.4737  lr: 0.000010  max_mem: 9421M
[03/28 21:15:23] d2.utils.events INFO:  eta: 0:19:59  iter: 17259  total_loss: 0.113  loss_cls: 0.036  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9566  data_time: 1.3260  lr: 0.000010  max_mem: 9421M
[03/28 21:15:56] d2.utils.events INFO:  eta: 0:19:25  iter: 17279  total_loss: 0.108  loss_cls: 0.033  loss_box_reg: 0.057  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9563  data_time: 1.0765  lr: 0.000010  max_mem: 9421M
[03/28 21:16:31] d2.utils.events INFO:  eta: 0:18:50  iter: 17299  total_loss: 0.128  loss_cls: 0.035  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  time: 1.9560  data_time: 1.1561  lr: 0.000010  max_mem: 9421M
[03/28 21:17:05] d2.utils.events INFO:  eta: 0:18:20  iter: 17319  total_loss: 0.124  loss_cls: 0.039  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9558  data_time: 1.1769  lr: 0.000010  max_mem: 9421M
[03/28 21:17:51] d2.utils.events INFO:  eta: 0:17:46  iter: 17339  total_loss: 0.114  loss_cls: 0.032  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9561  data_time: 1.6848  lr: 0.000010  max_mem: 9421M
[03/28 21:18:36] d2.utils.events INFO:  eta: 0:17:15  iter: 17359  total_loss: 0.122  loss_cls: 0.036  loss_box_reg: 0.065  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 1.9565  data_time: 1.7308  lr: 0.000010  max_mem: 9421M
[03/28 21:19:11] d2.utils.events INFO:  eta: 0:16:43  iter: 17379  total_loss: 0.120  loss_cls: 0.038  loss_box_reg: 0.067  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9562  data_time: 1.1282  lr: 0.000010  max_mem: 9421M
[03/28 21:19:44] d2.utils.events INFO:  eta: 0:16:10  iter: 17399  total_loss: 0.118  loss_cls: 0.034  loss_box_reg: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.018  time: 1.9559  data_time: 1.0959  lr: 0.000010  max_mem: 9421M
[03/28 21:20:19] d2.utils.events INFO:  eta: 0:15:37  iter: 17419  total_loss: 0.098  loss_cls: 0.031  loss_box_reg: 0.055  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 1.9557  data_time: 1.2070  lr: 0.000010  max_mem: 9421M
[03/28 21:20:54] d2.utils.events INFO:  eta: 0:15:05  iter: 17439  total_loss: 0.112  loss_cls: 0.034  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 1.9554  data_time: 1.1435  lr: 0.000010  max_mem: 9421M
[03/28 21:21:28] d2.utils.events INFO:  eta: 0:14:33  iter: 17459  total_loss: 0.140  loss_cls: 0.041  loss_box_reg: 0.078  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9551  data_time: 1.0883  lr: 0.000010  max_mem: 9421M
[03/28 21:22:16] d2.utils.events INFO:  eta: 0:14:01  iter: 17479  total_loss: 0.118  loss_cls: 0.036  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9556  data_time: 1.8842  lr: 0.000010  max_mem: 9421M
[03/28 21:22:56] d2.utils.events INFO:  eta: 0:13:27  iter: 17499  total_loss: 0.114  loss_cls: 0.037  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9556  data_time: 1.3573  lr: 0.000010  max_mem: 9421M
[03/28 21:23:34] d2.utils.events INFO:  eta: 0:12:53  iter: 17519  total_loss: 0.118  loss_cls: 0.036  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9556  data_time: 1.3250  lr: 0.000010  max_mem: 9421M
[03/28 21:24:08] d2.utils.events INFO:  eta: 0:12:24  iter: 17539  total_loss: 0.112  loss_cls: 0.033  loss_box_reg: 0.055  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9553  data_time: 1.1265  lr: 0.000010  max_mem: 9421M
[03/28 21:24:44] d2.utils.events INFO:  eta: 0:11:53  iter: 17559  total_loss: 0.119  loss_cls: 0.034  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9551  data_time: 1.2304  lr: 0.000010  max_mem: 9421M
[03/28 21:25:24] d2.utils.events INFO:  eta: 0:11:20  iter: 17579  total_loss: 0.122  loss_cls: 0.035  loss_box_reg: 0.058  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9552  data_time: 1.4498  lr: 0.000010  max_mem: 9421M
[03/28 21:26:00] d2.utils.events INFO:  eta: 0:10:48  iter: 17599  total_loss: 0.118  loss_cls: 0.036  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 1.9550  data_time: 1.2037  lr: 0.000010  max_mem: 9421M
[03/28 21:26:38] d2.utils.events INFO:  eta: 0:10:15  iter: 17619  total_loss: 0.120  loss_cls: 0.035  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9549  data_time: 1.3501  lr: 0.000010  max_mem: 9421M
[03/28 21:27:14] d2.utils.events INFO:  eta: 0:09:43  iter: 17639  total_loss: 0.124  loss_cls: 0.032  loss_box_reg: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9547  data_time: 1.1737  lr: 0.000010  max_mem: 9421M
[03/28 21:27:46] d2.utils.events INFO:  eta: 0:09:12  iter: 17659  total_loss: 0.123  loss_cls: 0.035  loss_box_reg: 0.064  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9544  data_time: 1.0875  lr: 0.000010  max_mem: 9421M
[03/28 21:28:21] d2.utils.events INFO:  eta: 0:08:39  iter: 17679  total_loss: 0.122  loss_cls: 0.033  loss_box_reg: 0.063  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9541  data_time: 1.1460  lr: 0.000010  max_mem: 9421M
[03/28 21:28:58] d2.utils.events INFO:  eta: 0:08:03  iter: 17699  total_loss: 0.124  loss_cls: 0.035  loss_box_reg: 0.069  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 1.9540  data_time: 1.2831  lr: 0.000010  max_mem: 9421M
[03/28 21:29:37] d2.utils.events INFO:  eta: 0:07:35  iter: 17719  total_loss: 0.111  loss_cls: 0.035  loss_box_reg: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 1.9540  data_time: 1.3785  lr: 0.000010  max_mem: 9421M
[03/28 21:30:19] d2.utils.events INFO:  eta: 0:07:03  iter: 17739  total_loss: 0.116  loss_cls: 0.034  loss_box_reg: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.9541  data_time: 1.5252  lr: 0.000010  max_mem: 9421M
[03/28 21:30:52] d2.utils.events INFO:  eta: 0:06:31  iter: 17759  total_loss: 0.116  loss_cls: 0.034  loss_box_reg: 0.066  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9538  data_time: 1.0946  lr: 0.000010  max_mem: 9421M
[03/28 21:31:27] d2.utils.events INFO:  eta: 0:05:58  iter: 17779  total_loss: 0.122  loss_cls: 0.036  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9536  data_time: 1.1753  lr: 0.000010  max_mem: 9421M
[03/28 21:32:05] d2.utils.events INFO:  eta: 0:05:25  iter: 17799  total_loss: 0.101  loss_cls: 0.031  loss_box_reg: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 1.9535  data_time: 1.3131  lr: 0.000010  max_mem: 9421M
[03/28 21:32:40] d2.utils.events INFO:  eta: 0:04:53  iter: 17819  total_loss: 0.127  loss_cls: 0.041  loss_box_reg: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.9532  data_time: 1.1477  lr: 0.000010  max_mem: 9421M
[03/28 21:33:12] d2.utils.events INFO:  eta: 0:04:20  iter: 17839  total_loss: 0.128  loss_cls: 0.041  loss_box_reg: 0.070  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 1.9528  data_time: 0.9833  lr: 0.000010  max_mem: 9421M
[03/28 21:33:51] d2.utils.events INFO:  eta: 0:03:47  iter: 17859  total_loss: 0.121  loss_cls: 0.033  loss_box_reg: 0.058  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 1.9528  data_time: 1.3995  lr: 0.000010  max_mem: 9421M
[03/28 21:34:40] d2.utils.events INFO:  eta: 0:03:15  iter: 17879  total_loss: 0.102  loss_cls: 0.030  loss_box_reg: 0.050  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 1.9534  data_time: 1.9040  lr: 0.000010  max_mem: 9421M
[03/28 21:35:14] d2.utils.events INFO:  eta: 0:02:42  iter: 17899  total_loss: 0.105  loss_cls: 0.033  loss_box_reg: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  time: 1.9531  data_time: 1.1512  lr: 0.000010  max_mem: 9421M
[03/28 21:35:48] d2.utils.events INFO:  eta: 0:02:10  iter: 17919  total_loss: 0.124  loss_cls: 0.035  loss_box_reg: 0.056  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.9528  data_time: 1.1343  lr: 0.000010  max_mem: 9421M
[03/28 21:36:28] d2.utils.events INFO:  eta: 0:01:38  iter: 17939  total_loss: 0.117  loss_cls: 0.033  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.020  time: 1.9529  data_time: 1.3882  lr: 0.000010  max_mem: 9421M
[03/28 21:37:08] d2.utils.events INFO:  eta: 0:01:06  iter: 17959  total_loss: 0.131  loss_cls: 0.039  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.020  time: 1.9529  data_time: 1.4273  lr: 0.000010  max_mem: 9421M
[03/28 21:37:53] d2.utils.events INFO:  eta: 0:00:33  iter: 17979  total_loss: 0.121  loss_cls: 0.034  loss_box_reg: 0.062  loss_rpn_cls: 0.002  loss_rpn_loc: 0.022  time: 1.9532  data_time: 1.6708  lr: 0.000010  max_mem: 9421M
[03/28 21:38:35] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/lr0.001_finetune/model_final.pth
[03/28 21:38:38] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/28 21:38:38] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/28 21:38:38] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/28 21:38:38] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/28 21:38:40] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0494 s / img. ETA=0:03:21
[03/28 21:38:46] d2.evaluation.evaluator INFO: Inference done 30/1210. 0.0464 s / img. ETA=0:04:46
[03/28 21:38:53] d2.evaluation.evaluator INFO: Inference done 51/1210. 0.0467 s / img. ETA=0:05:28
[03/28 21:38:58] d2.evaluation.evaluator INFO: Inference done 68/1210. 0.0461 s / img. ETA=0:05:27
[03/28 21:39:03] d2.evaluation.evaluator INFO: Inference done 74/1210. 0.0465 s / img. ETA=0:06:19
[03/28 21:39:13] d2.evaluation.evaluator INFO: Inference done 92/1210. 0.0473 s / img. ETA=0:07:11
[03/28 21:39:18] d2.evaluation.evaluator INFO: Inference done 113/1210. 0.0483 s / img. ETA=0:06:32
[03/28 21:39:23] d2.evaluation.evaluator INFO: Inference done 137/1210. 0.0489 s / img. ETA=0:05:54
[03/28 21:39:28] d2.evaluation.evaluator INFO: Inference done 155/1210. 0.0493 s / img. ETA=0:05:43
[03/28 21:39:33] d2.evaluation.evaluator INFO: Inference done 171/1210. 0.0491 s / img. ETA=0:05:38
[03/28 21:39:39] d2.evaluation.evaluator INFO: Inference done 189/1210. 0.0492 s / img. ETA=0:05:28
[03/28 21:39:44] d2.evaluation.evaluator INFO: Inference done 213/1210. 0.0491 s / img. ETA=0:05:08
[03/28 21:39:49] d2.evaluation.evaluator INFO: Inference done 235/1210. 0.0489 s / img. ETA=0:04:54
[03/28 21:39:54] d2.evaluation.evaluator INFO: Inference done 254/1210. 0.0489 s / img. ETA=0:04:46
[03/28 21:39:59] d2.evaluation.evaluator INFO: Inference done 276/1210. 0.0490 s / img. ETA=0:04:34
[03/28 21:40:05] d2.evaluation.evaluator INFO: Inference done 302/1210. 0.0492 s / img. ETA=0:04:22
[03/28 21:40:10] d2.evaluation.evaluator INFO: Inference done 325/1210. 0.0493 s / img. ETA=0:04:11
[03/28 21:40:16] d2.evaluation.evaluator INFO: Inference done 347/1210. 0.0492 s / img. ETA=0:04:02
[03/28 21:40:21] d2.evaluation.evaluator INFO: Inference done 367/1210. 0.0493 s / img. ETA=0:03:55
[03/28 21:40:26] d2.evaluation.evaluator INFO: Inference done 379/1210. 0.0494 s / img. ETA=0:03:56
[03/28 21:40:31] d2.evaluation.evaluator INFO: Inference done 397/1210. 0.0492 s / img. ETA=0:03:50
[03/28 21:40:36] d2.evaluation.evaluator INFO: Inference done 418/1210. 0.0492 s / img. ETA=0:03:43
[03/28 21:40:41] d2.evaluation.evaluator INFO: Inference done 437/1210. 0.0490 s / img. ETA=0:03:37
[03/28 21:40:46] d2.evaluation.evaluator INFO: Inference done 455/1210. 0.0490 s / img. ETA=0:03:32
[03/28 21:40:52] d2.evaluation.evaluator INFO: Inference done 474/1210. 0.0490 s / img. ETA=0:03:28
[03/28 21:40:57] d2.evaluation.evaluator INFO: Inference done 496/1210. 0.0489 s / img. ETA=0:03:20
[03/28 21:41:03] d2.evaluation.evaluator INFO: Inference done 516/1210. 0.0488 s / img. ETA=0:03:14
[03/28 21:41:08] d2.evaluation.evaluator INFO: Inference done 533/1210. 0.0488 s / img. ETA=0:03:10
[03/28 21:41:13] d2.evaluation.evaluator INFO: Inference done 557/1210. 0.0487 s / img. ETA=0:03:01
[03/28 21:41:18] d2.evaluation.evaluator INFO: Inference done 573/1210. 0.0486 s / img. ETA=0:02:57
[03/28 21:41:23] d2.evaluation.evaluator INFO: Inference done 587/1210. 0.0487 s / img. ETA=0:02:55
[03/28 21:41:28] d2.evaluation.evaluator INFO: Inference done 609/1210. 0.0486 s / img. ETA=0:02:47
[03/28 21:41:34] d2.evaluation.evaluator INFO: Inference done 637/1210. 0.0485 s / img. ETA=0:02:37
[03/28 21:41:39] d2.evaluation.evaluator INFO: Inference done 664/1210. 0.0484 s / img. ETA=0:02:28
[03/28 21:41:44] d2.evaluation.evaluator INFO: Inference done 687/1210. 0.0483 s / img. ETA=0:02:21
[03/28 21:41:49] d2.evaluation.evaluator INFO: Inference done 703/1210. 0.0482 s / img. ETA=0:02:17
[03/28 21:41:54] d2.evaluation.evaluator INFO: Inference done 725/1210. 0.0480 s / img. ETA=0:02:11
[03/28 21:41:59] d2.evaluation.evaluator INFO: Inference done 752/1210. 0.0479 s / img. ETA=0:02:02
[03/28 21:42:05] d2.evaluation.evaluator INFO: Inference done 779/1210. 0.0478 s / img. ETA=0:01:54
[03/28 21:42:10] d2.evaluation.evaluator INFO: Inference done 797/1210. 0.0476 s / img. ETA=0:01:49
[03/28 21:42:15] d2.evaluation.evaluator INFO: Inference done 817/1210. 0.0476 s / img. ETA=0:01:44
[03/28 21:42:22] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0476 s / img. ETA=0:01:45
[03/28 21:42:27] d2.evaluation.evaluator INFO: Inference done 846/1210. 0.0475 s / img. ETA=0:01:38
[03/28 21:42:34] d2.evaluation.evaluator INFO: Inference done 858/1210. 0.0475 s / img. ETA=0:01:36
[03/28 21:42:39] d2.evaluation.evaluator INFO: Inference done 882/1210. 0.0475 s / img. ETA=0:01:29
[03/28 21:42:44] d2.evaluation.evaluator INFO: Inference done 907/1210. 0.0474 s / img. ETA=0:01:22
[03/28 21:42:49] d2.evaluation.evaluator INFO: Inference done 932/1210. 0.0474 s / img. ETA=0:01:14
[03/28 21:42:54] d2.evaluation.evaluator INFO: Inference done 954/1210. 0.0473 s / img. ETA=0:01:08
[03/28 21:42:59] d2.evaluation.evaluator INFO: Inference done 973/1210. 0.0473 s / img. ETA=0:01:03
[03/28 21:43:04] d2.evaluation.evaluator INFO: Inference done 989/1210. 0.0473 s / img. ETA=0:00:59
[03/28 21:43:09] d2.evaluation.evaluator INFO: Inference done 1012/1210. 0.0473 s / img. ETA=0:00:53
[03/28 21:43:16] d2.evaluation.evaluator INFO: Inference done 1021/1210. 0.0472 s / img. ETA=0:00:51
[03/28 21:43:21] d2.evaluation.evaluator INFO: Inference done 1045/1210. 0.0472 s / img. ETA=0:00:44
[03/28 21:43:27] d2.evaluation.evaluator INFO: Inference done 1069/1210. 0.0472 s / img. ETA=0:00:38
[03/28 21:43:32] d2.evaluation.evaluator INFO: Inference done 1092/1210. 0.0471 s / img. ETA=0:00:31
[03/28 21:43:37] d2.evaluation.evaluator INFO: Inference done 1120/1210. 0.0471 s / img. ETA=0:00:23
[03/28 21:43:44] d2.evaluation.evaluator INFO: Inference done 1137/1210. 0.0471 s / img. ETA=0:00:19
[03/28 21:43:49] d2.evaluation.evaluator INFO: Inference done 1161/1210. 0.0471 s / img. ETA=0:00:13
[03/28 21:43:54] d2.evaluation.evaluator INFO: Inference done 1181/1210. 0.0471 s / img. ETA=0:00:07
[03/28 21:43:59] d2.evaluation.evaluator INFO: Inference done 1185/1210. 0.0470 s / img. ETA=0:00:06
[03/28 21:44:04] d2.evaluation.evaluator INFO: Inference done 1205/1210. 0.0470 s / img. ETA=0:00:01
[03/28 21:44:06] d2.evaluation.evaluator INFO: Total inference time: 0:05:26.083971 (0.270609 s / img per device, on 1 devices)
[03/28 21:44:06] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:56 (0.047004 s / img per device, on 1 devices)
[03/28 21:44:06] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/28 21:44:06] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/28 21:44:06] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/28 21:44:07] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.637 | 62.832 | 55.451 | 33.915 | 19.784 | 42.495 |
[03/28 21:44:07] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/28 21:44:07] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/28 21:44:07] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/28 21:44:07] d2.evaluation.testing INFO: copypaste: 44.6371,62.8318,55.4511,33.9146,19.7837,42.4950
[03/28 21:44:07] d2.utils.events INFO:  eta: 0:00:01  iter: 17999  total_loss: 0.122  loss_cls: 0.036  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 1.9534  data_time: 1.5391  lr: 0.000010  max_mem: 9421M
[03/28 21:44:07] d2.engine.hooks INFO: Overall training speed: 17997 iterations in 9:45:58 (1.9536 s / it)
[03/28 21:44:07] d2.engine.hooks INFO: Total training time: 10:39:21 (0:53:23 on hooks)
[03/30 10:33:30] detectron2 INFO: Rank of current process: 0. World size: 1
[03/30 10:33:31] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.7 (default, Mar 23 2020, 22:36:06) [GCC 7.3.0]
numpy                   1.18.1
detectron2              0.1.3 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/detectron2
Compiler                GCC 5.4
CUDA compiler           CUDA 9.2
detectron2 arch flags   sm_70
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.5.0 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   TITAN V
CUDA_HOME               /usr/local/cuda-11.2
Pillow                  7.0.0
torchvision             0.6.0a0+82fd1c8 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70
fvcore                  0.1.1.post20200623
cv2                     4.2.0
----------------------  -------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 9.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[03/30 10:33:31] detectron2 INFO: Command line arguments: Namespace(config_file='configs/faster_rcnn_login_lr0.001_finetune.yaml', dist_url='tcp://127.0.0.1:49923', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/lr0.001_finetune/model_final.pth'], resume=False)
[03/30 10:33:31] detectron2 INFO: Contents of args.config_file=configs/faster_rcnn_login_lr0.001_finetune.yaml:
_BASE_: "./bases/Base-RCNN-FPN.yaml"
MODEL:
  # COCO ResNet50 weights
  WEIGHTS: "./output/lr0.001_aug/model_final.pth"
  MASK_ON: False # Not doing segmentation
  RESNETS:
    DEPTH: 50 # ResNet50
  ROI_HEADS:
    NUM_CLASSES: 1 # Change to suit own task
    # Can reduce this for lower memory/faster training; Default 512
    BATCH_SIZE_PER_IMAGE: 512
  BACKBONE:
    FREEZE_AT: 2 # Default 2
DATASETS:
  TRAIN: ("login_train",)
  TEST: ("login_test",)
DATALOADER:
  NUM_WORKERS: 0
SOLVER:
  IMS_PER_BATCH: 8 # Batch size; Default 16
  BASE_LR: 0.001
  # (2/3, 8/9)
  STEPS: (12000, 16000) # The iteration number to decrease learning rate by GAMMA.
  MAX_ITER: 18000 # Number of training iterations
  CHECKPOINT_PERIOD: 4000 # Saves checkpoint every number of steps
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800) # Image input sizes
TEST:
  # The period (in terms of steps) to evaluate the model during training.
  # Set to 0 to disable.
  EVAL_PERIOD: 2000
OUTPUT_DIR: "./output/lr0.001_finetune" # Specify output directory



[03/30 10:33:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 0
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('login_test',)
  TRAIN: ('login_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: output/lr0.001_finetune/model_final.pth
OUTPUT_DIR: ./output/lr0.001_finetune
SEED: -1
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: False
  STEPS: (12000, 16000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 2000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[03/30 10:33:31] detectron2 INFO: Full config saved to ./output/lr0.001_finetune/config.yaml
[03/30 10:33:31] d2.utils.env INFO: Using a generated random seed 33459711
[03/30 10:33:34] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[03/30 10:33:34] fvcore.common.checkpoint INFO: Loading checkpoint from output/lr0.001_finetune/model_final.pth
[03/30 10:33:34] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/30 10:33:35] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   login    | 2862         |
|            |              |[0m
[03/30 10:33:35] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/30 10:33:35] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/30 10:33:35] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/30 10:33:37] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0523 s / img. ETA=0:03:16
[03/30 10:33:42] d2.evaluation.evaluator INFO: Inference done 31/1210. 0.0486 s / img. ETA=0:04:38
[03/30 10:33:47] d2.evaluation.evaluator INFO: Inference done 54/1210. 0.0474 s / img. ETA=0:04:23
[03/30 10:33:55] d2.evaluation.evaluator INFO: Inference done 71/1210. 0.0470 s / img. ETA=0:05:26
[03/30 10:34:00] d2.evaluation.evaluator INFO: Inference done 90/1210. 0.0472 s / img. ETA=0:05:16
[03/30 10:34:05] d2.evaluation.evaluator INFO: Inference done 113/1210. 0.0474 s / img. ETA=0:04:55
[03/30 10:34:14] d2.evaluation.evaluator INFO: Inference done 138/1210. 0.0482 s / img. ETA=0:05:11
[03/30 10:34:20] d2.evaluation.evaluator INFO: Inference done 156/1210. 0.0480 s / img. ETA=0:05:05
[03/30 10:34:25] d2.evaluation.evaluator INFO: Inference done 175/1210. 0.0475 s / img. ETA=0:04:57
[03/30 10:34:30] d2.evaluation.evaluator INFO: Inference done 195/1210. 0.0476 s / img. ETA=0:04:48
[03/30 10:34:35] d2.evaluation.evaluator INFO: Inference done 202/1210. 0.0477 s / img. ETA=0:05:02
[03/30 10:34:40] d2.evaluation.evaluator INFO: Inference done 229/1210. 0.0477 s / img. ETA=0:04:41
[03/30 10:34:45] d2.evaluation.evaluator INFO: Inference done 247/1210. 0.0474 s / img. ETA=0:04:36
[03/30 10:34:51] d2.evaluation.evaluator INFO: Inference done 270/1210. 0.0474 s / img. ETA=0:04:25
[03/30 10:34:57] d2.evaluation.evaluator INFO: Inference done 286/1210. 0.0474 s / img. ETA=0:04:27
[03/30 10:35:02] d2.evaluation.evaluator INFO: Inference done 310/1210. 0.0474 s / img. ETA=0:04:15
[03/30 10:35:07] d2.evaluation.evaluator INFO: Inference done 331/1210. 0.0473 s / img. ETA=0:04:07
[03/30 10:35:12] d2.evaluation.evaluator INFO: Inference done 354/1210. 0.0472 s / img. ETA=0:03:57
[03/30 10:35:19] d2.evaluation.evaluator INFO: Inference done 379/1210. 0.0472 s / img. ETA=0:03:50
[03/30 10:35:25] d2.evaluation.evaluator INFO: Inference done 401/1210. 0.0470 s / img. ETA=0:03:42
[03/30 10:35:30] d2.evaluation.evaluator INFO: Inference done 420/1210. 0.0470 s / img. ETA=0:03:36
[03/30 10:35:35] d2.evaluation.evaluator INFO: Inference done 441/1210. 0.0468 s / img. ETA=0:03:29
[03/30 10:35:40] d2.evaluation.evaluator INFO: Inference done 461/1210. 0.0467 s / img. ETA=0:03:23
[03/30 10:35:45] d2.evaluation.evaluator INFO: Inference done 477/1210. 0.0466 s / img. ETA=0:03:20
[03/30 10:35:51] d2.evaluation.evaluator INFO: Inference done 505/1210. 0.0466 s / img. ETA=0:03:10
[03/30 10:35:56] d2.evaluation.evaluator INFO: Inference done 522/1210. 0.0466 s / img. ETA=0:03:06
[03/30 10:36:01] d2.evaluation.evaluator INFO: Inference done 542/1210. 0.0465 s / img. ETA=0:03:00
[03/30 10:36:06] d2.evaluation.evaluator INFO: Inference done 562/1210. 0.0465 s / img. ETA=0:02:54
[03/30 10:36:11] d2.evaluation.evaluator INFO: Inference done 578/1210. 0.0464 s / img. ETA=0:02:51
[03/30 10:36:16] d2.evaluation.evaluator INFO: Inference done 602/1210. 0.0465 s / img. ETA=0:02:43
[03/30 10:36:22] d2.evaluation.evaluator INFO: Inference done 625/1210. 0.0465 s / img. ETA=0:02:36
[03/30 10:36:27] d2.evaluation.evaluator INFO: Inference done 650/1210. 0.0464 s / img. ETA=0:02:28
[03/30 10:36:32] d2.evaluation.evaluator INFO: Inference done 675/1210. 0.0464 s / img. ETA=0:02:20
[03/30 10:36:37] d2.evaluation.evaluator INFO: Inference done 695/1210. 0.0464 s / img. ETA=0:02:15
[03/30 10:36:43] d2.evaluation.evaluator INFO: Inference done 710/1210. 0.0463 s / img. ETA=0:02:12
[03/30 10:36:48] d2.evaluation.evaluator INFO: Inference done 736/1210. 0.0462 s / img. ETA=0:02:04
[03/30 10:36:53] d2.evaluation.evaluator INFO: Inference done 762/1210. 0.0462 s / img. ETA=0:01:56
[03/30 10:36:58] d2.evaluation.evaluator INFO: Inference done 783/1210. 0.0462 s / img. ETA=0:01:50
[03/30 10:37:03] d2.evaluation.evaluator INFO: Inference done 800/1210. 0.0462 s / img. ETA=0:01:46
[03/30 10:37:09] d2.evaluation.evaluator INFO: Inference done 808/1210. 0.0461 s / img. ETA=0:01:46
[03/30 10:37:18] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0462 s / img. ETA=0:01:45
[03/30 10:37:23] d2.evaluation.evaluator INFO: Inference done 842/1210. 0.0462 s / img. ETA=0:01:39
[03/30 10:37:28] d2.evaluation.evaluator INFO: Inference done 845/1210. 0.0462 s / img. ETA=0:01:40
[03/30 10:37:33] d2.evaluation.evaluator INFO: Inference done 867/1210. 0.0462 s / img. ETA=0:01:34
[03/30 10:37:39] d2.evaluation.evaluator INFO: Inference done 891/1210. 0.0462 s / img. ETA=0:01:27
[03/30 10:37:44] d2.evaluation.evaluator INFO: Inference done 912/1210. 0.0462 s / img. ETA=0:01:21
[03/30 10:37:49] d2.evaluation.evaluator INFO: Inference done 935/1210. 0.0462 s / img. ETA=0:01:14
[03/30 10:37:54] d2.evaluation.evaluator INFO: Inference done 960/1210. 0.0462 s / img. ETA=0:01:07
[03/30 10:37:59] d2.evaluation.evaluator INFO: Inference done 981/1210. 0.0462 s / img. ETA=0:01:01
[03/30 10:38:04] d2.evaluation.evaluator INFO: Inference done 994/1210. 0.0462 s / img. ETA=0:00:58
[03/30 10:38:09] d2.evaluation.evaluator INFO: Inference done 1009/1210. 0.0461 s / img. ETA=0:00:54
[03/30 10:38:14] d2.evaluation.evaluator INFO: Inference done 1027/1210. 0.0461 s / img. ETA=0:00:49
[03/30 10:38:19] d2.evaluation.evaluator INFO: Inference done 1052/1210. 0.0461 s / img. ETA=0:00:42
[03/30 10:38:25] d2.evaluation.evaluator INFO: Inference done 1060/1210. 0.0461 s / img. ETA=0:00:41
[03/30 10:38:31] d2.evaluation.evaluator INFO: Inference done 1076/1210. 0.0462 s / img. ETA=0:00:36
[03/30 10:38:36] d2.evaluation.evaluator INFO: Inference done 1100/1210. 0.0462 s / img. ETA=0:00:30
[03/30 10:38:41] d2.evaluation.evaluator INFO: Inference done 1124/1210. 0.0463 s / img. ETA=0:00:23
[03/30 10:38:46] d2.evaluation.evaluator INFO: Inference done 1146/1210. 0.0463 s / img. ETA=0:00:17
[03/30 10:38:52] d2.evaluation.evaluator INFO: Inference done 1169/1210. 0.0463 s / img. ETA=0:00:11
[03/30 10:38:57] d2.evaluation.evaluator INFO: Inference done 1187/1210. 0.0463 s / img. ETA=0:00:06
[03/30 10:39:02] d2.evaluation.evaluator INFO: Inference done 1205/1210. 0.0463 s / img. ETA=0:00:01
[03/30 10:39:04] d2.evaluation.evaluator INFO: Total inference time: 0:05:27.817834 (0.272048 s / img per device, on 1 devices)
[03/30 10:39:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:55 (0.046279 s / img per device, on 1 devices)
[03/30 10:39:04] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/30 10:39:04] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/30 10:39:04] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/30 10:39:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.637 | 62.832 | 55.451 | 33.915 | 19.784 | 42.495 |
[03/30 10:39:05] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/30 10:39:05] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/30 10:39:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/30 10:39:05] d2.evaluation.testing INFO: copypaste: 44.6371,62.8318,55.4511,33.9146,19.7837,42.4950
[03/30 10:47:01] detectron2 INFO: Rank of current process: 0. World size: 1
[03/30 10:47:02] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.7 (default, Mar 23 2020, 22:36:06) [GCC 7.3.0]
numpy                   1.18.1
detectron2              0.1.3 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/detectron2
Compiler                GCC 5.4
CUDA compiler           CUDA 9.2
detectron2 arch flags   sm_70
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.5.0 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   TITAN V
CUDA_HOME               /usr/local/cuda-11.2
Pillow                  7.0.0
torchvision             0.6.0a0+82fd1c8 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70
fvcore                  0.1.1.post20200623
cv2                     4.2.0
----------------------  -------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 9.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[03/30 10:47:02] detectron2 INFO: Command line arguments: Namespace(config_file='configs/faster_rcnn_login_StepReLu.yaml', dist_url='tcp://127.0.0.1:49923', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/lr0.001_finetune/model_final.pth'], resume=False)
[03/30 10:47:02] detectron2 INFO: Contents of args.config_file=configs/faster_rcnn_login_StepReLu.yaml:
_BASE_: "./bases/Base-RCNN-FPN.yaml"
MODEL:
  # COCO ResNet50 weights
  WEIGHTS: "./output/lr0.001_aug/model_final.pth"
  MASK_ON: False # Not doing segmentation
  RESNETS:
    DEPTH: 50 # ResNet50
  ROI_HEADS:
    NUM_CLASSES: 1 # Change to suit own task
    # Can reduce this for lower memory/faster training; Default 512
    BATCH_SIZE_PER_IMAGE: 512
  BACKBONE:
    FREEZE_AT: 2 # Default 2
    NAME: "build_resnet_fpn_backbone_quantize"
DATASETS:
  TRAIN: ("login_train",)
  TEST: ("login_test",)
DATALOADER:
  NUM_WORKERS: 0
SOLVER:
  IMS_PER_BATCH: 8 # Batch size; Default 16
  BASE_LR: 0.001
  # (2/3, 8/9)
  STEPS: (12000, 16000) # The iteration number to decrease learning rate by GAMMA.
  MAX_ITER: 18000 # Number of training iterations
  CHECKPOINT_PERIOD: 4000 # Saves checkpoint every number of steps
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800) # Image input sizes
TEST:
  # The period (in terms of steps) to evaluate the model during training.
  # Set to 0 to disable.
  EVAL_PERIOD: 2000
OUTPUT_DIR: "./output/lr0.001_finetune" # Specify output directory



[03/30 10:47:02] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 0
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('login_test',)
  TRAIN: ('login_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_quantize
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: output/lr0.001_finetune/model_final.pth
OUTPUT_DIR: ./output/lr0.001_finetune
SEED: -1
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: False
  STEPS: (12000, 16000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 2000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[03/30 10:47:02] detectron2 INFO: Full config saved to ./output/lr0.001_finetune/config.yaml
[03/30 10:47:02] d2.utils.env INFO: Using a generated random seed 4277066
[03/30 10:48:24] detectron2 INFO: Rank of current process: 0. World size: 1
[03/30 10:48:25] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.7 (default, Mar 23 2020, 22:36:06) [GCC 7.3.0]
numpy                   1.18.1
detectron2              0.1.3 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/detectron2
Compiler                GCC 5.4
CUDA compiler           CUDA 9.2
detectron2 arch flags   sm_70
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.5.0 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0                   TITAN V
CUDA_HOME               /usr/local/cuda-11.2
Pillow                  7.0.0
torchvision             0.6.0a0+82fd1c8 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70
fvcore                  0.1.1.post20200623
cv2                     4.2.0
----------------------  -------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 9.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[03/30 10:48:25] detectron2 INFO: Command line arguments: Namespace(config_file='configs/faster_rcnn_login_StepReLu.yaml', dist_url='tcp://127.0.0.1:49923', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/lr0.001_finetune/model_final.pth'], resume=False)
[03/30 10:48:25] detectron2 INFO: Contents of args.config_file=configs/faster_rcnn_login_StepReLu.yaml:
_BASE_: "./bases/Base-RCNN-FPN.yaml"
MODEL:
  # COCO ResNet50 weights
  WEIGHTS: "./output/lr0.001_aug/model_final.pth"
  MASK_ON: False # Not doing segmentation
  RESNETS:
    DEPTH: 50 # ResNet50
  ROI_HEADS:
    NUM_CLASSES: 1 # Change to suit own task
    # Can reduce this for lower memory/faster training; Default 512
    BATCH_SIZE_PER_IMAGE: 512
  BACKBONE:
    FREEZE_AT: 2 # Default 2
    NAME: "build_resnet_fpn_backbone_quantize"
DATASETS:
  TRAIN: ("login_train",)
  TEST: ("login_test",)
DATALOADER:
  NUM_WORKERS: 0
SOLVER:
  IMS_PER_BATCH: 8 # Batch size; Default 16
  BASE_LR: 0.001
  # (2/3, 8/9)
  STEPS: (12000, 16000) # The iteration number to decrease learning rate by GAMMA.
  MAX_ITER: 18000 # Number of training iterations
  CHECKPOINT_PERIOD: 4000 # Saves checkpoint every number of steps
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800) # Image input sizes
TEST:
  # The period (in terms of steps) to evaluate the model during training.
  # Set to 0 to disable.
  EVAL_PERIOD: 2000
OUTPUT_DIR: "./output/lr0.001_finetune" # Specify output directory



[03/30 10:48:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 0
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('login_test',)
  TRAIN: ('login_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_quantize
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: output/lr0.001_finetune/model_final.pth
OUTPUT_DIR: ./output/lr0.001_finetune
SEED: -1
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 4000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: False
  STEPS: (12000, 16000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 2000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[03/30 10:48:25] detectron2 INFO: Full config saved to ./output/lr0.001_finetune/config.yaml
[03/30 10:48:25] d2.utils.env INFO: Using a generated random seed 27213793
[03/30 10:48:29] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStemQuantize(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlockQuantize(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlockQuantize(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlockQuantize(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlockQuantize(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlockQuantize(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlockQuantize(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlockQuantize(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlockQuantize(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlockQuantize(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlockQuantize(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlockQuantize(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlockQuantize(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlockQuantize(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlockQuantize(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlockQuantize(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlockQuantize(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[03/30 10:48:29] fvcore.common.checkpoint INFO: Loading checkpoint from output/lr0.001_finetune/model_final.pth
[03/30 10:48:29] d2.data.datasets.coco INFO: Loaded 1210 images in COCO format from /home/l/liny/ruofan/PhishIntention/datasets/login_finder_dataset/val_coco2.json
[03/30 10:48:29] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   login    | 2862         |
|            |              |[0m
[03/30 10:48:29] d2.data.common INFO: Serializing 1210 elements to byte tensors and concatenating them all ...
[03/30 10:48:29] d2.data.common INFO: Serialized dataset takes 0.39 MiB
[03/30 10:48:29] d2.evaluation.evaluator INFO: Start inference on 1210 images
[03/30 10:48:31] d2.evaluation.evaluator INFO: Inference done 11/1210. 0.0684 s / img. ETA=0:03:14
[03/30 10:48:36] d2.evaluation.evaluator INFO: Inference done 30/1210. 0.0638 s / img. ETA=0:04:49
[03/30 10:48:42] d2.evaluation.evaluator INFO: Inference done 54/1210. 0.0628 s / img. ETA=0:04:35
[03/30 10:48:47] d2.evaluation.evaluator INFO: Inference done 70/1210. 0.0623 s / img. ETA=0:04:53
[03/30 10:48:52] d2.evaluation.evaluator INFO: Inference done 89/1210. 0.0622 s / img. ETA=0:04:53
[03/30 10:48:57] d2.evaluation.evaluator INFO: Inference done 107/1210. 0.0627 s / img. ETA=0:04:52
[03/30 10:49:02] d2.evaluation.evaluator INFO: Inference done 132/1210. 0.0629 s / img. ETA=0:04:32
[03/30 10:49:08] d2.evaluation.evaluator INFO: Inference done 150/1210. 0.0625 s / img. ETA=0:04:32
[03/30 10:49:13] d2.evaluation.evaluator INFO: Inference done 169/1210. 0.0625 s / img. ETA=0:04:32
[03/30 10:49:19] d2.evaluation.evaluator INFO: Inference done 185/1210. 0.0623 s / img. ETA=0:04:35
[03/30 10:49:24] d2.evaluation.evaluator INFO: Inference done 207/1210. 0.0624 s / img. ETA=0:04:25
[03/30 10:49:29] d2.evaluation.evaluator INFO: Inference done 229/1210. 0.0624 s / img. ETA=0:04:17
[03/30 10:49:34] d2.evaluation.evaluator INFO: Inference done 248/1210. 0.0622 s / img. ETA=0:04:13
[03/30 10:49:39] d2.evaluation.evaluator INFO: Inference done 269/1210. 0.0623 s / img. ETA=0:04:06
[03/30 10:49:45] d2.evaluation.evaluator INFO: Inference done 292/1210. 0.0624 s / img. ETA=0:03:57
[03/30 10:49:51] d2.evaluation.evaluator INFO: Inference done 306/1210. 0.0624 s / img. ETA=0:04:03
[03/30 10:49:56] d2.evaluation.evaluator INFO: Inference done 325/1210. 0.0624 s / img. ETA=0:03:58
[03/30 10:50:01] d2.evaluation.evaluator INFO: Inference done 347/1210. 0.0624 s / img. ETA=0:03:49
[03/30 10:50:11] d2.evaluation.evaluator INFO: Inference done 367/1210. 0.0624 s / img. ETA=0:03:53
[03/30 10:50:16] d2.evaluation.evaluator INFO: Inference done 379/1210. 0.0623 s / img. ETA=0:03:54
[03/30 10:50:21] d2.evaluation.evaluator INFO: Inference done 396/1210. 0.0622 s / img. ETA=0:03:50
[03/30 10:50:26] d2.evaluation.evaluator INFO: Inference done 415/1210. 0.0621 s / img. ETA=0:03:44
[03/30 10:50:31] d2.evaluation.evaluator INFO: Inference done 435/1210. 0.0620 s / img. ETA=0:03:37
[03/30 10:50:37] d2.evaluation.evaluator INFO: Inference done 455/1210. 0.0619 s / img. ETA=0:03:31
[03/30 10:50:42] d2.evaluation.evaluator INFO: Inference done 472/1210. 0.0619 s / img. ETA=0:03:28
[03/30 10:50:47] d2.evaluation.evaluator INFO: Inference done 489/1210. 0.0618 s / img. ETA=0:03:23
[03/30 10:50:52] d2.evaluation.evaluator INFO: Inference done 511/1210. 0.0619 s / img. ETA=0:03:15
[03/30 10:50:57] d2.evaluation.evaluator INFO: Inference done 525/1210. 0.0618 s / img. ETA=0:03:13
[03/30 10:51:02] d2.evaluation.evaluator INFO: Inference done 543/1210. 0.0618 s / img. ETA=0:03:08
[03/30 10:51:07] d2.evaluation.evaluator INFO: Inference done 560/1210. 0.0618 s / img. ETA=0:03:04
[03/30 10:51:14] d2.evaluation.evaluator INFO: Inference done 578/1210. 0.0617 s / img. ETA=0:02:59
[03/30 10:51:19] d2.evaluation.evaluator INFO: Inference done 604/1210. 0.0618 s / img. ETA=0:02:50
[03/30 10:51:24] d2.evaluation.evaluator INFO: Inference done 619/1210. 0.0619 s / img. ETA=0:02:46
[03/30 10:51:29] d2.evaluation.evaluator INFO: Inference done 641/1210. 0.0619 s / img. ETA=0:02:39
[03/30 10:51:34] d2.evaluation.evaluator INFO: Inference done 665/1210. 0.0619 s / img. ETA=0:02:31
[03/30 10:51:39] d2.evaluation.evaluator INFO: Inference done 685/1210. 0.0619 s / img. ETA=0:02:25
[03/30 10:51:44] d2.evaluation.evaluator INFO: Inference done 700/1210. 0.0618 s / img. ETA=0:02:22
[03/30 10:51:49] d2.evaluation.evaluator INFO: Inference done 712/1210. 0.0617 s / img. ETA=0:02:20
[03/30 10:51:54] d2.evaluation.evaluator INFO: Inference done 735/1210. 0.0618 s / img. ETA=0:02:12
[03/30 10:51:59] d2.evaluation.evaluator INFO: Inference done 757/1210. 0.0618 s / img. ETA=0:02:05
[03/30 10:52:04] d2.evaluation.evaluator INFO: Inference done 780/1210. 0.0617 s / img. ETA=0:01:58
[03/30 10:52:10] d2.evaluation.evaluator INFO: Inference done 794/1210. 0.0616 s / img. ETA=0:01:55
[03/30 10:52:15] d2.evaluation.evaluator INFO: Inference done 811/1210. 0.0615 s / img. ETA=0:01:51
[03/30 10:52:24] d2.evaluation.evaluator INFO: Inference done 822/1210. 0.0615 s / img. ETA=0:01:51
[03/30 10:52:29] d2.evaluation.evaluator INFO: Inference done 843/1210. 0.0615 s / img. ETA=0:01:44
[03/30 10:52:35] d2.evaluation.evaluator INFO: Inference done 862/1210. 0.0615 s / img. ETA=0:01:39
[03/30 10:52:40] d2.evaluation.evaluator INFO: Inference done 881/1210. 0.0615 s / img. ETA=0:01:33
[03/30 10:52:45] d2.evaluation.evaluator INFO: Inference done 902/1210. 0.0615 s / img. ETA=0:01:27
[03/30 10:52:50] d2.evaluation.evaluator INFO: Inference done 923/1210. 0.0616 s / img. ETA=0:01:21
[03/30 10:52:55] d2.evaluation.evaluator INFO: Inference done 926/1210. 0.0616 s / img. ETA=0:01:21
[03/30 10:53:00] d2.evaluation.evaluator INFO: Inference done 944/1210. 0.0616 s / img. ETA=0:01:16
[03/30 10:53:05] d2.evaluation.evaluator INFO: Inference done 966/1210. 0.0617 s / img. ETA=0:01:09
[03/30 10:53:13] d2.evaluation.evaluator INFO: Inference done 983/1210. 0.0617 s / img. ETA=0:01:05
[03/30 10:53:19] d2.evaluation.evaluator INFO: Inference done 996/1210. 0.0617 s / img. ETA=0:01:02
[03/30 10:53:24] d2.evaluation.evaluator INFO: Inference done 1016/1210. 0.0617 s / img. ETA=0:00:56
[03/30 10:53:29] d2.evaluation.evaluator INFO: Inference done 1034/1210. 0.0616 s / img. ETA=0:00:51
[03/30 10:53:34] d2.evaluation.evaluator INFO: Inference done 1056/1210. 0.0616 s / img. ETA=0:00:44
[03/30 10:53:39] d2.evaluation.evaluator INFO: Inference done 1080/1210. 0.0617 s / img. ETA=0:00:37
[03/30 10:53:44] d2.evaluation.evaluator INFO: Inference done 1098/1210. 0.0617 s / img. ETA=0:00:32
[03/30 10:53:50] d2.evaluation.evaluator INFO: Inference done 1122/1210. 0.0617 s / img. ETA=0:00:25
[03/30 10:53:55] d2.evaluation.evaluator INFO: Inference done 1142/1210. 0.0618 s / img. ETA=0:00:19
[03/30 10:54:00] d2.evaluation.evaluator INFO: Inference done 1163/1210. 0.0618 s / img. ETA=0:00:13
[03/30 10:54:05] d2.evaluation.evaluator INFO: Inference done 1181/1210. 0.0618 s / img. ETA=0:00:08
[03/30 10:54:12] d2.evaluation.evaluator INFO: Inference done 1185/1210. 0.0618 s / img. ETA=0:00:07
[03/30 10:54:18] d2.evaluation.evaluator INFO: Inference done 1205/1210. 0.0618 s / img. ETA=0:00:01
[03/30 10:54:19] d2.evaluation.evaluator INFO: Total inference time: 0:05:48.714149 (0.289389 s / img per device, on 1 devices)
[03/30 10:54:19] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:14 (0.061838 s / img per device, on 1 devices)
[03/30 10:54:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[03/30 10:54:19] d2.evaluation.coco_evaluation INFO: Saving results to ./output/lr0.001_finetune/coco_instances_results.json
[03/30 10:54:19] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[03/30 10:54:20] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.620 | 62.826 | 55.475 | 33.688 | 20.162 | 42.529 |
[03/30 10:54:20] d2.engine.defaults INFO: Evaluation results for login_test in csv format:
[03/30 10:54:20] d2.evaluation.testing INFO: copypaste: Task: bbox
[03/30 10:54:20] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[03/30 10:54:20] d2.evaluation.testing INFO: copypaste: 44.6197,62.8257,55.4745,33.6883,20.1621,42.5291
